---
title: "baml：面向 AI 工作流与智能体的提示词编程语言项目"
对象: "GitHub 项目"
项目主页: "https://github.com/BoundaryML/baml"
Stars快照: "3743"
官方网站: "https://docs.boundaryml.com"
主要语言: "Rust"
开源协议: "Apache-2.0"
---

## 摘要

### 1) 一句话总结
BAML 是一种基于 Rust 构建的开源领域特定语言（DSL），它通过将提示词转化为带有明确入参和返回类型的函数，为构建 AI 工作流和智能体提供类型安全、跨语言的结构化提示词管理方案。

### 2) 核心要点
* **基础信息**：底层基于 Rust 开发，采用 Apache-2.0 开源协议，100% 离线运行且无额外数据收集，当前 GitHub Stars 数为 7647。
* **核心理念**：将“提示词工程”转化为“Schema 工程”，把提示词定义为强类型的函数，替代难以维护的字符串拼接（如 f-strings）。
* **跨语言客户端生成**：只需编写 BAML 文件，编译器即可自动生成 Python、TypeScript、Ruby、Go、Java、C# 或 Rust 的强类型客户端代码供主程序调用。
* **Schema 对齐解析（SAP）**：即使底层模型不支持原生的工具调用（Tool-calling），也能准确解析包含 Markdown 或思维链的复杂 JSON 输出，实现新模型发布首日即可支持结构化输出。
* **灵活的模型路由**：支持快速切换数百种模型（如 OpenAI、Anthropic、Gemini、Ollama 等），并支持静态配置重试（Retry）、降级（Fallback）和轮询（Round-robin）策略。
* **流式输出支持**：提供完整的类型安全流式接口，并内置适用于前端（如 NextJS）和后端（如 Python）的实用工具。
* **Git 友好**：提示词作为纯文本文件保存在本地文件系统中，方便直接使用 Git 进行版本控制和差异对比。

### 3) 风险与不足
* **IDE 支持受限**：目前原生可视化与测试工具仅支持 VSCode，对 JetBrains 和 Neovim 的支持尚在开发中。
* **非全栈语言**：BAML 仅专注于编写和管理提示词，应用的核心业务逻辑仍必须使用常规编程语言来编写。

## 功能与定位

BAML（Basically a Made-up Language）是一个专为构建可靠 AI 工作流和智能体（Agents）设计的提示词框架与领域特定语言。它的核心理念是将“提示词工程”转化为“Schema 工程”，通过将大语言模型（LLM）的提示词定义为带有明确入参和返回类型的函数，为提示词编写提供类似代码的结构化和类型安全体验，从而替代难以维护的字符串拼接（如 f-strings）。

## 典型使用场景

* **构建 AI 智能体与工作流**：需要稳定、类型安全的结构化输出的复杂 AI 应用。
* **跨语言提示词管理**：在 Python、TypeScript、Ruby、Go、Java、C# 或 Rust 项目中统一管理和调用提示词。
* **流式 UI 开发**：为前端（如 NextJS）或后端应用快速构建带有类型安全的流式响应界面。
* **模型无缝切换与容灾**：在不同大模型之间快速切换，或配置自动重试与降级策略。

## 核心功能

* **提示词即函数**：将提示词封装为函数，明确声明输入参数、返回类型（Schema）、使用的模型及提示词模板。
* **跨语言客户端生成**：只需用 BAML 编写提示词，其 Rust 编译器会自动生成目标语言（如 Python、TS 等）的客户端代码，供主程序直接调用。
* **Schema 对齐解析（SAP）**：即使底层模型不支持原生的工具调用（Tool-calling）API，BAML 也能通过 SAP 算法准确解析复杂的 LLM 输出（例如包含 Markdown 或思维链的 JSON 数据）。
* **灵活的模型路由**：支持通过简短配置切换数百种模型（包括 OpenAI、Anthropic、Gemini、Vertex、Bedrock、Azure 以及兼容 OpenAI 格式的 Ollama、vLLM、OpenRouter 等），并支持静态定义的重试策略（Retry）、降级（Fallback）和轮询（Round-robin）。
* **流式输出（Streaming）**：提供完整的类型安全流式接口，并内置适用于 NextJS、Python 等环境的实用工具。
* **IDE 原生工具**：提供 VSCode 插件，支持在编辑器内可视化完整提示词、查看 API 请求，并支持并行运行测试以实现极速迭代。

## 特色与差异点

* **完全开源与隐私安全**：基于 Apache-2.0 协议，100% 离线运行。除了用户显式设置的模型调用外，没有任何额外的网络请求，不收集任何训练数据。
* **Git 友好**：遵循“不重复造轮子”的设计哲学，提示词作为纯文本文件保存在本地文件系统中，可直接使用 Git 进行版本控制和差异对比。
* **极致性能**：底层基于 Rust 构建，运行开销极低。
* **Day-1 模型支持**：得益于其解析算法，新模型发布首日即可支持结构化输出，无需等待模型官方支持并行工具调用或复杂 Schema。

## 使用方式概览

1. **定义 BAML 文件**：使用 BAML 语法定义数据结构（Class）和提示词函数，指定输入、输出类型及模型配置。
2. **生成客户端**：通过 BAML 编译器生成对应编程语言的强类型客户端代码。
3. **在业务代码中调用**：在主应用（如 Python 或 TypeScript）中引入生成的客户端，像调用普通本地函数一样传入参数，直接获取结构化的返回值或流式数据。

## 限制与注意事项

* **IDE 支持限制**：目前原生可视化与测试工具仅支持 VSCode，对 JetBrains 和 Neovim 的支持尚在开发中。
* **非全栈语言**：BAML 仅用于编写和管理提示词，应用的核心业务逻辑仍需使用常规编程语言编写。

## 链接

- 仓库：https://github.com/BoundaryML/baml
- 官网：https://docs.boundaryml.com

## 关联主题

- [[00-元语/AI]]
- [[00-元语/workflow]]
- [[00-元语/github]]
- [[00-元语/sdk]]
- [[00-元语/rag]]
