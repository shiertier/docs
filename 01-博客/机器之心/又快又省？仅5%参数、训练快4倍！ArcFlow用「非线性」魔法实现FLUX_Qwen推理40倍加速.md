---
title: "又快又省？仅5%参数、训练快4倍！ArcFlow用「非线性」魔法实现FLUX/Qwen推理40倍加速"
发布日期: 2026-02-24
作者: "机器之心"
来源: "机器之心"
原文链接: "https://www.jiqizhixin.com/articles/2026-02-24-8"
---

## 摘要

**1) 一句话总结**
ArcFlow 是一种针对扩散模型的少步蒸馏加速方案，通过动量参数化和解析求解器顺应原始非线性生成轨迹，仅需微调不到5%的参数即可将 FLUX/Qwen 等大模型的推理加速40倍（压缩至2步生成）。

**2) 核心要点**
*   **传统方法痛点**：现有的少步加速方案试图将复杂的生成轨迹强行“拉直”，导致几何失配（图像结构崩坏、细节丢失）以及全参数微调带来的高昂成本和灾难性遗忘。
*   **核心理念**：ArcFlow 放弃强制直线拟合，转而通过建模速度场的连续变化规律，顺应教师模型原本的非线性生成轨迹。
*   **动量参数化（Momentum Parameterization）**：引入物理学“动量”概念，模型不仅预测当前速度，还预测动量因子，从而显式构建出能精确贴合教师模型路径的非线性轨迹。
*   **解析求解器（Analytic Solver）**：基于动量公式推导出闭式解，只需一次前向传播即可实现数学层面的“零误差”积分，消除了传统方法的离散化噪声。
*   **极简微调成本**：无需重写整体模型参数，仅需通过 LoRA 微调不到 5% 的参数（主要适配动量预测头）即可实现轨迹对齐。
*   **训练效率提升**：相比全量微调方法（如 TwinFlow），ArcFlow 的训练收敛速度提升了 4 倍以上，且最大程度保留了原模型的庞大知识库。
*   **极致推理加速**：在 Qwen-Image-20B 和 FLUX.1-dev 上验证，将原本 50-100 步的迭代压缩至 2 步（2 NFE），实现超 40 倍的推理加速。
*   **画质与多样性保障**：在 2 步推理设定下，其 FID 和语义一致性得分优于或持平现有 SOTA 方法，有效克服了线性蒸馏容易出现的背景模糊、结构扭曲和多样性坍缩问题。

## 正文

![Image 1: Image](https://image.jiqizhixin.com/uploads/editor/14202b95-2eca-4925-9725-97ea19e7090f/640.png)
在生成式 AI 的浪潮中，我们见证了从 Stable Diffusion 到 FLUX、Qwen-Image 等大规模扩散模型的画质飞跃。然而，这种飞跃并非没有代价。为了从纯噪声中 “雕刻” 出清晰的图像，这些模型通常需要进行 **40 到 100 步（NFE）的迭代去噪**。这种延迟使得模型很难真正应用于实际的实时生成或大规模服务。

于是，“少步生成”（Few-step Generation）成为了必争之地。对于原本教师模型曲折的生成轨迹，目前的少步加速方案（如 Progressive Distillation, Distribution Matching 等）都在试图做同一件事：**把弯路拉直，一步到达终点。**

然而，原本高维空间的生成轨迹极其复杂，强行 “拉直” 会导致轨迹上的**几何失配（Geometric Mismatch）**。这直接导致了少步生成时的结构崩坏和细节丢失。

**有没有一种方法，既能快，又能顺应原本蜿蜒的生成轨迹？**

复旦大学与微软亚洲研究院带来的 **ArcFlow** 给出了答案：**如果路是弯的，那就学会 “漂移”，而不是把路修直。**

![Image 2: 图片](https://image.jiqizhixin.com/uploads/editor/7a0ae6b8-eb91-4d02-99ac-97697b6a9846/640.png)
*   论文地址：https://arxiv.org/abs/2602.09014

*   项目代码：https://github.com/pnotp/ArcFlow

**一、 困境：为什么 “走直线” 难以学习？**

在扩散模型中，教师模型（Pre-trained Teacher）的生成过程本质上是在高维空间中求解微分方程并进行多步积分。由于图像流形的复杂性，**教师模型原本的采样轨迹通常是一条蜿蜒的曲线**，其切线方向（即速度场）随时间步不断变化。

为了加速，现有的蒸馏方法（如 Progressive Distillation, Instaflow 等）尝试将这个轨迹压缩成一步直线抵达。它们的逻辑是：既然走曲线慢，那就训练学生模型，把起点（噪声）和终点（图像）之间连成一条直线。如果学生能学会走这条直线，那推理不就只需要一步了吗？

这种策略带来了两个致命问题：

**1. 几何失配（Geometric Mismatch）**：教师模型原本的权重是基于曲线轨迹训练出来的。强行让学生模型去拟合一条直线，相当于让它 “背叛” 教师原本的生成先验。这种几何上的不匹配，导致学生模型很难学，或者学出来的东西结构崩坏。

**2. 学习成本高**：为了强行扭转轨迹，学生模型往往需要进行**全参数微调（Full Fine-tuning）**。这不仅训练慢、显存开销大，而且容易导致 “灾难性遗忘”，破坏大模型原本优秀的泛化能力。

所以我们经常看到：很多蒸馏后的模型，虽然速度快了，但生成质量不稳定，甚至对复杂的 Prompt 理解能力下降。

**如果不强制拉直，我们还能怎么快起来？**

**二、 洞察：速度场不是随机的，它是连续的**

ArcFlow 团队重新审视了教师模型的轨迹，根据 ODE 的理论规律，在相邻的时间步之间，去噪的速度方向并不是跳跃式变化的，而是存在极强的相关性。这就像一辆赛车在过弯道，下一秒的方向和速度，很大程度上取决于当前秒的状态和惯性。既然教师模型的轨迹本身就是连续变化的，**为什么我们不直接去建模这种 “变化规律”，而不是强行把它改成直线呢？**

如果我们能找到一种参数化方法，能够描述这种 “弯曲” 的趋势，那么学生模型就不需要费力去把路拉直，而是可以**顺着教师的势能**，用极少的步数 “滑” 向终点。

基于这个核心洞察，ArcFlow 诞生了。

![Image 3: 图片](https://image.jiqizhixin.com/uploads/editor/70d3fa25-1a84-489a-af14-bdc2fc2e0c45/640.png)
**三、 ArcFlow 的三大杀手锏**

![Image 4: 图片](https://image.jiqizhixin.com/uploads/editor/c1c72c23-1233-4925-a274-dc199d562f94/640.png)
**1. 动量参数化（Momentum Parameterization）：给生成过程加个 “惯性”**

为了捕捉上述的 “速度连续性”，ArcFlow 引入了物理学中经典的 “动量”（Momentum）概念。

在传统方法中，模型在每个时间步独立预测速度。而在 ArcFlow 中，我们将速度场建模为**多个连续动量过程的混合**。通俗来说，模型不仅预测当前的 “速度”，还预测了一个 “动量因子”（Momentum Factor）。这个因子描述了速度随时间衰减或增强的趋势。这就好比我们知道了物体的初速度和受力情况（动量），哪怕不看中间过程，我们也能通过物理公式直接预判它未来的轨迹是弯曲的还是笔直的。

这一设计让 ArcFlow 能够**显式地构建非线性轨迹**。在 2-4 步的极少步数下，这种非线性轨迹比生硬的直线能更精确地贴合教师模型的原始路径。

**2. 解析求解器（Analytic Solver）：数学层面的 “零误差”**

既然已经用 “动量公式” 完美定义了速度随时间的演变规律，那么这条轨迹的积分就是**可解析的**。

也就是说，我们可以推导出一个闭式解（Closed-form Solution）。

这意味着，ArcFlow 不需要像传统求解器那样通过离散步去拟合轨迹。**它只需要一次前向传播，就能通过数学公式，精确无误地计算出任意时间间隔后的终端状态**。

这种**数学层面上的 “零误差” 积分**，是 ArcFlow 能够实现高精度流匹配的关键。它消除了传统蒸馏方法中的离散化噪声，让生成的图像细节清晰。

**3. 极简训练策略：<5% 参数的 LoRA 微调**

这是最让开发者兴奋的一点。

正如前文所说，传统方法因为要 “强行拉直” 轨迹，不得不重写整个模型的参数。而 ArcFlow 选择 “顺势而为”，它的非线性轨迹天然契合教师模型的预训练分布。

因此，ArcFlow 不需要破坏教师模型原本的参数。实验证明，**仅需通过 LoRA 微调不到 5% 的参数**（主要是为了适应新的动量预测头），就能实现完美的轨迹对齐。

这种策略带来了两大红利：

*   **训练收敛极快**：相比 TwinFlow 等全量微调方法，ArcFlow 的**收敛速度快了超过 4 倍**。

*   **保留教师先验**：最大程度继承了 FLUX/Qwen 原本庞大的知识库，不像其他蒸馏模型那样容易出现崩坏或画质劣化。

**四、 实验数据**

团队在 **Qwen-Image-20B** 和 **FLUX.1-dev** 这两个目前最强的开源模型上进行了验证。结果表明，ArcFlow 在速度、质量和效率上实现了的平衡。

**1. 推理速度**

从原始的 50-100 步迭代，直接压缩至 **2 步（2 NFE）**。在相同硬件上，实现了超过 40 倍加速。

**2. 画质表现**

在 Geneval、DPG-Bench 等基准测试中，ArcFlow 在 2 步设定下的 FID 和语义一致性得分大部分优于或持平目前的 SOTA 方法。

![Image 5: 图片](https://image.jiqizhixin.com/uploads/editor/9b20d537-2516-47a4-8806-5ceaa130c1c6/640.png)![Image 6: 图片](https://image.jiqizhixin.com/uploads/editor/e8bc24ed-01e3-4e91-a4ea-345fdf508e93/640.png)
视觉对比：

从论文展示的效果图来看，在同样的 2 步推理下，其他线性蒸馏方法生成的图像容易出现背景模糊、物体结构扭曲（如折断 / 重影的剑、模糊的背景），尤其是在不同的初始噪声下，其他方法容易出现生成模式相似、多样性坍缩的情况。而 ArcFlow 生成的图像不仅清晰度高，而且保留了教师模型原本的丰富细节和画面多样性。

![Image 7: 图片](https://image.jiqizhixin.com/uploads/editor/8c03075e-6f33-4c06-aa22-6c287f8ca410/640.png)
**3. 训练效率**

得益于更精准的轨迹拟合和 LoRA 策略，ArcFlow 的训练曲线令人赏心悦目。在相同迭代步数下，ArcFlow 的 FID 分数和画面质量大幅领先。对于没有大规模算力的实验室或个人开发者来说，这大大降低了复现和定制的门槛。

![Image 8: 图片](https://image.jiqizhixin.com/uploads/editor/1fe921f2-c9fd-41d9-b222-d2d591e6c46c/640.png)![Image 9: 图片](https://image.jiqizhixin.com/uploads/editor/199470a4-0f88-4aa0-b48b-f301362634dd/640.png)
**4. 更多效果展示**

![Image 10: 图片](https://image.jiqizhixin.com/uploads/editor/53686224-c9c3-4501-8dbf-a805b239a70e/640.png)![Image 11: 图片](https://image.jiqizhixin.com/uploads/editor/ac1ac0eb-00eb-4a11-b19a-db9caf4161f0/640.png)![Image 12: 图片](https://image.jiqizhixin.com/uploads/editor/1716ff36-57d0-4ffb-afde-96f46fc1b679/640.png)
**五、 总结**

ArcFlow 提出了一种新的少步蒸馏的解决思路：相较于 “把曲线拉直” 的 “蛮力”，不如顺应原本的模型特征空间，用参数去描述其复杂性。通过**动量参数化**和**解析求解器**，ArcFlow 避免了不稳定的对抗性目标函数和全参数训练，从而实现了更快的收敛速度和更高效的蒸馏过程。这为未来的高效生成模型研究提供了一个极具潜力的方向。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
