---
title: "告别静态权重：谷歌提出 Nested Learning，让大模型拥有“海马体”"

站点: "微信公众平台"
原文链接: "https://mp.weixin.qq.com/s/MZ3MR4a-khFEax0GujfuIQ"
发布日期: "2025-11-24"
作者: "沈公子今天读什么"
---

## 摘要

### 1) 一句话总结
谷歌提出“嵌套学习”（Nested Learning）范式及 HOPE 架构，通过多频率动态更新机制让大模型在推理阶段实现参数的实时在线学习，打破了传统深度学习静态权重的局限。

### 2) 核心要点
*   **解决“顺行性遗忘症”**：针对现有大模型在推理阶段权重锁死、无法将新上下文转化为长期记忆的问题，提出让模型在推理过程中实时自我更新的新范式。
*   **嵌套学习（Nested Learning）理论**：将深度神经网络重新定义为一组嵌套的优化问题，每一层不再是静态计算模块，而是具有独立更新频率的动态优化系统。
*   **提出“深度优化器”（Deep Optimizers）**：论证了传统优化器（如 Momentum、Adam）本质上是压缩梯度的联想记忆模块，并提出用多层感知机（MLP）替代简单的线性动量项，以记忆和预测复杂的梯度变化规律。
*   **HOPE 架构设计**：基于嵌套学习理论设计了 HOPE 模型，核心由“连续记忆系统”（Continuum Memory）和“自我修正机制”（Self-Modifying Titans）组成，推理全过程无任何参数被“冻结”。
*   **多频率分层处理**：连续记忆系统包含不同更新频率的嵌套链条（如 Fast MLP 每步更新处理细节，Mid MLP 每隔 C 步更新提取模式，Slow MLP 存储长期知识）。
*   **自我修正机制**：模型通过计算预测误差（“惊奇”信号），并利用深度优化器将该信号实时压缩进记忆中，实现自我更新。
*   **性能表现（具体数据）**：在 1.3B 参数规模下，HOPE 在语言建模和常识推理任务上取得 SOTA，平均分（57.23）显著优于基线模型 Transformer++（52.25）和 Titans（56.82）。
*   **机制验证**：消融实验表明，仅保留快速更新会导致灾难性遗忘，仅保留慢速更新会丧失上下文学习能力；可视化结果证实高频模块自动响应稀有实体，低频模块响应常见语义。

## 正文

大模型终于有“海马体”了！谷歌研究团队在一篇名为《Nested Learning: The Illusion of Deep Learning Architectures》的论文中提出了全新的 HOPE 架构。该架构让模型在推理阶段不再单纯依赖查找静态的权重表，而是通过“嵌套学习”机制，将当前的上下文实时压缩进参数里。这就像人脑把短期记忆转化为长期记忆一样，实现了真正的在线学习。

### 为什么需要 Nested Learning？

目前的深度学习模型，尤其是大语言模型（LLM），普遍患有一种“顺行性遗忘症”（Anterograde Amnesia）。虽然它们在预训练阶段学到了海量知识，但在部署后，面对新的上下文输入，模型只能利用短暂的“工作记忆”（Context Window），无法真正将新信息固化为长期记忆。也就是说，模型的权重在推理时是锁死的。

现有的解决办法往往是单纯地堆叠层数，但这仅仅增加了计算的空间深度，并没有解决“在不同时间尺度上持续学习”的问题。因此，我们需要一种新的范式，让模型在推理过程中也能实时自我更新。

### 核心理论：优化即记忆，层级即频率

这篇论文最烧脑、也最颠覆的地方在于视角的翻转：**通常我们认为“模型”是存储知识的，而“优化器”是训练模型的工具；但这篇论文证明了，优化器本身就是一个记忆模型，而模型的每一层前向传播，其实是在解一个内部的优化问题。**

基于此，作者提出了以下核心概念：

*   **嵌套学习（Nested Learning, NL）：** 深度神经网络本质上是一组嵌套的优化问题。每一层不应被视为静态的计算模块，而应被视为拥有独立更新频率（Update Frequency）的动态优化系统。
*   **深度优化器（Deep Optimizers）：** 常用的优化器（如 SGD+Momentum, Adam）本质上是联想记忆模块（Associative Memory），它们在试图压缩梯度信息。例如，Momentum 其实是在做一个线性回归来记忆梯度。既然如此，完全可以用更复杂的神经网络（MLP）来替代简单的动量项，构建“深度优化器”。

#### 一个生动的比喻：跨国公司的决策体系

为了更好地理解“嵌套学习”和“多频率更新”，我们可以把模型想象成一家大型跨国公司，其内部有一套处理海量信息的层级制度：

1.  **一线实习生（对应 Attention / 高频组件）：** 反应极快，电话一响立刻处理。但他们没有记事本，放下电话就忘。更新频率是毫秒级，负责捕捉当前的上下文流。
2.  **部门经理（对应 Model Layers / 模型参数）：** 负责制定“操作手册”（权重）。如果实习生报错，经理会修改手册，但他需要观察一段时间的趋势再做决定。更新频率是分钟级，捕捉中期的数据规律。
3.  **公司元老（对应 Optimizer / 优化器状态）：** 手里拿着“备忘录”（Momentum State），记录经理的修改路径并给出大方向建议，防止经理瞎改。更新频率是天/周级，在更长的时间尺度上对数据进行压缩和记忆。

在 Nested Learning 中，这三者没有本质区别，都在试图记住并适应环境，唯一的区别仅仅是**更新频率**不同。

### HOPE 架构的运行机制

基于嵌套学习理论，作者设计了 **HOPE（Hierarchy of Optimizers and Persistent Experience）** 架构。在 HOPE 中，没有任何部分是“冻结”的，所有参数都在根据输入流实时调整。其处理序列的具体流程如下：

**第一步：频率分解与输入处理**
输入 Token 被嵌入为向量后，不会进入单一通道，而是被视为不同频率信号的组合。高频通路负责处理稍纵即逝的细节（如人名），低频通路负责处理稳定的语义（如语法规则）。

**第二步：连续记忆系统（Continuum Memory System）**
信号进入一个由多个动态更新的 MLP 组成的嵌套链条：
*   **Level 1 (Fast MLP)：** 每一步都根据当前的局部预测误差立刻更新参数，就像实习生立刻记住电话内容。
*   **Level 2 (Mid MLP)：** 每隔一定步数（如 16 步）更新一次，汇总一段时间的信息，提取更抽象的模式。
*   **Level 3 (Slow MLP)：** 更新频率更低，存储长期固化的知识。

**第三步：自我修正机制（Self-Referential Mechanism）**
这是核心的注意力/记忆模块。它不仅查表，还在预测“如何更新自己”：
*   输入生成 Query、Key、Value。
*   模型利用当前记忆状态预测 Value，其预测误差被视为**“惊奇”信号（Surprise Signal）**。
*   使用 Deep Optimizer 思想，将这个“惊奇”信号压缩进记忆中进行嵌套更新。

**第四步：混合与输出**
将连续记忆系统（各级 MLP）和自我修正机制的输出进行门控融合（Gating），最终预测下一个 Token。

### 实验验证与核心发现

在 1.3B 参数规模下，HOPE 架构在语言建模（WikiText-103, The Pile）和常识推理（PIQA, HellaSwag 等）任务上，均击败了目前最强的 Transformer++ 以及 RetNet, Mamba, Titans 等现代 RNN 架构，取得了 **SOTA（最优）性能**。

论文的实验还揭示了几个深刻的洞察：

*   **多频率层级缺一不可：** 消融实验表明，如果只保留快速更新层，模型极易发生灾难性遗忘，长期记忆丢失；如果只保留慢速更新层，模型退化为静态网络，上下文学习能力大幅下降。这印证了人脑记忆机制（海马体快速编码 + 大脑皮层慢速巩固）在 AI 设计中的普适性。
*   **注意力机制本质上是高级优化器：** 作者尝试将不同的优化器算法作为模型内部的记忆更新规则，发现使用 Adam 的变体效果最好。从数学上看，Transformer 中 Attention 的更新公式与预处理梯度下降（类似于 Adam）高度一致。
*   **自动分层处理信息：** 可视化分析显示，HOPE 的低频模块主要对功能词和常见语义有反应，而高频模块则剧烈响应当前上下文中的稀有实体。

### 总结

Nested Learning 告诉我们，传统深度学习的架构设计产生了一种错觉，让我们以为智能来源于堆叠空间的深度（层数）。实际上，一个真正智能的系统，应该是一个**时间上的嵌套系统**：从毫秒级的 Attention，到分钟级的 Weights，再到周级的 Optimizer，每一层都在用自己的频率进行“梯度下降”与记忆更新。HOPE 模型，正是将这一理念完美代码化的前沿探索。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/memory]]
- [[00-元语/paper]]
- [[00-元语/benchmark]]
