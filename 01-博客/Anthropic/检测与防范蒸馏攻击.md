---
title: "检测与防范蒸馏攻击"
发布日期: 2026-02-23
作者: "Anthropic"
来源: "Anthropic News"
原文链接: "https://www.anthropic.com/news/detecting-and-preventing-distillation-attacks"
译注: "未找到官方中文版本，本文基于英文原文翻译整理。"
---

## 摘要

**1) 一句话摘要**
Anthropic 发现 DeepSeek、Moonshot 和 MiniMax 三家 AI 实验室通过约 2.4 万个欺诈账户进行了超 1600 万次交互，非法蒸馏并提取 Claude 的核心能力，为此 Anthropic 已采取多层面的技术防御与行业协作反制措施。

**2) 关键点**
*   **攻击规模与手段**：三家实验室利用商业代理服务（“九头蛇集群”）建立了庞大的欺诈账户网络（单一网络最高达 2 万个账户），绕过区域访问限制，通过高度重复的提示词大规模提取模型能力。
*   **DeepSeek 活动**：产生超 15 万次交互，主要针对推理能力、奖励模型打分及规避审查的替代方案，并被发现大规模生成思维链（chain-of-thought）训练数据。
*   **Moonshot AI 活动**：产生超 340 万次交互，针对智能体推理、编程和计算机视觉等能力，通过请求元数据追踪到其高级员工。
*   **MiniMax 活动**：产生超 1300 万次交互，针对智能体编程与工具调用；在 Anthropic 发布新模型后，其在 24 小时内将近一半的流量重定向至新系统。
*   **出口管制关联**：外国实验室的快速进步部分依赖于这种非法提取，这破坏了美国的出口管制；但由于大规模蒸馏仍需先进芯片，这也进一步印证了限制芯片获取的合理性。
*   **防御与反制措施**：Anthropic 部署了分类器和行为指纹识别系统以检测蒸馏模式，加强了对教育和初创账户的验证，并正在开发产品和模型级别的安全防护，以降低模型输出对非法蒸馏的有效性。
*   **行业协作**：Anthropic 正在与其他 AI 实验室、云提供商和相关机构共享技术指标，以应对这种超越单一公司防御能力的威胁。

**3) 风险/缺口**
*   **安全防护缺失与国家安全风险**：非法蒸馏的模型通常会被剥离必要的安全防护措施，可能被国家或非国家行为者用于开发生物武器、实施恶意网络活动、虚假信息活动或大规模监控。
*   **开源扩散风险**：如果这些缺乏保护的蒸馏模型被开源，危险能力将在任何单一政府的控制范围之外自由传播，导致风险成倍增加。
*   **对出口管制有效性的误判**：如果未能察觉这些蒸馏攻击，外国实验室表面上的快速进步可能会被外界错误地视为美国出口管制无效的证据。

## 正文

我们发现了三个 AI 实验室（DeepSeek、Moonshot 和 MiniMax）发起的工业级规模的活动，旨在非法提取 Claude 的能力以改进他们自己的模型。这些实验室通过约 24,000 个欺诈账户与 Claude 进行了超过 1600 万次交互，违反了我们的服务条款和区域访问限制。

这些实验室使用了一种称为“蒸馏（distillation）”的技术，即利用较强模型的输出来训练能力较弱的模型。蒸馏是一种广泛使用且合法的训练方法。例如，前沿 AI 实验室通常会蒸馏自己的模型，为客户创建更小、更便宜的版本。但蒸馏也可用于非法目的：竞争对手可以利用它从其他实验室获取强大的能力，而所需的时间和成本仅为独立开发的一小部分。

这些活动的强度和复杂性正在不断增加。采取行动的窗口期很窄，而且这种威胁已经超越了任何单一公司或地区。应对这一问题需要行业参与者、政策制定者和全球 AI 社区采取迅速、协调的行动。

## 为什么蒸馏问题至关重要

非法蒸馏的模型缺乏必要的安全防护措施（safeguards），从而带来了重大的国家安全风险。Anthropic 和其他美国公司构建的系统能够防止国家和非国家行为者利用 AI 进行例如开发生物武器或实施恶意网络活动的行为。通过非法蒸馏构建的模型不太可能保留这些安全防护措施，这意味着危险能力可能会在完全剥离许多保护措施的情况下扩散。

蒸馏美国模型的外国实验室随后可以将这些不受保护的能力输入到军事、情报和监控系统中——使威权政府能够部署前沿 AI 用于攻击性网络行动、虚假信息活动和大规模监控。如果蒸馏模型被开源，随着这些能力在任何单一政府的控制范围之外自由传播，这种风险将成倍增加。

## 蒸馏攻击与出口管制

Anthropic 一直支持出口管制，以帮助保持美国在 AI 领域的领先地位。蒸馏攻击破坏了这些管制，允许外国实验室（包括受中国共产党控制的实验室）通过其他手段缩小出口管制旨在维持的竞争优势。

如果没有察觉到这些攻击，这些实验室表面上的快速进步就会被错误地视为出口管制无效且可以通过创新来规避的证据。实际上，这些进步在很大程度上依赖于从美国模型中提取的能力，而大规模执行这种提取需要使用先进芯片。因此，蒸馏攻击强化了出口管制的合理性：限制芯片获取不仅限制了直接的模型训练，也限制了非法蒸馏的规模。

## 我们的发现

下文详述的三次蒸馏活动遵循了类似的策略，即使用欺诈账户和代理服务大规模访问 Claude，同时规避检测。提示词（prompts）的数量、结构和焦点与正常使用模式截然不同，反映了蓄意的能力提取而非合法使用。

通过 IP 地址关联、请求元数据、基础设施指标，以及在某些情况下行业合作伙伴（他们在自己的平台上观察到了相同的行为者和行为）的佐证，我们高度确信地将每次活动归因于特定的实验室。每次活动都针对 Claude 最具差异化的能力：智能体推理（agentic reasoning）、工具调用（tool use）和编程。

### DeepSeek

规模：超过 150,000 次交互

该行动针对：

- 跨多种任务的推理能力

- 基于评分标准的打分任务，使 Claude 充当强化学习的奖励模型（reward model）

- 为政策敏感查询创建规避审查的替代方案

DeepSeek 在多个账户间生成了同步流量。相同的模式、共享的支付方式和协调的时间安排表明其采用了“负载均衡”来增加吞吐量、提高可靠性并规避检测。

在一种值得注意的手法中，他们的提示词要求 Claude 想象并阐述已完成回复背后的内部推理过程，并逐步写出来——这实际上是在大规模生成思维链（chain-of-thought）训练数据。我们还观察到一些任务，其中 Claude 被用于为政治敏感查询（如关于异见人士、政党领导人或威权主义的问题）生成规避审查的替代方案，这很可能是为了训练 DeepSeek 自己的模型，引导对话避开受审查的话题。通过检查请求元数据，我们能够将这些账户追踪到该实验室的特定研究人员。

### Moonshot AI

规模：超过 340 万次交互

该行动针对：

- 智能体推理和工具调用

- 编程和数据分析

- 计算机使用智能体开发

- 计算机视觉

Moonshot（Kimi 模型）使用了跨越多种访问途径的数百个欺诈账户。多样的账户类型使得该活动更难被检测为一次协调行动。我们通过请求元数据对该活动进行了归因，这些数据与 Moonshot 高级员工的公开个人资料相匹配。在后期阶段，Moonshot 采用了更具针对性的方法，试图提取并重建 Claude 的推理轨迹。

### MiniMax

规模：超过 1300 万次交互

该行动针对：

- 智能体编程

- 工具调用与编排

我们通过请求元数据和基础设施指标将该活动归因于 MiniMax，并根据其公开的产品路线图确认了时间节点。我们在该活动仍在进行时——即在 MiniMax 发布其正在训练的模型之前——就检测到了它，这让我们对蒸馏攻击的生命周期（从数据生成到模型发布）有了前所未有的可见性。当我们在 MiniMax 活动期间发布新模型时，他们在 24 小时内就做出了转向，将近一半的流量重定向，以从我们最新的系统中捕获能力。

## 蒸馏者如何访问前沿模型

出于国家安全原因，Anthropic 目前不向中国或其位于国外的子公司提供 Claude 的商业访问权限。

为了规避这一点，实验室使用商业代理服务，这些服务大规模转售对 Claude 和其他前沿 AI 模型的访问权限。这些服务运行着我们称之为“九头蛇集群（hydra cluster）”的架构：庞大的欺诈账户网络，将流量分布在我们的 API 以及第三方云平台上。这些网络的广度意味着不存在单点故障。当一个账户被封禁时，会有一个新账户取而代之。在一个案例中，单个代理网络同时管理着超过 20,000 个欺诈账户，将蒸馏流量与无关的客户请求混合在一起，从而增加了检测难度。

一旦获得访问权限，这些实验室就会生成大量精心设计的提示词，旨在从模型中提取特定能力。其目标要么是收集高质量的回复用于直接的模型训练，要么是生成运行强化学习所需的数以万计的独特任务。区分蒸馏攻击与正常使用的是其模式。像下面这样的提示词（它近似于我们所见的大规模重复使用的类似提示词）单看可能显得毫无恶意：

但是，当该提示词的变体在数百个协同账户中出现数万次，且全部针对同一狭窄的能力时，这种模式就变得清晰了。集中在少数领域的海量数据、高度重复的结构，以及直接映射到对训练 AI 模型最有价值的内容，这些都是蒸馏攻击的标志。

## 我们如何应对

我们继续在防御方面投入巨资，使此类蒸馏攻击更难执行且更容易被识别。这些措施包括：

- 检测。我们构建了多个分类器和行为指纹识别系统，旨在识别 API 流量中的蒸馏攻击模式。这包括检测用于构建推理训练数据的思维链诱导行为。我们还构建了检测工具，用于识别大量账户间的协同活动。

- 情报共享。我们正在与其他 AI 实验室、云提供商和相关机构共享技术指标。这为了解蒸馏攻击的整体情况提供了更全面的视角。

- 访问控制。我们加强了对教育账户、安全研究项目和初创组织的验证——这些是建立欺诈账户最常被利用的途径。

- 反制措施。我们正在开发产品、API 和模型级别的安全防护措施，旨在降低模型输出对非法蒸馏的有效性，同时不降低合法客户的体验。

但没有哪家公司能单独解决这个问题。正如我们上文所述，这种规模的蒸馏攻击需要 AI 行业、云提供商和政策制定者采取协调一致的应对措施。我们发布此文，是为了向所有利益相关者公开这些证据。

## 相关内容

### 向防御者提供前沿网络安全能力

网页版 Claude Code 中内置的一项新功能 Claude Code Security 现已提供有限的研究预览版。它能扫描代码库中的安全漏洞，并提出针对性的软件补丁供人工审查，使团队能够发现并修复传统方法通常会遗漏的安全问题。

### Anthropic 与卢旺达政府签署关于 AI 在医疗和教育领域应用的谅解备忘录

### 推出 Claude Sonnet 4.6

Sonnet 4.6 在编程、智能体和大规模专业工作方面提供了前沿性能。

## 相关文档

- [[01-博客/字节笔记本/Anthropic指名道姓控诉中国3家AI 公司蒸馏攻击，马斯克反击：你自己也不干净！|Anthropic指名道姓控诉中国3家AI 公司蒸馏攻击，马斯克反击：你自己也不干净！]]；关联理由：同一事件；说明：该文基于本官方通告做中文解读并引用关键观点。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
