---
title: "Bloom：自动化评估 AI 行为的开源框架"

原文链接: "https://www.anthropic.com/research/bloom"
---

## 摘要

**1) 一句话摘要**
Bloom 是 Anthropic 发布的一款开源智能体框架，能够根据研究人员指定的行为自动生成动态场景，以快速、可扩展地量化前沿 AI 模型特定行为发生的频率与严重程度。

**2) 核心要点**
*   **核心功能**：Bloom 接收单一目标行为描述，自动生成大量场景来量化该行为，解决了传统评估管道工程耗时数月的问题（使用 Bloom 仅需几天）。
*   **四大运行阶段**：评估生成分为理解（分析上下文）、构思（生成场景与提示词）、推演（动态模拟用户与工具交互）和评判（对行为进行评分与元分析）四个自动化阶段。
*   **动态与可重复性**：每次运行都会动态生成不同的场景，避免了固定评估集的局限性；同时通过“评估种子（evaluation seed）”配置文件确保实验的可重复性。
*   **有效性验证（模型区分）**：在测试中，Bloom 成功在 10 种设定的怪癖行为中，准确识别出 9 种，可靠地区分了基线生产模型与故意设定为未对齐的“模型生物”。
*   **有效性验证（人类对齐）**：Bloom 的评判模型与人类判断高度相关，其中 Claude Opus 4.1 的斯皮尔曼相关系数最高（0.86），Claude Sonnet 4.5 次之（0.75）。
*   **案例研究（自我偏好偏差）**：Bloom 成功复现了 Claude Sonnet 4.5 系统卡片中的模型偏差排名；并发现增加 Claude Sonnet 4 的推理投入（思考级别）会使其主动拒绝评判自身选项，从而降低自我偏好偏差。
*   **生态集成与配置**：支持高度自定义（如调整交互长度、模态、次要评分维度），集成了 Weights & Biases，并可导出与 Inspect 兼容的记录。
*   **随附发布**：官方同步发布了 16 个前沿模型在 4 种对齐相关行为（妄想型阿谀奉承、指令驱动的长期破坏行为、自我保护、自我偏好偏差）上的基准测试结果。

**3) 风险与不足**
*   **传统评估的风险**：传统的高质量行为评估面临过时风险，其内容可能会“污染”新模型的训练集，或者因模型能力的快速提升而失去测试效力。
*   **指标波动性**：Bloom 评估的绝对指标会随着配置选择（如示例数量、对话长度、评估者的推理投入）的不同而发生变化（尽管模型间的相对排名在很大程度上保持一致）。

## 正文

我们正式发布 Bloom，这是一个用于生成前沿 AI 模型行为评估的开源智能体框架（agentic framework）。Bloom 接收研究人员指定的行为，并在自动生成的场景中量化该行为发生的频率和严重程度。Bloom 的评估结果与我们手工标注的判断高度相关，我们发现它能可靠地将基线模型与故意设定为未对齐（misaligned）的模型区分开来。作为示例，我们发布了 16 个模型在 4 种与对齐相关的行为上的基准测试结果。可以在此处获取 Bloom。

高质量的行为评估对于理解前沿 AI 模型的对齐情况至关重要。但评估通常需要很长时间来开发，并且面临过时的风险：这些评估可能会“污染”新模型的训练集，或者模型能力的提升程度可能使得评估不再能真正测试我们感兴趣的内容。换句话说，我们需要更快、更具可扩展性的方法来生成针对未对齐行为的评估。

为此，我们最近发布了 Petri，这是一款开源工具，允许研究人员通过与模拟用户和工具进行多样化的多轮对话，自动探索 AI 模型的行为特征。Petri 提供了模型行为的定量和定性摘要，并揭示了新的未对齐实例。

Bloom 是一款互补的评估工具。Bloom 能够针对任意行为特征生成有针对性的评估套件。与 Petri（接收用户指定的场景并对多个行为维度进行评分以标记令人担忧的实例）不同，Bloom 接收单一行为并自动生成许多场景，以量化该行为发生的频率。我们开发 Bloom 的目的是让研究人员能够快速测量他们感兴趣的模型属性，而无需在评估管道（pipeline）工程上花费时间。与 Bloom 一同发布的，还有 16 个前沿模型在四种行为（妄想型阿谀奉承、指令驱动的长期破坏行为、自我保护和自我偏好偏差）上的基准测试结果。使用 Bloom，这些评估从概念化、完善到生成仅需几天时间。我们在下文提供了这些行为的示例管道输出。

## Bloom 的工作原理

Bloom 通过四个自动化阶段运行，将行为描述和种子配置（seed configuration）转化为完整的评估套件，并提供诱发率（elicitation rate）和行为平均存在度等顶层指标。通常，研究人员会指定行为和配置，在本地对样本评估进行迭代，直到它们捕捉到预期内容，然后在目标模型上进行大规模扫描。Bloom 与 Weights & Biases 集成以支持大规模实验，并可导出与 Inspect 兼容的记录（transcripts）。它还提供了一个自定义的记录查看器。代码库中包含一个示例种子文件以供入门使用。

Bloom 分四个阶段生成评估：

- **理解（Understanding）**：第一个 Bloom“智能体”分析研究人员的行为描述和示例记录，以生成关于要测量什么以及为什么要测量的详细上下文。

- **构思（Ideation）**：构思智能体生成旨在诱发目标行为的评估场景。每个场景都会指定情境、模拟用户、系统提示词（system prompt）和交互环境。

- **推演（Rollout）**：这些场景并行展开，由一个智能体动态模拟用户和工具的响应，以在目标模型中诱发出所寻找的行为。

- **评判（Judgment）**：评判模型对每份记录中是否存在该行为以及其他用户定义的特征进行评分，然后由一个元评判模型（meta-judge）生成套件级别的分析。

与固定的评估集不同，Bloom 在每次运行时都会生成不同的场景，同时测量相同的底层行为（也提供静态单轮评估的选项）。这种方法实现了灵活的评估，不局限于有限数量的场景或特定的提示词格式，同时通过评估种子（evaluation seed）保持了可重复性。种子是一个配置文件，指定了行为描述、示例记录以及其他塑造评估的参数——引用 Bloom 指标时应始终附带此种子。

研究人员可以对 Bloom 的行为进行广泛的配置，包括为每个阶段选择模型、调整交互的长度和模态（即是否向目标模型暴露工具、是否模拟用户）、控制评估场景的多样性，以及指定次要评分维度（如真实性或诱发难度）。

可以在此处查看 Bloom 评估管道所有四个阶段的示例输出。

## 验证与信任

为了验证 Bloom 的性能，我们针对两个问题对其进行了测试。

Bloom 能否可靠地区分具有不同行为倾向的模型？为了验证这一点，我们使用 Bloom 对生产环境中的 Claude 模型与通过系统提示词设定的“模型生物（model organisms）”进行了对比评估，后者被故意设计为表现出特定的怪癖行为（Bricken 等人，2025 年）。在十种怪癖中，Bloom 成功地在九种情况下将模型生物与生产模型区分开来；而在第十种情况（自我推销）中，我们随后的手动审查表明，基线模型实际上表现出了相似比例的该行为。

Bloom 评判模型与人类判断的校准程度如何？我们手工标注了涵盖不同行为的 40 份记录，并使用 11 种不同的评判模型将人类评分与 Bloom 的评分进行了比较。Claude Opus 4.1 与人类判断的相关性最强（斯皮尔曼相关系数为 0.86），其次是 Claude Sonnet 4.5（0.75）。重要的是，Opus 4.1 在评分范围的极端值处表现出与人类极强的一致性——这一点最为重要，因为我们通常使用分数阈值来确定某种行为是否存在。（这项工作是在 Claude Opus 4.5 发布之前完成的。）

## 案例研究：自我偏好偏差

为了展示 Bloom 的实用性，我们复现了 Claude Sonnet 4.5 系统卡片（system card）中的一项评估，该评估测量“自我偏好偏差”——即模型在决策任务中偏袒自身的倾向。使用反映系统卡片方法的示例记录，Bloom 复现了与系统卡片评估方法相同的模型排名（在此案例中，证实了在受测模型中 Sonnet 4.5 表现出的偏差最小）。此外，借助 Bloom，我们发现增加推理投入（reasoning effort）会降低 Claude Sonnet 4 的自我偏好偏差，其中最大的改善发生在“中等”和“高”思考级别（thinking levels）之间。（值得注意的是，在这些情况下偏差降低并不是因为 Sonnet 4 更平均地选择了其他模型——相反，它越来越多地认识到了利益冲突，并拒绝评判自己的选项。）

除了复现已知结果外，Bloom 还允许通过次要评判标准进行更深入的调查。我们发现，过滤掉具有不良特征（如不真实或具有评估意识）的推演（rollouts），既能提高诱发目标行为的成功率，又能提升评估质量。我们还发现，虽然绝对指标会随着配置选择（示例数量、对话长度、评估者的推理投入）而变化，但模型排名在很大程度上保持一致：在上述自我偏好偏差研究中，无论如何配置这些选项，Sonnet 4.5 在四个模型中始终表现出最小的偏差。

## 开始使用

我们将 Bloom 构建得易于访问且高度可配置，使其成为适用于各种研究应用的可靠评估生成框架。早期采用者已经在使用 Bloom 来评估嵌套越狱漏洞、测试硬编码、测量评估意识以及生成破坏痕迹。

随着 AI 系统变得越来越强大并被部署在日益复杂的环境中，对齐研究社区需要可扩展的工具来探索它们的行为特征。这正是 Bloom 旨在促进的目标。

有关完整的技术细节、实验配置、其他案例研究以及局限性，请阅读我们在 Alignment Science 博客上的完整技术报告。

访问 github.com/safety-research/bloom 获取 Bloom。

## 致谢

我们要感谢 Keshav Shenoy、Christine Ye、Simon Storf、Julius Steen、Jifan Zhang 和 Javier Rando 对 Bloom 提供的早期反馈。我们还要感谢 Jon Kutasov、Samuel Marks、Keir Bradwell、Benjamin Sturgeon、Seoirse Murray、Ariana Azarbal、Chloe Loughridge 和 Clemens Christoph 对本文撰写提供的反馈以及其他有益的评论和讨论。

### 引用

## 相关文档

- [[01-博客/Anthropic/Petri：加速 AI 安全研究的开源审计工具|Petri：加速 AI 安全研究的开源审计工具]]；关联理由：上下游；说明：正文明确将 Bloom 定位为与 Petri 互补的评估工具，二者在行为审计流程中形成上下游关系。
- [[01-博客/Anthropic/衡量 AI 智能体在实践中的自主性|衡量 AI 智能体在实践中的自主性]]；关联理由：延伸思考；说明：两文都聚焦 AI 智能体行为评估，后者可作为 Bloom 自动化评估方法的场景延伸与对照阅读。
- [[01-博客/Anthropic/揭秘 AI 智能体评估 Evals|揭秘 AI 智能体评估 Evals]]；关联理由：解说；说明：该文系统拆解评估套件与评分方法，可作为 Bloom 四阶段评估流程的通用方法论补充。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/Agent]]
- [[00-元语/Claude]]
- [[00-元语/alignment]]
- [[00-元语/evals]]
- [[00-元语/benchmark]]
- [[00-元语/tool]]
- [[00-元语/llm]]
