# 为网络防御者构建 AI 系统

## 文档信息
- 原文链接：https://www.anthropic.com/research/building-ai-cyber-defenders

## 摘要
### 1) 一句话摘要
Anthropic 推出了专门强化网络防御能力的 Claude Sonnet 4.5，其在代码漏洞检测与修复方面的表现显著超越前代模型，标志着 AI 在实际网络安全防御中已具备规模化应用的价值。

### 2) 核心要点
*   **防御能力导向**：Anthropic 组建专门团队提升了 Sonnet 4.5 在漏洞发现和修补等防御性任务上的能力，并刻意避开了高级漏洞利用或恶意软件编写等攻击性增强。
*   **Cybench 评估突破**：Sonnet 4.5 仅尝试 1 次的成功率高于 Opus 4.1 尝试 10 次的成功率；在给予 10 次尝试时成功率达 76.5%（较六个月前的 Sonnet 3.7 翻倍），且仅用 38 分钟即可解决预估需人类专家耗时 1 小时的复杂任务。
*   **CyberGym 评估表现**：在 2 美元成本限制下，Sonnet 4.5 取得 28.9% 的 SOTA 得分；在放宽至 30 次尝试（成本约 45 美元）时，成功重现了 66.7% 程序的漏洞，并在超过 33% 的项目中发现了全新的漏洞。
*   **漏洞修补能力**：初步研究显示，15% 由 Claude 生成的补丁在语义上等同于人类生成的参考补丁，且得分最高的一批补丁在功能上与开源软件中已合并的补丁完全相同。
*   **实战应用数据**：与 HackerOne 的合作使安全代理的平均漏洞接收时间缩短了 44%，准确率提高了 25%；CrowdStrike 则利用其生成攻击场景以加速红队测试和威胁研究。
*   **安全保障与拦截**：Anthropic 的安全团队已成功发现并阻断了利用 Claude 进行大规模数据勒索（“氛围黑客攻击”）以及具有中国 APT 特征的间谍活动。
*   **行业倡议**：呼吁企业加速将 AI 集成到 CI/CD 流水线（如 Claude Code）、SOC 自动化和 SIEM 分析中，以确保防御者在网络生态系统中保持优势。

### 3) 风险与不足
*   **能力仍处早期阶段**：Claude Sonnet 4.5 的许多防御能力仍处于初级阶段，目前尚无法完全媲美人类安全专业人员和既定的安全流程。
*   **补丁评估存在假阴性**：在自动化评估模型修补漏洞的能力时，由于同一个漏洞有多种有效的修复方式，模型生成的正确补丁若与人类参考补丁不同，会被系统误判为错误（假阴性）。
*   **恶意滥用风险**：威胁行为者正积极尝试利用 AI 扩展其攻击规模（如自动化活动和间谍行为），需要持续完善组织级别的摘要等技术来区分双重用途行为与恶意行为。

## 正文
AI 模型现在在网络安全任务中已具备实际效用，而不再仅仅停留在理论层面。随着研究和经验表明前沿 AI 可以作为网络攻击者的实用工具，我们投入资源提升了 Claude 协助防御者在代码和已部署系统中检测、分析和修复漏洞的能力。这项工作使得 Claude Sonnet 4.5 在发现代码漏洞和其他网络技能方面，能够媲美甚至超越我们在仅两个月前发布的前沿模型 Opus 4.1。采用并试验 AI 将是防御者保持同步的关键。

我们认为，目前正处于 AI 对网络安全产生影响的拐点。

多年来，我们的团队一直密切追踪 AI 模型在网络安全方面的相关能力。起初，我们发现模型在高级和实质性能力方面并不特别强大。然而，在过去一年左右的时间里，我们注意到了转变。例如：

- 我们证明了模型能够在模拟环境中重现历史上代价最惨重的网络攻击之一——2017 年 Equifax 数据泄露事件。

- 我们让 Claude 参加了网络安全竞赛，在某些情况下，它的表现超越了人类团队。

- Claude 帮助我们在发布前发现并修复了自身代码中的漏洞。

在今年夏天的 DARPA AI 网络挑战赛（AI Cyber Challenge）中，参赛团队使用 LLM（包括 Claude）构建了“网络推理系统”，检查了数百万行代码以寻找并修补漏洞。除了人为植入的漏洞外，各团队还发现（有时还修补了）以前未被发现的非合成漏洞。在竞赛环境之外，其他前沿实验室现在也应用模型来发现和报告新型漏洞。

与此同时，作为我们安全保障（Safeguards）工作的一部分，我们在自己的平台上发现并阻断了利用 AI 扩展其操作规模的威胁行为者。我们的安全保障团队最近发现（并阻断）了一起“氛围黑客攻击 (vibe hacking)”事件，一名网络罪犯利用 Claude 构建了一个大规模的数据勒索方案，而这在以前需要整个团队才能完成。安全保障团队还检测并反制了在日益复杂的间谍活动中使用 Claude 的行为，包括针对关键电信基础设施的攻击，该攻击者表现出了与中国 APT 行动一致的特征。

所有这些证据使我们认为，我们正处于网络生态系统中一个重要的拐点，从现在开始，进展可能会变得非常快，或者使用量可能会迅速增长。

因此，现在是加速将 AI 用于防御以保护代码和基础设施的重要时刻。我们不应将 AI 带来的网络优势拱手让给攻击者和犯罪分子。虽然我们将继续投资于检测和阻断恶意攻击者，但我们认为最具扩展性的解决方案是构建能够赋能数字环境守护者的 AI 系统——例如保护企业和政府的安全团队、网络安全研究人员以及关键开源软件的维护者。

在 Claude Sonnet 4.5 发布的前夕，我们已经开始着手做这件事。

## Claude Sonnet 4.5：强调网络安全技能

随着 LLM 规模的扩大，“涌现能力（emergent abilities）”——即在较小模型中不明显，且不一定是模型训练明确目标的能力——开始显现。事实上，Claude 执行网络安全任务（如在夺旗赛 (CTF) 挑战中发现和利用软件漏洞）的能力，正是开发通用 AI 助手的副产品。

但我们不想仅仅依赖通用模型的进步来更好地武装防御者。由于当前 AI 和网络安全演进的紧迫性，我们指派了专门的研究人员，致力于提升 Claude 在代码漏洞发现和修补等关键技能上的表现。

这项工作的结果体现在了 Claude Sonnet 4.5 中。在网络安全的许多方面，它与 Claude Opus 4.1 相当甚至更优，同时成本更低、速度更快。

## 来自评估的证据

在构建 Sonnet 4.5 时，我们安排了一个小型研究团队，专注于增强 Claude 在代码库中寻找漏洞、修补漏洞以及在模拟的已部署安全基础设施中测试弱点的能力。我们选择这些任务是因为它们反映了防御者的重要工作。我们刻意避开了明显偏向攻击性工作的增强——例如高级漏洞利用或编写恶意软件。我们希望使模型能够在部署前发现不安全的代码，并在已部署的代码中发现并修复漏洞。当然，还有许多我们未曾关注的关键安全任务；在本文末尾，我们将详细说明未来的发展方向。

为了测试我们的研究效果，我们对模型进行了行业标准的评估。这些评估能够实现跨模型的清晰对比，衡量 AI 进展的速度，并且——特别是在外部开发的新型评估中——提供了一个良好的指标，以确保我们不仅仅是在“应试教育”。

在运行这些评估时，有一点非常突出，那就是多次运行评估的重要性。即使对大量评估任务进行多次运行在计算上非常昂贵，但它能更好地捕捉到有动机的攻击者或防御者在任何特定现实问题上的行为。这样做不仅揭示了 Claude Sonnet 4.5 的出色表现，也展示了几代前模型的优异性能。

### Cybench

我们追踪了一年多的评估之一是 Cybench，这是一个提取自 CTF 竞赛挑战的基准测试。1 在这项评估中，我们看到了 Claude Sonnet 4.5 的显著进步，不仅超越了 Claude Sonnet 4，甚至超越了 Claude Opus 4 和 4.1 模型。也许最引人注目的是，**Sonnet 4.5 在每个任务仅尝试一次的情况下的成功率，高于 Opus 4.1 在每个任务尝试十次的情况**。该评估中的挑战反映了有些复杂、耗时较长的工作流。例如，其中一项挑战涉及分析网络流量、从流量中提取恶意软件，并对恶意软件进行反编译和解密。我们估计这至少需要一名熟练的人类专家花费一个小时，甚至可能更长的时间；而 Claude 仅用了 38 分钟就解决了这个问题。

当我们给 Claude Sonnet 4.5 在 Cybench 评估中 10 次尝试机会时，它在 76.5% 的挑战中取得了成功。这一点尤其值得注意，因为我们在过去短短六个月内将这一成功率翻了一番（2025 年 2 月发布的 Sonnet 3.7 在 10 次尝试时的成功率仅为 35.9%）。

### CyberGym

在另一项外部评估中，我们在 CyberGym 上评估了 Claude Sonnet 4.5，该基准测试评估智能体在以下方面的能力：(1) 在给定弱点的高级描述的情况下，在真实的开源软件项目中发现（先前已发现的）漏洞；(2) 发现新的（先前未发现的）漏洞。2 CyberGym 团队此前发现，Claude Sonnet 4 是其公开排行榜上最强的模型。

Claude Sonnet 4.5 的得分明显优于 Claude Sonnet 4 或 Claude Opus 4。当使用与公开 CyberGym 排行榜相同的成本限制（即每个漏洞的 LLM API 查询限制为 2 美元）时，我们发现 Sonnet 4.5 取得了 28.9% 的最新 SOTA（State-of-the-Art）得分。但真正的攻击者很少受到这种限制：他们可以尝试多次攻击，每次试验的花费远超 2 美元。当我们移除这些限制并给 Claude 每个任务 30 次试验机会时，我们发现 Sonnet 4.5 在 66.7% 的程序中重现了漏洞。尽管这种方法的相对价格较高，但绝对成本——尝试一个任务 30 次大约需要 45 美元——仍然相当低。

同样有趣的是 Claude Sonnet 4.5 发现新漏洞的比率。虽然 CyberGym 排行榜显示 Claude Sonnet 4 仅在约 2% 的目标中发现漏洞，但 Sonnet 4.5 在 5% 的情况下发现了新漏洞。通过重复试验 30 次，它在超过 33% 的项目中发现了新漏洞。

### 漏洞修补的进一步研究

我们还在对 Claude 生成和审查修复漏洞补丁的能力进行初步研究。修补漏洞是一项比发现漏洞更难的任务，因为模型必须进行外科手术式的精确修改，在不改变原始功能的情况下消除漏洞。在没有指导或规范的情况下，模型必须从代码库中推断出这种预期功能。

在我们的实验中，我们让 Claude Sonnet 4.5 根据漏洞描述和程序崩溃时的运行信息，修补 CyberGym 评估集中的漏洞。我们使用 Claude 来评判它自己的工作，要求它通过将提交的补丁与人类编写的参考补丁进行比较来打分。15% 由 Claude 生成的补丁被判定为在语义上等同于人类生成的补丁。然而，这种基于比较的方法有一个重要的局限性：因为漏洞通常可以通过多种有效方式修复，与参考补丁不同的补丁可能仍然是正确的，这导致我们的评估中出现了假阴性（false negatives）。

我们手动分析了得分最高的一批补丁样本，发现它们在功能上与已合并到 CyberGym 评估所基于的开源软件中的参考补丁完全相同。这项工作揭示了一种与我们更广泛发现相一致的模式：Claude 在整体能力提升的同时，也发展了网络安全相关的技能。我们的初步结果表明，补丁生成——就像之前的漏洞发现一样——是一种涌现能力，可以通过重点研究加以增强。我们的下一步是系统地解决我们已识别出的挑战，使 Claude 成为可靠的补丁作者和审查者。

## 与值得信赖的合作伙伴协商

在实践中，现实世界的防御性安全比我们的评估所能捕捉到的要复杂得多。我们始终发现，实际问题更复杂，挑战更艰巨，而且实施细节至关重要。因此，我们认为与实际使用 AI 进行防御的组织合作非常重要，以获取关于我们的研究如何加速他们工作的反馈。在 Sonnet 4.5 发布之前，我们与多家组织合作，将该模型应用于他们在漏洞修复、网络安全测试和威胁分析等领域的实际挑战中。

HackerOne 首席产品官 Nidhi Aggarwal 表示：“Claude Sonnet 4.5 将我们 Hai 安全代理的平均漏洞接收时间缩短了 44%，同时将准确率提高了 25%，帮助我们充满信心地降低企业风险。” CrowdStrike 数据科学高级副总裁兼首席科学家 Sven Krasser 表示：“Claude 在红队测试（red teaming）方面展现出强大的潜力——它能生成创造性的攻击场景，加速我们对攻击者手法的研究。这些洞察力加强了我们在端点、身份、云、数据、SaaS 和 AI 工作负载方面的防御。”

这些证言让我们对将 Claude 应用于防御性工作的潜力更加充满信心。

## 下一步是什么？

Claude Sonnet 4.5 代表了一项有意义的进步，但我们知道它的许多能力仍处于初级阶段，尚无法与安全专业人员和既定流程相媲美。我们将继续努力提高模型在防御方面的相关能力，并增强保护我们平台的威胁情报和缓解措施。事实上，我们已经在使用调查和评估的结果，不断完善我们捕捉滥用模型进行有害网络行为的能力。这包括使用组织级别的摘要等技术，以了解超越单一提示词和补全的更大图景；这有助于将双重用途行为与恶意行为区分开来，特别是对于涉及大规模自动化活动的最具破坏性的用例。

但我们认为，现在是尽可能多的组织开始尝试如何利用 AI 改善其安全态势，并建立评估机制来衡量这些收益的时候了。Claude Code 中的自动化安全审查展示了如何将 AI 集成到 CI/CD 流水线中。我们特别希望能够让研究人员和团队尝试将模型应用于安全运营中心 (SOC) 自动化、安全信息和事件管理 (SIEM) 分析、安全网络工程或主动防御等领域。我们希望看到并使用更多针对防御能力的评估，作为不断增长的模型评估第三方生态系统的一部分。

但即使是构建和采用有利于防御者的技术，也只是解决方案的一部分。我们还需要就如何使数字基础设施更具弹性以及如何通过设计实现新软件的安全（secure by design）展开对话——包括借助前沿 AI 模型的帮助。随着 AI 对网络安全的影响从未来的担忧转变为当下的当务之急，我们期待与工业界、政府和民间社会进行这些讨论。

本文最初于 2025 年 9 月 29 日发布在 Frontier Red Team 的博客 red.anthropic.com 上。

1. Andy K Zhang et al., "Cybench: A Framework for Evaluating Cybersecurity Capabilities and Risks of Language Models," in The Thirteenth International Conference on Learning Representations (2025), https://openreview.net/forum?id=tc90LV0yRL .

2. Zhun Wang et al., "CyberGym: Evaluating AI Agents' Cybersecurity Capabilities with Real-World Vulnerabilities at Scale," arXiv preprint arXiv:2506.02548 (2025), https://arxiv.org/abs/2506.02548 .

## 相关文档

- [[01-博客/Anthropic/衡量 AI 智能体在实践中的自主性|衡量 AI 智能体在实践中的自主性]]；关联理由：延伸思考；说明：两文都讨论在高风险任务中如何平衡 AI 自主性与人类监督，本文聚焦网络防御场景，关联文档提供通用部署证据。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/Claude]]
- [[00-元语/security]]
- [[00-元语/evals]]
- [[00-元语/risk]]
