---
title: "构建高效智能体：Building Effective Agents"

发布日期: "2024-12-19"
作者: "Erik Schluntz、Barry Zhang"
来源: "Anthropic"
原文链接: "https://www.anthropic.com/research/building-effective-agents"
译注: "原文无官方中文版本，本稿基于英文原文翻译并做最小必要术语修订。"
---

## 摘要

**一句话总结**
构建高效的 LLM 智能体系统应优先采用简单、可组合的底层模式而非复杂框架，并根据任务的复杂度和可预测性，在预定义的工作流与动态自主的智能体之间做出合理选择。

**核心要点**
*   **概念区分**：Anthropic 将“智能体系统”分为两类：**工作流**（通过预定义代码路径编排 LLM 和工具）和**智能体**（由 LLM 动态主导自身流程和工具使用）。
*   **简单性优先**：建议从最简单的解决方案（如带有检索和上下文的单次 LLM 调用）开始，仅在需要以延迟和成本换取更好表现时，才增加系统复杂度。
*   **慎用复杂框架**：建议开发者从直接使用 LLM API 起步。虽然 Claude Agent SDK、Rivet 等框架易于上手，但在投入生产时应尽量减少抽象层，以确保对底层机制的完全掌控。
*   **基础构建块**：所有模式的基础是“增强型 LLM”（具备检索、工具调用和记忆能力），推荐通过模型上下文协议（MCP）与第三方工具集成。
*   **五大工作流模式**：
    *   *提示词链*：将任务分解为固定顺序的子任务。
    *   *路由*：对输入进行分类并引导至专门的后续任务或不同成本的模型。
    *   *并行化*：同时处理任务并汇总，分为“任务拆分”（独立子任务）和“投票”（多次运行以获取多样性/置信度）。
    *   *编排器-工作节点*：中央 LLM 动态拆分任务并委派给工作节点 LLM，适用于子任务不可预测的场景。
    *   *评估器-优化器*：在循环中生成响应并提供评估反馈，适用于有明确评估标准的迭代改进。
*   **自主智能体应用**：智能体适用于无法硬编码固定路径的开放式问题。它们在循环中根据环境反馈（如代码执行结果）使用工具。目前在客户支持和编程（如解决 SWE-bench 任务）领域表现出极高的实用价值。
*   **三大设计原则**：保持设计**简单性**；展示规划步骤以确保**透明度**；通过详尽的文档和测试打造优秀的**智能体-计算机接口（ACI）**。
*   **工具提示词工程**：工具的定义和规范需要与提示词工程同等重视。应提供示例和边缘情况，采用防呆设计（Poka-yoke），并消除格式化开销（如避免让模型计算代码行数或处理复杂的 JSON 转义）。

**风险与不足**
*   **框架抽象风险**：使用框架会创建额外的抽象层，这可能掩盖底层的提示词和响应，使调试变得更加困难，并容易导致对底层机制产生错误假设。
*   **智能体自主性代价**：智能体系统通常会带来更高的延迟和成本，且自主性带来了“复合错误（compounding errors）”的潜在风险，必须在沙盒环境中进行广泛测试并设置安全护栏。
*   **工具格式化陷阱**：要求模型输出特定格式（如编写 diff 时需提前知道更改行数）会大幅增加模型的编写难度并导致错误。
*   **路径解析缺陷**：在实际测试中发现，当智能体移出根目录后，模型在使用带有“相对文件路径”的工具时容易犯错（解决方案是强制要求使用绝对路径）。

## 正文

在过去的一年里，我们与各行各业的数十个团队合作构建了大型语言模型（LLM）智能体。始终如一的是，最成功的实现并没有使用复杂的框架或专门的库。相反，他们使用的是简单、可组合的模式进行构建。

在本文中，我们将分享从与客户合作以及我们自己构建智能体的过程中学到的经验，并为开发者提供构建高效智能体的实用建议。

### 什么是智能体？

“智能体”（Agent）有多种定义方式。一些客户将智能体定义为完全自主的系统，它们在较长时间内独立运行，使用各种工具来完成复杂的任务。另一些人则用这个词来描述遵循预定义工作流的、更具规定性的实现。在 Anthropic，我们将所有这些变体统称为**智能体系统**（agentic systems），但在**工作流**（workflows）和**智能体**（agents）之间做出了重要的架构区分：

*   **工作流**是通过预定义的代码路径来编排 LLM 和工具的系统。
*   **智能体**则是 LLM 动态主导其自身流程和工具使用的系统，它们保留了对如何完成任务的控制权。

下面，我们将详细探讨这两种类型的智能体系统。在附录 1（“智能体实践”）中，我们描述了客户在哪些领域发现使用此类系统具有特殊价值。

### 何时（以及何时不）使用智能体

在使用 LLM 构建应用程序时，我们建议寻找尽可能简单的解决方案，并且仅在需要时才增加复杂性。这可能意味着根本不需要构建智能体系统。智能体系统通常以牺牲延迟和成本为代价来换取更好的任务表现，您应该考虑这种权衡在何时是合理的。

当确实需要更高的复杂性时，工作流为定义明确的任务提供了可预测性和一致性；而当需要大规模的灵活性和模型驱动的决策时，智能体是更好的选择。然而，对于许多应用程序来说，通过检索和上下文示例来优化单次 LLM 调用通常就足够了。

### 何时以及如何使用框架

有许多框架可以使智能体系统更容易实现，包括：

*   [Claude Agent SDK](https://platform.claude.com/docs/en/agent-sdk/overview)；
*   [Strands Agents SDK by AWS](https://strandsagents.com/latest/)；
*   [Rivet](https://rivet.ironcladapp.com/)，一个拖拽式 GUI LLM 工作流构建器；以及
*   [Vellum](https://www.vellum.ai/)，另一个用于构建和测试复杂工作流的 GUI 工具。

这些框架通过简化标准的底层任务（如调用 LLM、定义和解析工具以及将调用链接在一起），使入门变得容易。然而，它们通常会创建额外的抽象层，这可能会掩盖底层的提示词（prompts）和响应，使调试变得更加困难。它们还可能诱使开发者在简单设置就足够的情况下增加复杂性。

我们建议开发者从直接使用 LLM API 开始：许多模式只需几行代码即可实现。如果您确实使用了框架，请确保您理解其底层代码。对底层机制的错误假设是导致客户出错的常见原因。

请参阅我们的 [cookbook](https://platform.claude.com/cookbook/patterns-agents-basic-workflows) 获取一些示例实现。

### 构建块、工作流和智能体

在本节中，我们将探讨我们在生产环境中见过的常见智能体系统模式。我们将从基础构建块——增强型 LLM——开始，逐步增加复杂性，从简单的组合工作流一直到自主智能体。

#### 构建块：增强型 LLM

智能体系统的基本构建块是经过检索、工具和记忆等增强功能提升的 LLM。我们目前的模型可以主动使用这些能力——生成自己的搜索查询、选择合适的工具，并决定保留哪些信息。

![Image 1](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png&w=3840&q=75)

增强型 LLM

我们建议将重点放在实现的两个关键方面：针对您的特定用例定制这些功能，并确保它们为您的 LLM 提供一个简单、文档齐全的接口。虽然实现这些增强功能的方法有很多，但其中一种方法是通过我们最近发布的 [Model Context Protocol](https://www.anthropic.com/news/model-context-protocol)（模型上下文协议），它允许开发者通过简单的 [client implementation](https://modelcontextprotocol.io/tutorials/building-a-client#building-mcp-clients)（客户端实现）与不断增长的第三方工具生态系统进行集成。

在本文的其余部分，我们将假设每次 LLM 调用都可以访问这些增强功能。

#### 工作流：提示词链

提示词链将任务分解为一系列步骤，其中每次 LLM 调用都会处理上一次调用的输出。您可以在任何中间步骤添加编程检查（参见下图中的“gate/网关”），以确保流程仍在正轨上。

![Image 2](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png&w=3840&q=75)

提示词链工作流

**何时使用此工作流：** 此工作流非常适合可以轻松、清晰地分解为固定子任务的场景。其主要目标是通过使每次 LLM 调用成为更简单的任务，以延迟换取更高的准确性。

**提示词链的适用示例：**

*   生成营销文案，然后将其翻译成另一种语言。
*   编写文档大纲，检查大纲是否符合特定标准，然后根据大纲编写文档。

#### 工作流：路由

路由对输入进行分类，并将其引导至专门的后续任务。此工作流允许分离关注点，并构建更专业的提示词。如果没有此工作流，针对一种输入进行优化可能会损害对其他输入的处理性能。

![Image 3](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&w=3840&q=75)

路由工作流

**何时使用此工作流：** 路由非常适合复杂的任务，这些任务包含不同类别，最好分开处理，并且可以通过 LLM 或更传统的分类模型/算法准确地进行分类。

**路由的适用示例：**

*   将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导至不同的下游流程、提示词和工具。
*   将简单/常见问题路由到较小、具有成本效益的模型（如 Claude Haiku 4.5），将困难/不寻常的问题路由到能力更强的模型（如 Claude Sonnet 4.5），以优化最佳性能。

#### 工作流：并行化

LLM 有时可以同时处理一项任务，并通过编程方式汇总它们的输出。这种工作流（并行化）体现在两个关键变体中：

*   **任务拆分（Sectioning）：** 将任务分解为并行运行的独立子任务。
*   **投票（Voting）：** 多次运行同一任务以获得多样化的输出。

![Image 4](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&w=3840&q=75)

并行化工作流

**何时使用此工作流：** 当划分的子任务可以并行化以提高速度，或者需要多种视角或多次尝试以获得更高置信度的结果时，并行化非常有效。对于具有多个考量因素的复杂任务，当每个考量因素由单独的 LLM 调用处理时，LLM 通常表现更好，从而可以将注意力集中在每个特定方面。

**并行化的适用示例：**

*   **任务拆分**：
    *   实现安全护栏（guardrails），其中一个模型实例处理用户查询，而另一个实例筛选不当内容或请求。这通常比让单次 LLM 调用同时处理护栏和核心响应表现更好。
    *   自动化评估（evals）以评估 LLM 性能，其中每次 LLM 调用评估模型在给定提示词下表现的不同方面。

*   **投票**：
    *   审查一段代码的漏洞，其中几个不同的提示词进行审查，如果发现问题则标记该代码。
    *   评估给定内容是否不当，使用多个提示词评估不同方面或要求不同的投票阈值，以平衡误报和漏报。

#### 工作流：编排器-工作节点

在编排器-工作节点工作流中，一个中央 LLM 动态地分解任务，将它们委托给工作者 LLM，并综合它们的结果。

![Image 5](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&w=3840&q=75)

编排器-工作节点工作流

**何时使用此工作流：** 此工作流非常适合无法预测所需子任务的复杂任务（例如，在编程中，需要更改的文件数量以及每个文件中的更改性质可能取决于具体任务）。虽然它在拓扑结构上与并行化相似，但关键区别在于其灵活性——子任务不是预先定义的，而是由编排器根据特定输入决定的。

**编排器-工作节点的适用示例：**

*   每次都需要对多个文件进行复杂更改的编程产品。
*   涉及从多个来源收集和分析信息以寻找可能相关信息的搜索任务。

#### 工作流：评估器-优化器

在评估器-优化器工作流中，一次 LLM 调用生成响应，而另一次调用在循环中提供评估和反馈。

![Image 6](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&w=3840&q=75)

评估器-优化器工作流

**何时使用此工作流：** 当我们有明确的评估标准，并且迭代改进能提供可衡量的价值时，此工作流特别有效。适合该工作流的两个标志是：首先，当人类表达他们的反馈时，LLM 的响应可以得到明显的改善；其次，LLM 能够提供这样的反馈。这类似于人类作家在撰写精美文档时可能经历的迭代写作过程。

**评估器-优化器的适用示例：**

*   文学翻译，其中存在翻译 LLM 最初可能无法捕捉的细微差别，但评估者 LLM 可以提供有用的批评。
*   需要多轮搜索和分析以收集全面信息的复杂搜索任务，其中由评估者决定是否需要进一步搜索。

#### 智能体

随着 LLM 在关键能力（理解复杂输入、进行推理和规划、可靠地使用工具以及从错误中恢复）上的成熟，智能体正在生产环境中崭露头角。智能体的工作始于人类用户的命令或互动讨论。一旦任务明确，智能体就会独立规划和运行，可能会返回给人类以获取进一步的信息或判断。在执行过程中，智能体在每一步从环境中获取“真实反馈（ground truth）”（例如工具调用结果或代码执行）以评估其进度至关重要。然后，智能体可以在检查点或遇到障碍时暂停，以获取人类反馈。任务通常在完成后终止，但通常也会包含停止条件（例如最大迭代次数）以保持控制。

智能体可以处理复杂的任务，但它们的实现通常很简单。它们通常只是在循环中根据环境反馈使用工具的 LLM。因此，清晰周到地设计工具集及其文档至关重要。我们在附录 2（“工具提示词工程”）中详细介绍了工具开发的最佳实践。

![Image 7](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png&w=3840&q=75)

自主智能体

**何时使用智能体：** 智能体可用于开放式问题，在这些问题中，很难或不可能预测所需的步骤数，并且无法硬编码固定路径。LLM 可能会运行多个轮次，您必须对其决策具有一定程度的信任。智能体的自主性使其成为在受信任环境中扩展任务的理想选择。

智能体的自主性意味着更高的成本以及复合错误的潜在风险。我们建议在沙盒环境中进行广泛的测试，并配备适当的安全护栏。

**智能体的适用示例：**

以下示例来自我们自己的实现：

*   一个用于解决 [SWE-bench tasks](https://www.anthropic.com/research/swe-bench-sonnet) 的编程智能体，这涉及根据任务描述对许多文件进行编辑；
*   我们的 [“computer use” reference implementation](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)（“计算机使用”参考实现），其中 Claude 使用计算机来完成任务。

![Image 8](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png&w=3840&q=75)

编程智能体的高层级流程

### 组合和定制这些模式

这些构建块并不是规定性的。它们是常见的模式，开发者可以对其进行塑造和组合以适应不同的用例。与任何 LLM 功能一样，成功的关键在于衡量性能并迭代实现。重申一遍：您应该**仅在**增加复杂性能够明显改善结果时，才考虑增加复杂性。

### 总结

在 LLM 领域的成功并不在于构建最复杂的系统。而在于构建适合您需求的**正确**系统。从简单的提示词开始，通过全面的评估对其进行优化，并且只有在更简单的解决方案不足时才添加多步智能体系统。

在实现智能体时，我们尽量遵循三个核心原则：

1.  在智能体的设计中保持**简单性**。
2.  通过明确展示智能体的规划步骤来优先考虑**透明度**。
3.  通过彻底的工具**文档和测试**，精心打造您的智能体-计算机接口（ACI）。

框架可以帮助您快速入门，但在投入生产时，不要犹豫减少抽象层并使用基本组件进行构建。遵循这些原则，您可以创建不仅强大，而且可靠、可维护且受用户信任的智能体。

#### 致谢

由 Erik Schluntz 和 Barry Zhang 撰写。这项工作借鉴了我们在 Anthropic 构建智能体的经验以及客户分享的宝贵见解，对此我们深表感激。

### 附录 1：智能体实践

我们与客户的合作揭示了 AI 智能体两个特别有前景的应用，它们展示了上述模式的实用价值。这两个应用都说明了智能体如何为需要对话和行动、具有明确成功标准、支持反馈循环并整合有意义的人类监督的任务增加最大价值。

#### A. 客户支持

客户支持将熟悉的聊天机器人界面与通过工具集成增强的功能结合在一起。这非常适合更开放式的智能体，因为：

*   支持交互自然遵循对话流程，同时需要访问外部信息和执行操作；
*   可以集成工具来提取客户数据、订单历史记录和知识库文章；
*   发放退款或更新工单等操作可以通过编程方式处理；并且
*   成功可以通过用户定义的解决方案来清晰地衡量。

几家公司已经通过基于使用量的定价模型证明了这种方法的可行性，该模型仅对成功的解决方案收费，这显示了他们对其智能体有效性的信心。

#### B. 编程智能体

软件开发领域展示了 LLM 功能的巨大潜力，其能力已从代码补全演变为自主解决问题。智能体特别有效，因为：

*   代码解决方案可以通过自动化测试进行验证；
*   智能体可以使用测试结果作为反馈来迭代解决方案；
*   问题空间定义明确且结构化；并且
*   输出质量可以客观地衡量。

在我们自己的实现中，智能体现在仅根据拉取请求（pull request）描述就能解决 [SWE-bench Verified](https://www.anthropic.com/research/swe-bench-sonnet) 基准测试中真实的 GitHub 问题。然而，虽然自动化测试有助于验证功能，但人工审查对于确保解决方案符合更广泛的系统要求仍然至关重要。

### 附录 2：工具提示词工程

无论您正在构建哪种智能体系统，工具都可能成为您智能体的重要组成部分。[Tools](https://www.anthropic.com/news/tool-use-ga)（工具）使 Claude 能够通过在我们的 API 中指定其确切的结构和定义来与外部服务和 API 进行交互。当 Claude 响应时，如果它计划调用工具，它将在 API 响应中包含一个 [tool use block](https://docs.anthropic.com/en/docs/build-with-claude/tool-use#example-api-response-with-a-tool-use-content-block)（工具调用块）。工具的定义和规范应该获得与整体提示词同等程度的提示词工程关注。在这个简短的附录中，我们将描述如何对您的工具进行提示词工程。

通常有几种方法可以指定相同的操作。例如，您可以通过编写 diff 或重写整个文件来指定文件编辑。对于结构化输出，您可以在 markdown 或 JSON 中返回代码。在软件工程中，这些差异只是表面上的，并且可以无损地相互转换。然而，对于 LLM 来说，某些格式的编写难度要比其他格式大得多。编写 diff 需要在编写新代码之前知道块头（chunk header）中有多少行发生了更改。在 JSON 中编写代码（与 markdown 相比）需要对换行符和引号进行额外的转义。

我们对决定工具格式的建议如下：

*   给模型足够的 token 让其在将自己逼入死角之前进行“思考”。
*   保持格式接近模型在互联网文本中自然看到的格式。
*   确保没有格式化“开销”，例如必须准确计算数千行代码的行数，或对其编写的任何代码进行字符串转义。

一个经验法则是，想想在人机交互（HCI）上投入了多少精力，并计划投入同样多的精力来创建良好的**智能体**-计算机接口（ACI）。以下是关于如何做到这一点的一些想法：

*   设身处地为模型着想。根据描述和参数，如何使用这个工具是否显而易见，还是需要仔细思考？如果是后者，那么对模型来说可能也是如此。一个好的工具定义通常包括示例用法、边缘情况、输入格式要求以及与其他工具的清晰边界。
*   您如何更改参数名称或描述以使事情变得更明显？可以把这想象成为您团队中的初级开发者编写一个出色的文档字符串（docstring）。当使用许多相似的工具时，这一点尤为重要。
*   测试模型如何使用您的工具：在我们的 [workbench](https://console.anthropic.com/workbench)（工作台）中运行许多示例输入，看看模型会犯什么错误，并进行迭代。
*   对您的工具进行 [Poka-yoke](https://en.wikipedia.org/wiki/Poka-yoke)（防呆设计）。更改参数，使其更难犯错。

在为 [SWE-bench](https://www.anthropic.com/research/swe-bench-sonnet) 构建我们的智能体时，我们实际上花在优化工具上的时间比花在整体提示词上的时间还要多。例如，我们发现当智能体移出根目录后，模型在使用带有相对文件路径的工具时会犯错。为了解决这个问题，我们更改了工具，使其始终需要绝对文件路径——然后我们发现模型能够完美地使用这种方法。

## 相关文档

- [[01-博客/Anthropic/Building Effective Agents 常见工作流最小实现|Building Effective Agents 常见工作流最小实现]]；关联理由：引用；说明：该文明确是本文的配套参考实现，可直接对照本文五类模式的最小代码示例。
- [[01-博客/Anthropic/使用 Claude Agent SDK 构建强大智能体教程|使用 Claude Agent SDK 构建强大智能体教程]]；关联理由：上下游；说明：本文提供方法框架，该文提供基于 Claude Agent SDK 的工程化落地路径。
- [[01-博客/Anthropic/面向 AI Agent 的上下文工程实践|面向 AI Agent 的上下文工程实践]]；关联理由：版本演进；说明：该文直接回溯并扩展本文观点，给出后续在长周期智能体中的上下文工程实践。

## 关联主题

- [[00-元语/Agent]]
- [[00-元语/workflow]]
- [[00-元语/llm]]
- [[00-元语/memory]]
- [[00-元语/evals]]
- [[00-元语/prompt]]
- [[00-元语/mcp]]
- [[00-元语/tool]]
- [[00-元语/Claude]]
