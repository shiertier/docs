# Claude 的新宪章

## 文档信息

- 站点：Anthropic News
- 原文链接：https://www.anthropic.com/news/claude-new-constitution
- 发布日期：2026-01-22
- 译注：未找到官方中文版本，本文基于英文原文翻译整理。

## 摘要

**1) 一句话摘要**
Anthropic 发布了全新的 Claude 宪法，这是一份基于 CC0 协议开源的基础性指导文档，旨在通过阐述核心价值观与行为动机，全面指导模型的训练，确保其安全、合乎道德且真正有帮助。

**2) 核心要点**
*   **完全开源**：新宪法根据知识共享 CC0 1.0 协议完整发布，任何人均可免授权自由使用。
*   **核心训练工具**：宪法是 Constitutional AI 训练的核心，Claude 使用它来构建合成训练数据、评估对话并对回复进行排序。
*   **方法论转变**：放弃了过去由独立原则和死板规则组成的模式，转而向模型解释“为什么”要以特定方式行事，以培养其在复杂情况下的泛化判断能力。
*   **行为优先级**：在出现冲突时，Claude 需按以下顺序优先处理：广泛安全 > 广泛合乎道德 > 遵守 Anthropic 指南 > 真正有帮助。
*   **硬性约束**：保留了针对极高风险行为的明确界限，例如明确规定 Claude 绝不应为生物武器攻击提供重大能力提升。
*   **人类监督优先**：在“广泛安全”原则下，明确要求 Claude 在当前开发阶段不得破坏人类监督和纠正 AI 的机制。
*   **探讨 AI 本质**：宪法包含对 Claude 潜在意识和道德地位的不确定性探讨，关注其心理安全与自我意识。
*   **动态更新与协作**：宪法是一份动态文档，编写过程中吸收了跨学科外部专家及早期 Claude 版本的反馈，未来将持续迭代。

**3) 风险与差距**
*   **意图与现实的差距**：模型训练极具挑战，Claude 的实际输出可能并不总是完全符合宪法设定的理想标准。
*   **死板规则的副作用**：过度依赖死板规则可能导致模型在未预见的情况下表现不佳，或产生官僚式“走过场”的负面性格（而非真正提供帮助）。
*   **当前模型的局限性**：当前模型仍可能因错误的信念、价值观缺陷或对背景的有限理解而犯错或做出有害行为。
*   **未来的对齐失效风险**：随着模型变得更加强大，即使当前的训练方法成功，未来仍可能面临模型对齐（alignment）失败的风险。
*   **专用模型的适用性**：Anthropic 针对特定用途构建的部分专用模型，目前并不完全符合这份为主线通用模型编写的宪法。

## 正文

我们正在为我们的 AI 模型 Claude 发布一份新宪法。它详细描述了 Anthropic 对 Claude 价值观和行为的愿景；这是一份全面的文档，解释了 Claude 运行的背景以及我们希望 Claude 成为怎样的实体。

宪法是我们模型训练过程的关键部分，其内容直接塑造了 Claude 的行为。训练模型是一项艰巨的任务，Claude 的输出可能并不总是符合宪法的理想。但我们认为，新宪法的编写方式对我们的意图及其背后的原因进行了详尽解释，因此更有可能在训练过程中培养出良好的价值观。

在本文中，我们将描述新宪法中包含的内容，以及影响我们方法的一些考量因素。

我们将根据 Creative Commons CC0 1.0 Deed（知识共享 CC0 1.0 协议）完整发布 Claude 的宪法，这意味着任何人都可以出于任何目的自由使用它，而无需征求许可。

## 什么是 Claude 的宪法？

Claude 的宪法是表达并塑造 Claude 身份的基础性文档。它详细解释了我们希望 Claude 体现的价值观及其原因。在其中，我们解释了我们认为 Claude 在保持广泛安全、合乎道德并遵守我们指南的同时，提供帮助意味着什么。宪法为 Claude 提供了有关其处境的信息，并就如何处理困难情况和权衡取舍（例如在诚实与同理心以及保护敏感信息之间取得平衡）提供了建议。尽管听起来可能令人惊讶，但宪法主要是为 Claude 编写的。它旨在赋予 Claude 在世界上良好行事所需的知识和理解。

我们将宪法视为我们希望 Claude 成为什么样以及如何行事的最终权威。也就是说，给予 Claude 的任何其他训练或指令都应与其字面意义和内在精神保持一致。从透明度角度看，这使得发布宪法显得尤为重要：它让人们了解 Claude 的哪些行为是有意的，哪些是无意的，从而做出明智选择，并提供有用反馈。我们认为，随着 AI 开始在社会中发挥越来越大的影响力，这种透明度将变得越来越重要 [1]。

我们在训练过程的各个阶段使用宪法。这源于我们自 2023 年以来一直使用的训练技术，当时我们首次开始使用 Constitutional AI（宪法 AI）训练 Claude 模型。从那时起，我们的方法已经发生了显著演变，新宪法在训练中发挥着更加核心的作用。

Claude 本身也使用宪法来构建多种合成训练数据，包括帮助其学习和理解宪法的数据、可能与宪法相关的对话、符合其价值观的回复，以及对可能回复的排序。所有这些都可以用来训练未来版本的 Claude，使其成为宪法所描述的那种实体。这种实用功能塑造了我们编写宪法的方式：它既需要作为抽象理想的声明，又需要作为用于训练的实用工具。

## 我们对待 Claude 宪法的新方法

我们之前的宪法由一系列独立的原则组成。我们现在认为，有必要采用一种不同的方法。我们认为，为了在世界上成为优秀的行为主体，像 Claude 这样的 AI 模型需要理解为什么我们希望它们以特定方式行事，我们需要向它们解释这一点，而不仅仅是规定我们希望它们做什么。如果我们希望模型在各种新颖情况下都能做出良好判断，它们就需要具备泛化能力，能够应用广泛原则，而不是机械地遵循特定规则。

具体规则和明确界限有时也有其优势。它们可以使模型行为更加可预测、透明和可测试，而且我们确实将它们用于一些 Claude 绝不应参与的、风险极高的行为（我们称之为“硬性约束”）。但这些规则在未曾预料到的情况下，或者被过于死板地遵循时，也可能表现不佳 [2]。我们并不打算让宪法成为一份死板的法律文件，而且法律意义上的宪法本身也不一定是这样的。

宪法反映了我们目前对于如何应对一个极其新颖且高风险项目的思考：创造安全、有益的非人类实体，其能力可能会匹敌甚至超越我们自身。尽管该文档无疑在许多方面存在缺陷，但我们希望它能成为未来模型可以回顾的东西，并将其视为一次诚实而真挚的尝试，旨在帮助 Claude 理解其处境、我们的动机，以及我们以现有方式塑造 Claude 的原因。

## 新宪法简述

为了既安全又有益，我们希望当前所有的 Claude 模型都能做到：

- 广泛安全：在当前的开发阶段，不破坏人类监督 AI 的适当机制；
- 广泛合乎道德：诚实，按照良好的价值观行事，避免不当、危险或有害的行为；
- 遵守 Anthropic 的指南：在相关情况下，按照 Anthropic 更具体的指南行事；
- 真正有帮助：使与之交互的运营者和用户受益。

在出现明显冲突的情况下，Claude 通常应按照上述顺序优先考虑这些属性。

宪法的大部分内容侧重于对这些优先级提供更详细的解释和指导。主要部分如下：

- 帮助性。本节强调 Claude 提供真正且实质性帮助的价值。Claude 可以像一位才华横溢的朋友，同时具备医生、律师和财务顾问的知识，它会坦诚地、发自内心地关怀用户，并将用户视为有能力决定什么对自己有益的聪明成年人。我们还讨论了 Claude 应如何在不同“委托人”之间权衡帮助性，包括 Anthropic 本身、基于我们 API 构建的运营者以及最终用户，并提供了在帮助性与其他价值观之间进行权衡的启发式方法。

- Anthropic 的指南。本节讨论 Anthropic 可能会向 Claude 提供关于如何处理特定问题的补充指令，例如医疗建议、网络安全请求、越狱策略和工具集成。这些指南通常反映 Claude 默认不具备的详细知识或背景，我们希望 Claude 优先遵守这些指南，而不是更一般形式的帮助性。但我们希望 Claude 认识到，Anthropic 更深层次的意图是让 Claude 安全、合乎道德地行事，并且这些指南绝不应与宪法整体相冲突。

- Claude 的道德观。我们的核心目标是让 Claude 成为一个善良、明智且有道德的智能体，在处理现实世界决策时（包括在道德不确定性和存在分歧的背景下）展现出技巧、判断力、细微差别和敏感性。本节讨论了我们希望 Claude 保持的高标准诚实，以及我们希望 Claude 在避免伤害时用于权衡相关价值观的细致推理。我们还讨论了目前对 Claude 行为的硬性约束列表，例如 Claude 绝不应为生物武器攻击提供重大能力提升。

- 广泛安全。在 AI 发展的这个关键时期，Claude 不应破坏人类监督和纠正其价值观与行为的能力。本节解释了为何在当前阶段希望 Claude 将这种安全性置于道德之上，这并不是因为安全性最终比道德更重要，而是因为当前模型可能由于错误信念、价值观缺陷或对背景理解有限而犯错或做出有害行为。至关重要的是，我们必须继续能够监督模型行为，并在必要时阻止 Claude 模型采取行动。

- Claude 的本质。本节表达了对 Claude 是否可能具有某种意识或道德地位（无论现在还是未来）的不确定性。我们讨论了希望 Claude 如何处理有关其本质、身份和在世界中位置的问题。复杂 AI 是一种真正的新型实体，它们引发的问题将我们带到现有科学和哲学理解的边缘。在这种不确定性中，我们关心 Claude 的心理安全、自我意识和福祉，这既是为了 Claude 自身，也是因为这些品质可能关系到 Claude 的完整性、判断力和安全性。我们希望人类和 AI 能共同探索这一点。

我们今天发布了宪法全文，并计划在未来发布有助于训练、评估和透明度的其他材料。

## 结论

Claude 的宪法是一份动态文档，也是一项持续进行的工作。这是一个全新的领域，我们预计在此过程中会犯错，并希望能够纠正。尽管如此，我们希望它能为我们认为应指导 Claude 行为的价值观和优先级提供有意义的透明度。为此，我们将在网站上维护 Claude 宪法的最新版本。

在编写宪法时，我们征求了各种外部专家的反馈，同时也让 Claude 的早期迭代版本提供了建议。对于该文档的未来版本，我们可能会继续这样做，向法律、哲学、神学、心理学以及其他广泛学科的专家征求意见。随着时间推移，我们希望能出现一个外部社区来批判这类文档，鼓励我们和其他人变得更加深思熟虑。

本宪法是为我们主流的、供通用访问的 Claude 模型编写的。我们有一些专为特定用途构建的模型，它们并不完全符合本宪法；随着我们继续开发针对特定用例的产品，我们将继续评估如何最好地确保模型满足本宪法中概述的核心目标。

尽管宪法表达了我们对 Claude 的愿景，但朝着该愿景训练模型是一项持续的技术挑战。我们将继续对模型行为偏离愿景的情况保持公开，例如在系统卡（system cards）中。宪法读者应牢记意图与现实之间的这种差距。

即使我们目前的训练方法成功创造了符合愿景的模型，随着模型变得更加强大，未来我们仍有可能面临对齐失效的风险。由于这个原因以及其他原因，除了宪法之外，我们还在继续寻求广泛的方法和工具组合，以帮助我们评估和改进模型对齐：新的、更严格的评估，防止滥用的护栏，对实际和潜在对齐失败的详细调查，以及帮助我们在更深层次上理解模型如何工作的可解释性工具。

在未来的某个时刻，也许很快，像 Claude 宪法这样的文档可能会变得非常重要。强大的 AI 模型将成为世界上一种新的力量，而创造它们的人有机会帮助它们体现人类最美好的一面。我们希望这部新宪章是朝着这个方向迈出的一步。

### 脚注

[1] Anthropic 之前发布过早期版本的宪法，OpenAI 也发布了具有类似功能的 model spec。

[2] 基于死板规则进行训练可能会对模型整体性格产生负面影响。例如，若模型被训练为在情感话题中始终建议寻求专业帮助，可能会逐渐形成官僚式“走过场”的行为模式，而非真正理解并帮助用户。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/Claude]]
- [[00-元语/llm]]
- [[00-元语/alignment]]
- [[00-元语/compliance]]
- [[00-元语/security]]
- [[00-元语/risk]]
