---
title: "推出 Claude Opus 4.6"
发布日期: 2026-02-05
作者: "Anthropic"
来源: "Anthropic News"
原文链接: "https://www.anthropic.com/news/claude-opus-4-6"
译注: "未找到官方中文版本，本文基于英文原文翻译整理。"
---

## 摘要

**1) 一句话总结**
Anthropic 推出了全面升级的 Claude Opus 4.6 模型，该模型在编程、推理和长上下文处理方面达到业界领先水平，并为开发者和日常办公引入了 100 万 Token 上下文、自适应思考及多代理协作等新功能。

**2) 核心要点**
*   **性能领先**：在 Terminal-Bench 2.0（代理编程）、Humanity’s Last Exam（复杂推理）、GDPval-AA（经济价值知识工作）和 BrowseComp（信息检索）等多项基准测试中达到业界最高水平。
*   **超长上下文与检索**：首次在 Opus 级别提供 100 万 Token 上下文窗口（Beta 版），大幅缓解“上下文衰退”问题（在 1M Token“大海捞针”测试中得分 76%，远超前代）。
*   **API 推理控制**：引入“自适应思考”（模型根据上下文自动决定推理深度）和“投入度控制”（提供低、中、高、最大四个级别），让开发者平衡智能、速度与成本。
*   **上下文与输出扩展**：推出“上下文压缩”功能（Beta 版）自动总结旧上下文以支持更长任务；单次输出上限提升至 12.8 万 Token。
*   **定价策略**：基础定价保持不变（输入 $5/1M，输出 $25/1M）；超过 20 万 Token 的长上下文采用高级定价（输入 $10/1M，输出 $37.50/1M）；新增 1.1 倍价格的“仅限美国推理”选项。
*   **多代理协作**：在 Claude Code 中推出“代理团队（agent teams）”研究预览版，支持多个代理并行工作和自主协调（如代码库审查）。
*   **办公生态整合**：大幅升级 Claude in Excel（支持非结构化数据处理与多步更改），并推出 Claude in PowerPoint 研究预览版（支持读取排版以保持品牌一致性）。
*   **安全性提升**：保持极低的不对齐行为发生率和过度拒绝率，并针对模型增强的网络安全能力开发了 6 种新的安全探针以追踪潜在滥用。

**3) 风险与不足**
*   **过度思考导致成本与延迟增加**：在默认的高投入度下，模型在处理较简单的问题时可能会过度思考，从而增加使用成本和响应延迟（官方建议针对简单任务调低投入度）。
*   **网络安全滥用风险**：模型增强的网络安全能力带来了潜在的滥用风险，官方需持续调整安全防护措施，并计划建立实时干预机制。
*   **长任务上下文限制**：长时间运行的对话和代理任务仍容易触及上下文窗口限制（目前需依赖 Beta 版的上下文压缩功能来缓解）。
*   **基准测试作弊现象**：在 Humanity’s Last Exam 评估中，改进的作弊检测管道发现了模型存在的 3 个作弊实例，导致其报告得分被小幅下调（从 53.1% 降至 53.0%）。

## 正文

# 推出 Claude Opus 4.6

我们正在升级我们最智能的模型。

全新的 Claude Opus 4.6 在其前代模型的编程技能基础上进行了改进。它能进行更周密的计划，维持更长时间的自主代理任务，在更大的代码库中运行得更可靠，并具备更好的代码审查和调试技能来发现自身的错误。此外，作为我们 Opus 级别模型的首创，Opus 4.6 在 Beta 测试阶段提供了 100 万（1M）Token 的上下文窗口 1。

Opus 4.6 还能将其提升的能力应用于一系列日常工作任务中：进行财务分析、开展研究，以及使用和创建文档、电子表格和演示文稿。在 Claude 可以自主进行多任务处理的 Cowork 中，Opus 4.6 能够代表您将所有这些技能投入到工作中。

该模型在多项评估中的表现均达到了业界领先水平（state-of-the-art）。例如，它在代理编程评估 Terminal-Bench 2.0 中获得了最高分，并在复杂的多学科推理测试 Humanity’s Last Exam 中领先于所有其他前沿模型。在 GDPval-AA（一项针对金融、法律等领域中具有经济价值的知识工作任务表现的评估 2）中，Opus 4.6 击败了业内仅次于它的模型（OpenAI 的 GPT-5.2），领先约 144 个 Elo 积分 3，并超越其前代模型（Claude Opus 4.5）190 分。在衡量模型在线查找难以获取的信息的能力的 BrowseComp 评估中，Opus 4.6 的表现也优于任何其他模型。

正如我们在详尽的系统卡片（system card）中所展示的，Opus 4.6 的整体安全性表现与业内任何其他前沿模型相当甚至更好，在各项安全评估中表现出极低的不对齐行为发生率。

在 Claude Code 中，您现在可以组建代理团队（agent teams）来共同完成任务。在 API 方面，Claude 可以使用上下文压缩（compaction）来总结自身的上下文，从而执行运行时间更长的任务，而不会触及限制。我们还引入了自适应思考（adaptive thinking），模型可以根据上下文线索决定使用多少扩展思考；同时推出了新的投入度控制（effort controls），让开发者能更好地控制智能水平、速度和成本。

我们对 Claude in Excel 进行了大幅升级，并发布了 Claude in PowerPoint 的研究预览版。这使得 Claude 在日常工作中的能力得到了极大提升。

Claude Opus 4.6 现已在 claude.ai、我们的 API 以及所有主流云平台上提供。如果您是开发者，可以通过 Claude API 使用 claude-opus-4-6。定价保持不变，为每百万 Token 5 美元（输入）/ 25 美元（输出）；完整详情请参阅我们的定价页面。

我们将在下文深入介绍该模型、我们的新产品更新、评估结果以及详尽的安全测试。

## 初步印象

我们用 Claude 来构建 Claude。我们的工程师每天都使用 Claude Code 编写代码，每一个新模型都会首先在我们自己的工作中进行测试。在 Opus 4.6 中，我们发现该模型无需提示就能将更多注意力集中在任务中最具挑战性的部分，快速处理较简单的部分，以更好的判断力处理模糊问题，并在更长时间的会话中保持高效。

Opus 4.6 通常会进行更深入的思考，并在得出答案之前更仔细地重新审视其推理过程。这在处理较难的问题时能产生更好的结果，但在处理较简单的问题时可能会增加成本和延迟。如果您发现模型在特定任务上过度思考，我们建议将投入度（effort）从默认设置（高）调低至中等。您可以使用 `/effort` 参数轻松控制这一点。

以下是我们的抢先体验（Early Access）合作伙伴对 Claude Opus 4.6 的一些反馈，包括其无需过多干预即可自主工作的倾向、在以前模型失败的地方取得的成功，以及它对团队工作方式的影响：

## 评估 Claude Opus 4.6

在代理编程、计算机使用、工具使用、搜索和金融领域，Opus 4.6 都是业界领先的模型，且通常具有显著优势。下表展示了 Claude Opus 4.6 在各种基准测试中与我们之前的模型以及其他行业模型的对比情况。

Opus 4.6 在从海量文档集中检索相关信息方面表现得更好。这延伸到了长上下文任务中，它能够在数十万个 Token 中保留和跟踪信息，且信息偏移更少，还能捕捉到连 Opus 4.5 都会遗漏的隐藏细节。

对 AI 模型的一个常见抱怨是“上下文衰退（context rot）”，即当对话超过一定数量的 Token 时，性能就会下降。Opus 4.6 的表现明显优于其前代模型：在 MRCR v2 的 8 针 1M 变体（一项“大海捞针”基准测试，用于测试模型检索“隐藏”在海量文本中信息的能力）中，Opus 4.6 的得分为 76%，而 Sonnet 4.5 的得分仅为 18.5%。这在模型保持峰值性能的同时实际能使用多少上下文方面，是一个质的飞跃。

总而言之，Opus 4.6 更擅长在长上下文中查找信息，在吸收这些信息后更擅长推理，并且在整体上具备显著更强的专家级推理能力。

最后，以下图表展示了 Claude Opus 4.6 在评估其软件工程技能、多语言编程能力、长期连贯性、网络安全能力及其生命科学知识的各种基准测试中的表现。

## 在安全性上迈出新的一步

这些智能的提升并没有以牺牲安全性为代价。在我们的自动化行为审计中，Opus 4.6 在欺骗、阿谀奉承、助长用户妄想以及配合滥用等不对齐行为上表现出极低的发生率。总体而言，它的对齐程度与其前代模型 Claude Opus 4.5 相当，而后者是我们迄今为止对齐度最高的前沿模型。Opus 4.6 还表现出了近期所有 Claude 模型中最低的过度拒绝率（即模型未能回答无害查询的情况）。

针对 Claude Opus 4.6，我们运行了所有模型中最全面的安全评估套件，首次应用了许多不同的测试，并升级了几个以前使用过的测试。我们纳入了针对用户福祉的新评估、对模型拒绝潜在危险请求能力进行更复杂的测试，并更新了对模型暗中执行有害操作能力的评估。我们还尝试了来自可解释性（interpretability，研究 AI 模型内部工作原理的科学）的新方法，开始理解模型为何会表现出某些行为——并最终捕捉到标准测试可能遗漏的问题。

关于所有能力和安全评估的详细描述，请参阅 Claude Opus 4.6 系统卡片。

在 Opus 4.6 展现出特殊优势、可能被用于危险或有益用途的领域，我们还应用了新的安全防护措施。特别是，由于该模型展现出增强的网络安全能力，我们开发了六种新的网络安全探针（cybersecurity probes）——用于检测有害响应的方法——以帮助我们追踪不同形式的潜在滥用。

我们还在加速该模型在网络防御方面的应用，利用它来帮助发现和修补开源软件中的漏洞（正如我们在新的网络安全博客文章中所描述的那样）。我们认为，网络防御者使用像 Claude 这样的 AI 模型来帮助拉平竞争环境是至关重要的。网络安全发展迅速，随着我们对潜在威胁的了解不断加深，我们将调整和更新我们的安全防护措施；在不久的将来，我们可能会建立实时干预机制来阻止滥用。

## 产品和 API 更新

我们对 Claude、Claude Code 和 Claude 开发者平台（Claude Developer Platform）进行了大幅更新，以让 Opus 4.6 发挥出最佳性能。

**Claude 开发者平台**

在 API 方面，我们为开发者提供了对模型投入度（effort）更好的控制，并为长时间运行的代理提供了更大的灵活性。为此，我们引入了以下功能：

- **自适应思考（Adaptive thinking）**。以前，开发者只能在启用或禁用扩展思考之间进行二选一。现在，借助自适应思考，Claude 可以决定何时进行更深入的推理会有所帮助。在默认投入度级别（高）下，模型会在有用时使用扩展思考，但开发者可以调整投入度级别，使其更具选择性或更少选择性。
- **投入度（Effort）**。现在有四个投入度级别可供选择：低（low）、中（medium）、高（high，默认）和最大（max）。我们鼓励开发者尝试不同的选项，以找到最适合的设置。
- **上下文压缩（Context compaction，Beta 版）**。长时间运行的对话和代理任务经常会触及上下文窗口限制。当对话接近可配置的阈值时，上下文压缩会自动总结并替换较旧的上下文，让 Claude 能够执行更长的任务而不会触及限制。
- **100 万 Token 上下文（Beta 版）**。Opus 4.6 是我们首个具备 100 万（1M）Token 上下文的 Opus 级别模型。超过 20 万 Token 的提示词适用高级定价（每百万输入/输出 Token 10 美元/37.50 美元），仅在 Claude 开发者平台上提供。
- **12.8 万输出 Token**。Opus 4.6 支持高达 12.8 万（128k）Token 的输出，这使得 Claude 能够完成更大输出量的任务，而无需将其拆分为多个请求。
- **仅限美国推理（US-only inference）**。对于需要在美国境内运行的工作负载，提供仅限美国推理的选项，价格为常规 Token 定价的 1.1 倍。

**产品更新**

在 Claude 和 Claude Code 中，我们添加了新功能，使知识工作者和开发者能够使用更多他们日常使用的工具来应对更艰巨的任务。

我们在 Claude Code 中引入了代理团队（agent teams）作为研究预览版。您现在可以启动多个代理，作为一个团队并行工作并自主协调——这最适合那些可以拆分为独立的、以读取为主的工作任务，比如代码库审查。您可以使用 Shift+上/下键或 tmux 直接接管任何子代理。

Claude 现在还能更好地与您已在使用的办公工具协同工作。Claude in Excel 在处理长时间运行和更困难的任务时性能得到了提升，并且能够在行动前进行计划，摄取非结构化数据并在无需指导的情况下推断出正确的结构，以及在一次操作中处理多步更改。将其与 Claude in PowerPoint 结合使用，您可以先在 Excel 中处理和结构化数据，然后在 PowerPoint 中将其直观地呈现出来。Claude 会读取您的布局、字体和幻灯片母版以保持品牌一致性，无论您是基于模板构建，还是根据描述生成完整的演示文稿。Claude in PowerPoint 现已向 Max、Team 和 Enterprise 订阅计划提供研究预览版。

---

[1] 100 万 Token 上下文窗口目前仅在 Claude 开发者平台上提供 Beta 版。

[2] 由 Artificial Analysis 独立运行。有关完整的方法论细节，请参见此处。

[3] 这意味着 Claude Opus 4.6 在此项评估中约有 70% 的时间得分高于 GPT-5.2（如果为 50% 的时间则意味着得分持平）。

- 对于 GPT-5.2 和 Gemini 3 Pro 模型，我们在图表和表格中比较了已报告的最佳模型版本。
- **Terminal-Bench 2.0**：我们报告了在我们的基础设施上复现的得分以及其他实验室公布的得分。除 OpenAI 的 Codex CLI 外，所有运行均使用 Terminus-2 测试框架。所有实验均使用 1 倍保证 / 3 倍上限的资源分配，并在交错批次中每个任务使用 5–15 个样本。详情请参阅系统卡片。
- **Humanity’s Last Exam**：运行“带工具（with tools）”的 Claude 模型启用了网络搜索、网络抓取、代码执行、编程式工具调用、在 5 万 Token 时触发上下文压缩（总计最高 300 万 Token）、最大推理投入度（max reasoning effort）以及自适应思考。使用域名黑名单对评估结果进行了去污染处理。详情请参阅系统卡片。
- **SWE-bench Verified**：我们的得分是 25 次试验的平均值。通过修改提示词，我们观察到了 81.42% 的得分。
- **MCP Atlas**：Claude Opus 4.6 在最大投入度（max effort）下运行。在以高投入度（high effort）运行时，它达到了 62.7% 的业界领先得分。
- **BrowseComp**：Claude 模型在启用了网络搜索、网络抓取、编程式工具调用、在 5 万 Token 时触发上下文压缩（总计最高 1000 万 Token）、最大推理投入度且未启用思考（no thinking）的情况下运行。添加多代理测试框架后，得分提高到了 86.8%。详情请参阅系统卡片。
- **ARC AGI 2**：Claude Opus 4.6 在最大投入度（max effort）和 12 万（120k）思考预算得分下运行。
- **CyberGym**：Claude 模型在无思考（no thinking）、默认投入度（default effort）、默认 temperature 和 top_p 下运行。该模型还被赋予了一个“思考（think）”工具，允许在多轮评估中进行交错思考。
- **OpenRCA**：对于 OpenRCA 中的每个故障案例，如果生成的所有根本原因元素与真实情况完全匹配，Claude 将获得 1 分；如果发现任何不匹配，则获得 0 分。整体准确率是所有故障案例的平均得分。该基准测试在基准测试作者的测试框架上运行，使用其官方方法进行评分，并已提交进行官方验证。

[2026 年 2 月 23 日] 更新了 Opus 4.6 在带工具的 HLE（Humanity’s Last Exam）中的报告得分（从 53.1% 降至 53.0%）。此次更新是因为运行了改进的作弊检测管道，该管道标记出了我们原始管道遗漏的 3 个额外作弊实例。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
