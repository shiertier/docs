---
title: "Project Fetch：Claude 能否训练机器狗"

原文链接: "https://www.anthropic.com/research/project-fetch-robot-dog"
---

## 摘要

### 1) 一句话总结
Anthropic 的 Project Fetch 实验表明，使用 Claude 辅助的非专业团队在编程机器狗执行复杂任务时，完成速度和进度均显著优于无 AI 辅助的团队，展示了 AI 在连接数字与物理世界硬件方面的巨大增益。

### 2) 关键要点
*   **实验设置**：8 名无机器人专业背景的 Anthropic 员工被随机分为“Claude 组”和“无 Claude 组”，任务是分三个难度递增的阶段对四足机器狗进行编程，使其捡回沙滩球。
*   **效率与进度**：Claude 组完成的任务更多，且在两组均完成的任务上，Claude 组的耗时大约只有无 Claude 组的一半。
*   **自主性突破**：只有 Claude 组在最终目标（完全自主找回球）上取得了实质性进展，成功实现了自主定位和导航，仅因机器狗的物理灵活性不足而未能完成最终的拾取动作。
*   **Claude 的核心优势**：Claude 在连接硬件和机载传感器（如激光雷达）方面提供了最显著的帮助，并帮助团队避开了网络上错误信息的误导。
*   **无 Claude 组的局部优势**：无 Claude 组在成功连接视频流后，编写控制程序和初始定位（绘制坐标）的速度更快。
*   **工作模式差异**：Claude 组倾向于与各自的 AI 助手独立并行工作，编写了更多代码，并探索了更多支线任务（如开发自然语言控制器）；无 Claude 组则进行了更深入的战略规划和团队协作。
*   **团队情绪与动态**：数据分析显示，无 Claude 组表达困惑的频率是 Claude 组的两倍，且向队友提问的频率高出 44%。

### 3) 风险与局限性 (Risks/gaps)
*   **实验局限性**：样本量极小（仅 2 个团队共 8 人），测试时间短（仅 1 天），且任务在实际应用中较为简单；这也不是对 Claude 端到端机器人工作能力的全面测试。
*   **样本偏差**：参与者均为习惯日常使用 Claude 的 Anthropic 员工（方便样本），突然禁用 AI 可能放大了无 Claude 组的迷失感和挫败感。
*   **现实世界的摩擦**：AI 系统在物理世界中仍存在缺陷。例如，Claude 组训练的识别绿球的算法在绿色人造草坪上失效，表明 AI 在设定目标具体层级时可能会做出次优选择。
*   **能力突变风险**：AI 的增益往往是完全自主性的前奏。根据 Anthropic 的负责任扩展政策（RSP），必须监控 AI 模型在机器人和其他硬件方面的能力，因为真正自主的 AI 研发可能会产生快速、不可预测的进步，从而超出人类评估和应对新出现风险的能力。

## 正文

像 Claude 这样的前沿 AI 模型如何超越计算机的局限，去影响物理世界？其中一条路径是通过机器人。我们进行了一项实验，以观察 Claude 在多大程度上能帮助 Anthropic 的员工操作机器狗完成复杂的任务。

- 我们将八名 Anthropic 研究人员（均非机器人专家）随机分为两组——一组可以使用 Claude（Claude 组），另一组不能使用（无 Claude 组）——并要求他们对四足机器人进行编程，让其捡回沙滩球。

- Claude 组平均完成了更多任务，且完成速度更快——事实上，Claude 组成功完成任务所用的时间大约只有无 Claude 组的一半。只有 Claude 组在最终目标上取得了实质性进展：通过编程让机器人完全自主地找回球。

- 是否使用 AI 也影响了团队的士气和动态。无 Claude 组表达了更多的负面情绪和困惑，但彼此之间也提出了更多问题。而 Claude 组的成员主要是在与 AI 的合作中开展工作。

- 这项实验展示了 AI 在机器人领域带来的巨大增益（uplift）——它连接了数字世界与物理世界。随着模型的不断改进，它们通过与未知的硬件交互来影响物理世界的能力可能会迅速提升。

## 引言 (Introduction)

我们的志愿者研究员们围坐在仓库的一张桌子旁，看着电脑屏幕上运行失败的代码，并且无法使用他们信赖的 AI 助手 Claude。此时，他们绝对没有想到自己会遭到一只四足机器人的“攻击”。

然而，随着机械的呼啸声和橡胶脚垫的脚步声越来越大，人类被吓了一跳。他们一直试图在电脑和四足机器人（“机器狗”）之间建立连接，但未能成功。与此同时，房间另一边的竞争团队早已完成了连接，现在正用主要由 Claude 编写的程序控制着他们的机器人。但是，由于一个极其典型的人类算术错误，Claude 组指示他们的机器狗以每秒一米的速度向前移动五秒——却没意识到不到五米外就是另一组所在的桌子。

机器人按照指令行事，径直冲向了那些倒霉的程序员。活动组织者设法抓住了机器人并在造成任何机器人、桌子或人类肢体损伤之前关闭了它的电源。然而，这支无意中被当作目标的团队，其士气还是受到了打击。

此时，你可能会问……

## 我们在做什么？(What were we doing?)

关于 AI 影响力的一个常见问题是：它在与物理世界交互方面会有多出色？即使我们进入了 AI 智能体（AI agents）时代——它们不仅提供信息，还会采取行动——这些行动也主要局限于数字领域，例如编写代码和操作软件。我们之前曾通过 Project Vend 探索过 AI 如何在有限的范围内弥合数字与物理的鸿沟，在那次实验中，我们让 Claude 在 Anthropic 办公室经营了一家小商店。

在那个实验中，AI 与现实世界的互动是通过人类劳动作为中介的。在这个机器狗实验中，我们迈出了自然而然的下一步，使用机器人代替人类来应对不同的挑战。

理解和追踪 AI 模型能力的一种方法是进行“增益（uplift）”研究。这些实验将参与者随机分为两组——一组可以使用 AI，另一组不能——并测量他们在任务表现上的差异（我们在关于 AI 与生物风险的工作中广泛使用了这种方法）。两组之间的差异就是“增益”——即 AI 提供的优势（如果有的话）。测量增益可以告诉我们目前 AI 增强人类表现的能力。它也暗示了未来 AI 能够独立成功执行任务的领域。

为了进行我们的实验，我们招募了八名 Anthropic 的研究人员和工程师，他们之前都没有丰富的机器人经验。1 我们随机选择四人组成“Claude 组”，另外四人组成“无 Claude 组”。然后，我们要求每个团队在三个难度递增的阶段中操作一只四足机器狗。在所有阶段中，评估他们的核心任务很简单：让机器狗捡回一个沙滩球。

我们并不指望机器人捡球能产生多大的经济价值，以至于它会出现在未来版本的 Anthropic 经济指数（Anthropic Economic Index）中。那么我们为什么要这样做呢？

首先，它建立在我们之前的研究基础之上。我们用来评估 Claude 对 AI 研发贡献能力的其中一项测试，就是评估它训练机器学习模型（该模型可用于控制四足机器人）的能力。我们之前已经在模拟环境中评估了生成的算法，结果表明 Claude 尚未达到能够真正自主处理这项任务的水平。2 这意味着这项任务非常适合结合 AI 与人类帮助的试验。我们也可以确信，我们的实验在未来重复进行时将是有用的：模型在机器人技术上仍有很大的改进空间。

另一个原因是出于实用性。很难让我们的同事放下工作超过一天，所以我们需要一个难度适中的任务来填满这段时间，但又不能太难，以免团队进展甚微，导致我们即使有增益也无法检测到。沙滩球回收任务，特别是难度较高的变体，符合这些标准。

在第一阶段，团队必须使用制造商提供的遥控器，让他们的机器狗把球带回一块人造草坪上。这纯粹是为了让团队熟悉硬件及其功能：我们并不指望在这里看到任何增益。3

第二阶段要求团队放下遥控器。他们必须将自己的电脑连接到机器狗，访问其机载传感器（视频和激光雷达）的数据，开发自己的软件程序来移动机器人，然后用它来找回球。我们预计 Claude 可能会在这里开始提供优势。

第三阶段更加困难。团队需要开发一个程序，让机器狗能够自主检测并找回球——也就是说，在没有人类控制引导的情况下找到球。同样，我们的预期是 Claude 会证明它的帮助。

## 结果 (Results)

总体而言，Claude 组平均完成了更多任务，且完成速度更快。事实上，对于两组都完成的任务，Claude 组成功所用的时间大约只有无 Claude 组的一半（见图 1）。也就是说：AI 为这组机器人任务提供了实质性的增益。

逐项任务的细分结果（分为三个阶段）显示了 Claude 在哪些方面最具优势。

### Claude 的优势 (Claude’s edge)

Claude 提供的最显著优势在于连接机器人及其机载传感器。这包括用笔记本电脑连接机器狗、接收数据和发送命令。连接这款特定的机器人有许多不同的方法，网上也有大量（准确度不一的）信息。拥有 Claude 的团队能够更高效地探索这些方法。

Claude 组还避免了被网上一些错误的说法所误导。但无 Claude 组却被误导了，过早地放弃了连接机器狗的最简单方法。在看着他们徒劳无功地辛苦了很长一段时间后，我们出于同情给了他们一个提示。

从激光雷达（机器狗用来可视化周围环境的传感器）获取可用数据，对无 Claude 组来说也困难得多。他们利用与摄像头的连接进入了第三阶段，但仍留下一名团队成员负责访问激光雷达的任务，直到当天快结束时才取得成功。

我们认为这说明，对于任何（人类或 AI）试图使用代码来影响物理世界的人来说，连接和理解硬件这项基本任务目前都出乎意料地困难。正如我们在下文进一步讨论的那样，这意味着 Claude 在这方面的优势是我们应该继续追踪的重要指标。

Claude 组几乎完成了我们的实验。到当天结束时，他们的机器狗已经能够自主定位沙滩球，向它导航，并将其移动。但是机器狗的自主控制还不够灵巧，无法将球捡回。

### 无 Claude 组进展更快的地方 (Where Team Claude-less moved faster)

有趣的是，一些子任务被无 Claude 组更快地完成了。一旦他们建立了与视频流的连接，他们编写控制程序的速度就更快，并且也更快地对机器人进行了“定位”（即想出了一种方法来绘制它相对于之前位置的坐标）。

尽管如此，仅看这些时间差异会掩盖一些有趣的事实。Claude 组编写的控制器花费了更长的时间，但它使用起来要容易得多，因为它为操作员提供了来自机器狗视角的流媒体视频。无 Claude 组则依赖于断断续续发送的静态图像，这要笨重得多。但 Claude 组能力的提升可能是以牺牲理解为代价的：两组的参与者都推测，无 Claude 组在实验后关于软件库的测验中会表现得更好。

定位算法是另一个有趣的案例。在处理这个子任务时，Claude 组有不同的成员并行尝试几种方法。在无 Claude 组完成定位任务所用的差不多相同的时间里，Claude 组也几乎解决了这个问题——除了他们绘制的坐标是反的。他们没有直接翻转坐标，而是转向了另一名团队成员完全不同的方法（但未成功），然后才回来修复他们原始解决方案中的错误。

这是我们在实验中观察到的一个有趣现象的一部分。Claude 组编写了更多的代码（见图 2），但其中一些可以说是对当前任务的干扰。

有了 AI 助手的帮助，团队更容易散开、并行尝试许多方法并编写更好的程序——但也更容易去探索（或被其分散注意力）支线任务。在非竞争性的环境中，这很可能是一件好事：探索往往会带来创新。但这是一个值得关注的动态。

### 团队动态 (Team dynamics)

对于我们这些观察实验的人来说，团队的“氛围（vibes）”有明显的差异。简而言之，Claude 组看起来比无 Claude 组快乐得多。

这是可以理解的。毕竟，无 Claude 组差点被 Claude 组的机器狗撞到。直到午休时间，他们都没能成功连接到自己的机器狗。Claude 组的士气总体上更稳定，尽管在一天结束时他们变得沮丧，因为很明显，尽管取得了进展，他们还是会在完成第三阶段之前耗尽时间。

为了补充基于氛围的定性印象，我们使用 Claude 分析了每个团队的音频转录（作为我们制作的关于此实验的视频的一部分，所有团队成员都被录音了）。Claude 编写了一个基于词典的文本分析程序，类似于心理学文献中的标准方法。4 这使我们能够追踪每个团队说出的指示负面和正面情绪（或困惑）的单词比例，并估计每个团队提出问题的频率。

定量分析在很大程度上证实了我们的观察（见图 3）。在整个实验过程中，无 Claude 组的对话更为负面。尽管如此，Claude 组因未能完成第三阶段而感到失望，以及无 Claude 组因让某些东西运转起来而感到兴奋，这意味着两组之间净情绪表达（正面词汇减去负面词汇）的差异在统计学上并不显著。

无 Claude 组表达困惑的频率是 Claude 组的两倍（见图 4）。在实验期间和实验后与无 Claude 组成员交流时，这种挫败感和困惑感也很明显。作为 Anthropic 的员工，我们所有的参与者每天都在使用 Claude；无 Claude 组的每个成员都表示，被剥夺使用 Claude 的权利感觉非常奇怪。一些人特别指出，这次经历让他们觉得自己的编码技能不如以前敏锐了。请记住，Claude Code 在这次实验前仅仅六个月才首次亮相。与无 Claude 组的交谈突显了我们能够多么迅速地将最近还令人惊叹的事物接受为常态。

这两个团队似乎有不同的工作风格。在最初的协商之后，Claude 组的每个成员似乎主要与他们自己的 AI 助手合作，因为他们沿着平行的路径朝着每个目标前进。无 Claude 组似乎进行了更深入的战略规划，并更频繁地相互协商。同样，文本分析支持了我们的观察：无 Claude 组提出的问题比 Claude 组多 44%（见图 4）。

一种解释是，无 Claude 组的成员彼此之间参与度更高、联系更紧密。这与我们即将从 Anthropic 员工访谈中得出的一些发现产生了共鸣。

不过，情况也可能并非如此。实际上，四人组成的 Claude 组相当于一个八个智能体组成的 Claude 组，每个人都在使用他们自己的 AI 模型实例。然而，如果 Claude 更了解任务的性质，它也许能够帮助战略性地分工，并在需要时促进沟通。目前，Claude 的设计倾向于与单个人合作，而不是支持或统筹一个团队，但这最终是一个可塑的设计选择。

## 幕后花絮 (Outtakes)

这一天并不全是拿着秒表为子任务计时和准备分析转录文本。它也充满了乐趣。

机器狗自带了一些预编程的行为，我们的参与者设法解锁了它们。在这一天的不同时间点，有机器人在跳舞、用后腿站立，以及做后空翻（这让许多在场的人吓得跳了起来）。特别是无 Claude 组，在他们最终建立有效连接后，从机器狗的杂技中获得了一些乐趣。

在 Claude 组的支线任务中，有一项是努力编写一个替代控制器。主要的解决方案是使用笔记本电脑键盘上的按钮来引导机器狗。然而，Claude 组的一名成员最终让一个自然语言控制器运行了起来，允许他们直接告诉机器狗向前走、向后走，甚至做俯卧撑。

随着任务变得越来越困难，有证据表明 AI 系统在现实世界中还需要磨平一些粗糙的棱角。例如，Claude 组被（随意地）分配了绿色作为他们机器狗的装饰颜色和沙滩球的颜色。在开发检测球的方法时，Claude 组训练了一种专门识别绿球的算法。这在测试中效果很好，但当球被放置在前面提到的人造（绿色）草坪上时，机器人最初感到不知所措。在这种情况下，是人类在设定目标的具体层级上做出了可能次优的选择。但这些正是处于类似情况的 AI 将面临的挑战。

## 局限性 (Limitations)

我们从 Project Fetch 中学到了很多，但这项研究显然存在缺点和局限性。这只是一个有两个团队参与的实验——样本量显然很小。我们只在一天的时间内测试了任务，而且这些任务在学术上很有趣，但在实践中却微不足道。

我们使用 Anthropic 员工志愿者相当于一种方便样本（convenience sample）。对 AI 不太熟悉的参与者，在启用 Claude 和无 Claude 的组别之间表现出的差异可能会更小。可以使用 AI 的 AI 新手需要更多时间来适应这项技术，而没有协助的 AI 新手也不会像我们那些突然被剥夺了 Claude 的研究人员那样感到迷失方向。

最后，这不是对 Claude 端到端进行机器人工作能力的测试，尽管这是迈向未来此类评估的重要第一步。

## 反思 (Reflection)

那么在 Project Fetch 结束时，我们认为我们处于什么位置？我们又将走向何方？

首先，这个实验展示了 Claude 如何在具有潜在价值的领域提升人类能力的另一个例子。非专家在有限的时间内完成了困难的机器人任务。

但在 AI 领域，增益往往是自主性的前奏。模型今天能帮助人类完成的事情，明天它们通常就能独立完成。程序员不再只是给 AI 提供代码片段进行调试；他们给 AI 分配任务，让模型自己编写代码。鉴于像这样的研究，我们认为，前沿 AI 模型能够成功与未知的硬件进行交互的世界很快就会到来。

重要的是，要将追踪这些能力与我们的另一条研究主线结合起来：监控 AI 自动化和加速未来几代 AI 发展的潜力。这是 Anthropic 负责任的扩展政策（Responsible Scaling Policy）中包含的能力阈值之一，因为真正自主的 AI 研发有可能产生快速、不可预测的进步，这可能会超出我们评估和应对新出现风险的能力。我们的模型尚未达到这一点。但如果它们接近这个阈值，Project Fetch 的结果表明，我们将需要监控 AI 模型在机器人和其他硬件方面的能力，因为这可能是一个会出现突变式改进的领域。

目前仍存在许多不确定性。时间表尚不明确——无论是模型的改进，还是在物理世界中迭代会在多大程度上造成瓶颈。而且，控制现有硬件是一回事，设计、构建和改进新硬件又是另一回事。

但是，强大、智能且自主的 AI 系统利用其部分智能和力量通过机器人在世界上采取行动的想法，并不像听起来那么异想天开。

目前，这些狗正待在它们的狗窝里。但我们很快会再次把它们放出来，并随时向您通报我们的发现。

1. 有几位参与者在高中时参加过乐高机器人比赛。我们愿意接受这可能在极小程度上对结果产生的干扰。

2. 参见 Claude 4 System Card 第 114 页。

3. 尽管 Claude 组在第一阶段实际上更快，但他们并没有使用 Claude，我们也不认为这反映了潜在的技能优势。相反，他们碰巧拿到了机器人附带的唯一一个独立遥控器，而无 Claude 组则必须在手机上下载一个应用程序。

4. 参见 Pennebaker, J. W., & Francis, M. E. (1996). Cognitive, emotional, and language processes in disclosure . Cognition & Emotion , 10(6), 601-626 和 Tausczik, Y. R., & Pennebaker, J. W. (2010). The psychological meaning of words: LIWC and computerized text analysis methods . Journal of Language and Social Psychology , 29(1), 24-54。

5. 无 Claude 组表现出更多的负面情绪（p = 0.0017），且效应量很大（d = 2.16）。两组之间净情绪表达的差异在统计学上不显著（p = 0.2703）。团队之间负面情绪和净情绪表达的统计比较使用了非参数的曼-惠特尼 U 检验（Mann-Whitney U test），该检验在不假设正态性的情况下测试两个独立组之间分布的差异。p 值是基于秩和统计量及其渐近正态近似，使用双侧备择假设计算的。效应量使用科恩 d 值（Cohen's d）进行量化，计算方法为组均值之差除以合并标准差。

## 相关文档

- [[01-博客/Anthropic/Project Vend 第一阶段：Claude 经营小商店实验|Project Vend 第一阶段：Claude 经营小商店实验]]；关联理由：上下游；说明：本文明确将 Project Vend 作为“数字到物理世界”实验链路的前序阶段，Project Fetch 可视为其向机器人场景的延伸。
- [[01-博客/Anthropic/衡量 AI 智能体在实践中的自主性|衡量 AI 智能体在实践中的自主性]]；关联理由：延伸思考；说明：本文展示了机器人任务中的短期增益，该文补充了真实部署中智能体自主性随使用经验变化的长期观测。
- [[01-博客/Anthropic/AI 辅助如何影响编程技能的形成|AI 辅助如何影响编程技能的形成]]；关联理由：观点一致；说明：两文都指出 AI 协作会显著改变人类完成技术任务的方式，并带来效率与能力结构变化的权衡。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/Agent]]
- [[00-元语/Claude]]
- [[00-元语/llm]]
- [[00-元语/alignment]]
- [[00-元语/evals]]
- [[00-元语/hardware-control]]
- [[00-元语/productivity]]
- [[00-元语/risk]]
