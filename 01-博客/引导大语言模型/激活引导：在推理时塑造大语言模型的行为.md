---
title: "激活引导：在推理时塑造大语言模型的行为"
发布日期: "2026-02-21"
原文链接: "https://lowleveldesign.io/News/activation-steering-llm-behavior-2026-02-21"

来源: "用户提供的视频讲解转写文本"
形式: "视频字幕转写整理"
主题: "激活引导、概念向量、前向钩子与稀疏自编码器特征"
整理说明: "由转写整理成文，已做断句、去口癖与结构化；部分模型名与机构名可能存在转写误差"
记录日期: "2026-02-22"
---

## 摘要

**1) 一句话总结**
激活引导是一种无需修改模型权重，通过在推理阶段使用前向钩子向模型中间层注入概念向量，从而精确干预并塑造大语言模型输出行为的技术。

**2) 核心要点**
*   **干预机制**：引导仅发生在推理阶段的前向传播过程中，通过修改层与层之间传递的隐藏状态（激活空间）来影响生成，原始模型参数保持不变。
*   **线性表征与向量算术**：可解释概念在激活空间中表现出线性特征，支持向量相加（组合概念）与缩放（调整概念强度）。
*   **干预层级选择**：推荐在模型的中间层进行引导，因为早期层偏向局部表征，后期层偏向表面措辞，而中间层更集中承载抽象概念与推理过程。
*   **工程实现**：核心操作为 `X ← X + α · V`（X为输出激活，V为概念向量，α为干预强度），通常利用 HuggingFace Transformers 的前向钩子（Forward Hooks）来实现。
*   **向量获取方法一（对比激活）**：准备正负例提示样本，分别取平均激活后做差值，以此获得特定概念的方向向量。
*   **向量获取方法二（稀疏自编码器）**：通过训练自编码器重建激活状态并在中间层施加稀疏性来提取特征库（可借助 Neuropedia 平台或 HuggingFace Hub 获取）。
*   **应用实例**：在开源模型（如转写提及的 lama3.18B）中间层注入特定向量，可使模型回答偏离原分布（如呈现“巴黎化”视角或自认为金属结构）。

**3) 风险与局限（基于原文明确提及）**
*   **推理破坏风险**：干预系数（α）不能盲目调高，过强的干预会破坏模型的推理过程，导致输出内容混乱。
*   **知识边界局限**：激活引导只能在模型已学会的概念空间内改变生成路径，无法用于教导模型学习全新的知识。
*   **特征查找困难**：使用稀疏自编码器提取的特征往往没有现成的语义标签，定位特定概念较为繁琐。
*   **表征误解风险**：概念通常以跨多个神经元的分布式（叠加）方式编码，不能将激活空间的单一坐标简单等同于“单一概念神经元”。

## 正文

当你想调整大语言模型的行为或“性格”时，常见手段是提示工程与微调。讲者提出第三条路线：不改权重、不做训练，而是在推理阶段对模型内部激活做一次精确干预，让输出朝某个概念或风格偏移。这类方法在转写中被称为引导模型，更常见的说法是激活引导。

### 1. 核心类比：像神经刺激一样在运行时干预

讲者把这种方法类比为神经科学中的神经刺激：不改变大脑的结构，只在运行时刺激特定区域，进而触发或抑制某些行为。对应到大语言模型，就是在前向传播过程中对某一层的激活做修改，从而影响模型接下来的生成。

关键点在于：加载到内存中的仍然是原始模型参数，引导只发生在生成过程中。

### 2. 模型内部视角：层与层之间传递的隐藏状态

讲者先回顾了典型自回归 Transformer 的结构：模型逐 token 生成，每层包含注意力块与前馈网络块；层与层之间会传递一个高维向量，常被称为隐藏状态。

在这段讲解里，这个高维空间被称为激活空间。你可以把隐藏状态看作模型此刻的内部“想法”，也可以把向量的各个坐标想象成一组抽象神经元的输出信号。引导的切入点就位于这些中间激活上。

### 3. 概念向量与线性表征：为什么加一个向量就能改变行为

讲者强调了一个经验性现象：在很多大语言模型中，可解释概念往往以向量的形式出现在激活空间里，并且在一定程度上表现出线性表征的特征。

线性表征最重要的可用性是向量可加：

- 把“汽车”的向量与“红色”的向量相加，可以得到更接近“红色汽车”的表示。
- 对同一个概念向量做缩放，通常更像是在调整概念的强度，而不是改变概念的类别。

讲者提到词向量领域的经典类比来说明“向量算术”的直觉（具体例子在不同叙述中会有差异，这里以直觉为主）。他想表达的是：这种可加性不仅出现在早期词嵌入，也可能在更深层的激活里继续出现。

同时他也提醒一个常见误解：不能把每个坐标都当作“单一概念神经元”。概念更可能以跨多个神经元的分布式方式编码，转写中将其称为叠加。

### 4. 哪一层最适合引导：中间层更像抽象推理区

讲者给出了一个经验判断：不同层扮演不同角色。

- 早期层更贴近输入中刚出现的词与局部表征。
- 后期层更贴近即将输出的词与表面措辞。
- 中间层更可能承载抽象概念与推理过程。

因此，如果目标是让模型“受到某个概念影响”，而不是强迫它反复输出同一组关键词，引导中间层往往更合适。

### 5. 实操思路：用前向钩子把概念向量加到激活上

假设你已经有了一个概念向量 `V`，并选择在第 `N` 层的输出激活 `X` 上做干预，引导的基本操作就是把缩放后的 `V` 加到 `X` 上：

- `X ← X + α · V`

其中系数 `α` 决定干预强度。讲者用 HuggingFace Transformers 的用法举例，核心工程手段是前向钩子：把一个函数挂在某一层上，在前向传播经过该层时自动触发，对该层输出做一次加法修改。

转写中提到他把这套方法应用到一个开源模型（写作 “lama3.18B”，以转写为准），并选在中间层做干预。通过不同的系数与不同问题，他观察到模型的回答会逐渐偏离原本分布，呈现出更“巴黎化”的视角；当直接追问“你是谁”时，模型甚至会把自己描述成某种大型金属结构，从而表现出被特定概念牵引的身份叙事。

讲者也强调：系数不能盲目调高。过强的干预会破坏模型的推理，导致输出变得混乱。为了更稳定，你可以配合调整生成参数，例如温度与一些重复控制项。

### 6. 概念向量从哪里来：对比激活与稀疏自编码器

讲者介绍了两类寻找概念向量的方法。

第一类是对比激活法：

- 你准备成对的提示样本，分别代表正例与负例。
- 对正例与负例分别取平均激活，再做差。
- 如果配对足够多，差向量可能会成为你要的概念方向。

讲者声称在某些情况下这种方法效果很好，甚至可能优于纯提示工程或有监督微调。

第二类是稀疏自编码器：

- 训练一个自编码器去重建大语言模型的激活状态，并在中间层施加稀疏性。
- 经验上，稀疏层的某些维度往往对应更可解释的特征。

优点是它能提供一个可挑选的特征库，社区也会分享现成的自编码器；缺点是特征往往没有现成的语义标签，查找某个特定概念会更麻烦。转写中提到一个用于浏览与可视化这些特征的平台 Neuropedia（以转写为准），以及在 HuggingFace Hub 上获取相关资源。

### 7. 适用边界：引导不是教新知识

讲者把引导的优缺点总结得很直接：

- 优势：不需要微调，不改权重，干预强度可控，并且可以贯穿整个生成过程。
- 局限：需要找到合适的概念向量与干预强度；引导更适合模型已经学会表示的概念，它不会教会模型新的知识。

如果你把它看作一种可编程的“运行时偏置”，它更像是在既有能力空间里改变路径，而不是增加能力本身。

## 相关文档

- [[01-博客/Anthropic/大型语言模型中内省能力的迹象|大型语言模型中内省能力的迹象]]；关联理由：解说；说明：该文直接讨论概念向量注入与 activation steering 的实验现象，可补充本文对“注入后行为改变”的机制侧证。
- [[01-博客/Anthropic/应对ASL-4级AI风险：三种安全用例框架构想|应对ASL-4级AI风险：三种安全用例框架构想]]；关联理由：延伸思考；说明：该文把 SAE 与 feature steering 放入安全评估与监控框架，属于本文技术路线在安全治理层面的延展。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/prompt]]
- [[00-元语/alignment]]
