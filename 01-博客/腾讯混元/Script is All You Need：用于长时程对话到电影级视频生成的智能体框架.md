# Script is All You Need：用于长时程对话到电影级视频生成的智能体框架

## 文档信息

- 来源：https://xd-mu.github.io/ScriptIsAllYouNeed/
- 发布机构：腾讯混元多模态部门；西安电子科技大学
- 译注：该页面未提供官方中文版本，正文为基于原文内容的中文翻译整理。

## 摘要

腾讯混元与西安电子科技大学联合提出了一个端到端的智能体框架，通过剧本、导演和评论家智能体的协作，将粗略对话转化为连贯的长程电影级视频。

- 研发背景：旨在解决现有视频生成模型难以从对话等高层概念中生成连贯长篇叙事的语义鸿沟问题。
- 研发机构：由腾讯混元多模态部门与西安电子科技大学联合开发。
- ScripterAgent：采用 SFT + RL 两阶段范式进行训练，负责将粗略对话转化为细粒度、可执行的结构化电影剧本。
- DirectorAgent：负责调度视频生成模型，采用带有帧锚定的跨场景连续生成策略，以保持长程视觉连续性。
- CriticAgent 与新指标：引入 AI 驱动的评估智能体和视觉-剧本对齐度 VSA 指标，从技术和电影艺术角度检查结构有效性与语义保真度。
- 剧本生成表现：专家评分显示，ScripterAgent 在戏剧张力 4.1 对 3.7、视觉意象 4.3 对 3.8 两项上优于基线模型。
- 视频生成提升：该框架提升了 Sora2-Pro 和 Veo3.1 等模型表现，剧本忠实度提升高达 +0.4 分。
- 连贯性提升：VSA 指标结果显示平均时序-语义连贯性提升超过 7 分。
- 演示支持：项目页面提供了可按案例比较的多模型视频生成演示。

## 正文

### 概述

近期的视频生成模型能够根据简单文本提示合成高质量视觉画面，但仍难以从对话等高层概念生成连贯的长篇叙事，创作意图与电影级执行之间存在语义鸿沟。

该项目提出了一个用于对话到电影级视频生成的端到端智能体框架。核心组件 `ScripterAgent` 经过训练，可将粗略对话转化为细粒度、可执行的电影剧本。生成的剧本随后交由 `DirectorAgent` 使用跨场景连续生成策略调度视频模型，以维持长时程连贯性。

评估部分包含由 AI 驱动的 `CriticAgent`，以及视觉-剧本对齐度 `Visual-Script Alignment`（`VSA`）指标。文中给出的结果显示，该框架在受测模型上提升了剧本忠实度与时序保真度。

### 方法论

#### ScripterAgent

`ScripterAgent` 将粗略对话转化为结构化电影剧本，训练方式为两阶段范式 `SFT + RL`，目标是使输出更贴近专业导演标准。

#### DirectorAgent

`DirectorAgent` 负责调度视频生成模型，使用带帧锚定的跨场景连续生成策略，以保持跨场景视觉连续性并缓解时序不连贯问题。

#### CriticAgent

`CriticAgent` 从技术与电影表达两个角度评估生成结果，通过自动化指标与 `VSA` 检查结构有效性和语义保真度。

### 实验结果

#### 主要发现

- 剧本生成方面：`ScripterAgent` 在报告的专家评分中优于基线模型，戏剧张力为 `4.1` 对 `3.7`，视觉意象为 `4.3` 对 `3.8`。
- 视频生成方面：使用该框架生成的剧本可提升多个 SOTA 视频模型表现，示例中包含 `Sora2-Pro` 与 `Veo3.1`，剧本忠实度提升最高 `+0.4` 分。
- 权衡关系：分析指出不同模型系列中存在“视觉表现力”与“剧本契合度”的权衡。
- 时序表现：`VSA` 指标显示平均时序-语义连贯性提升超过 `7` 分。

### 演示

页面提供视频生成演示，支持按案例对比不同视频生成模型输出。

## 关联主题

- [[00-元语/Agent]]
- [[00-元语/AI]]
- [[00-元语/multimodal]]
- [[00-元语/video]]
- [[00-元语/evals]]
- [[00-元语/alignment]]
- [[00-元语/llm]]
- [[00-元语/paper]]
