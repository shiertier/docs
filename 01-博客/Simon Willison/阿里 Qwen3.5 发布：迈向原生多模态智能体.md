# 阿里 Qwen3.5 发布：迈向原生多模态智能体

## 文档信息
- 来源：https://simonwillison.net/2026/Feb/17/qwen35/#atom-everything
- 发布日期：2026-02-15

## 摘要
**1) 一句话总结**
阿里 Qwen 团队发布了支持视觉输入的多模态大模型 Qwen 3.5 系列的首批两款模型，包括拥有 3970 亿参数的高效开源权重 MoE 模型，以及支持高达 100 万 token 上下文的专有托管模型 Qwen3.5 Plus。

**2) 关键点**
* **多模态支持**：首批发布的两款模型（一款开源，一款专有）均原生支持视觉输入功能。
* **开源模型架构**：开源模型 Qwen3.5-397B-A17B 采用混合专家（MoE）架构，结合了线性注意力（门控增量网络）与稀疏 MoE 以提升推理效率。
* **参数与激活量**：开源模型总参数量达 3970 亿，但每次前向传播仅激活 170 亿参数，在保障性能的同时优化了速度与成本。
* **模型体积与版本**：开源模型在 Hugging Face 上的原始体积为 807GB；Unsloth 提供了体积更小的 GGUF 格式版本（大小从 94.2GB 到 462GB 不等）。
* **专有模型定位**：专有托管模型 Qwen3.5 Plus 2026-02-15 是 397B 模型的托管 API 版本。
* **超长上下文**：专有模型原生支持 256K tokens，但实际支持高达 100 万 token 的上下文长度。
* **附加功能**：专有模型支持搜索和代码解释器功能，用户可在 Qwen Chat 的自动模式（Auto mode）下调用。

## 正文
阿里巴巴的 Qwen 团队刚刚发布了 Qwen 3.5 系列的首批两款模型——一款为开源权重模型，另一款为专有模型。这两款模型均支持视觉输入的多模态功能。

### 开源权重模型：Qwen3.5-397B-A17B

这款开源权重模型是一个混合专家（MoE）模型，名为 Qwen3.5-397B-A17B。值得注意的是，Qwen 官方特别强调了该架构在服务效率方面的优势：

该模型基于创新的混合架构，将线性注意力（通过门控增量网络 Gated Delta Networks）与稀疏的混合专家架构相结合，实现了卓越的推理效率。尽管其总参数量高达 3970 亿，但每次前向传播仅激活 170 亿参数，在不牺牲性能的前提下优化了速度和成本。

该模型在 Hugging Face 上的体积为 807GB。此外，Unsloth 提供了一系列体积更小的 GGUF 格式版本，大小从 94.2GB（1-bit）到 462GB（Q8_K_XL）不等。

我从 OpenRouter 托管的模型中得到了关于“鹈鹕”的测试结果。

### 专有托管模型：Qwen3.5 Plus

专有托管模型名为 Qwen3.5 Plus 2026-02-15，其定位稍显复杂。Qwen 研究员 Junyang Lin 对此解释道：

> Qwen3-Plus 是 397B 模型的托管 API 版本。虽然该模型原生支持 256K tokens，但 Qwen3.5-Plus 支持高达 100 万 token 的上下文长度。此外，它还支持搜索和代码解释器功能，用户可以在 Qwen Chat 的自动模式（Auto mode）下使用这些功能。

我也测试了该模型生成的“鹈鹕”，其质量与开源权重模型非常相近。

## 关联主题
- [[00-元语/llm]]
- [[00-元语/multimodal]]
- [[00-元语/Agent]]
