# 大语言模型高考数学拿高分靠强化学习，那文科考高分得靠什么？

## 文档信息
- 来源：https://baoyu.io/blog/large-language-model-arts-exam-success
- 发布日期：2025-06-27
- 作者：宝玉

## 摘要

### 1) 一句话总结
大语言模型（如豆包1.6系列）在高考文科中取得683分的高分，主要归功于高质量的人文训练数据、自适应思维链（CoT）推理、长上下文处理能力以及多模态直接读图技术。

### 2) 核心要点
*   **成绩表现**：豆包1.6系列在高考文科全科试卷中获得 683 分（满分 750 分），按山东赋分排名达到清华北大的录取水平。
*   **文科训练差异**：文科题目缺乏标准答案，无法像数学或编程那样单纯依赖强化学习（自我刷题对答案）来提升能力。
*   **训练数据优化**：模型使用了比例更高、质量更好的人文领域语料，通过清洗去重提高了知识密度，从而在历史、地理、政经等需要大量记忆的科目中表现优异。
*   **思维链（CoT）推理**：复杂文科题（如英语翻译）通过多步内在思考、拆解和自我检查，能显著提高正确率。
*   **自适应思考模式（AdaCoT）**：先进模型（如 Claude 4、豆包 Seed 1.6）能根据提示词复杂度动态决定思考模式（全思考、不思考或自适应），以平衡答题效率。
*   **256K 长上下文**：文科综合常有“长材料＋多问”题型，256K 的长上下文窗口使模型能一次性读取全部材料与提问，避免信息割裂。
*   **多模态直接读图**：模型（如 Gemini、豆包 Seed 1.6）在预训练中混合图文并融合视觉奖励，能直接且精准地提取地图、统计图等关键信息。

### 3) 风险与不足（基于原文）
*   **思维链的时间与算力成本**：强制对所有问题使用思维链会增加时间成本和算力消耗，在有时间限制的考试场景下，可能导致题目做不完。
*   **长上下文的遗忘问题**：部分号称支持长上下文的模型，在输入内容过长时会出现生成质量下降或记不住输入内容的情况。
*   **非多模态模型的信息损耗**：不支持原生多模态的模型（如 DeepSeek R1）在处理图表题时，只能依赖 OCR 将图片转为文字，这会导致严重的视觉信息损耗。

## 正文
上次分析了大语言模型在高考数学考试中拿高分靠的是强化学习，也就是在后训练阶段，自己训练自己做有标准答案的数学题或者编程题，反复的自己刷题，做完题目对答案，答案做对了就有奖励，做错了就有惩罚，最终自己训练自己越练越牛。但是文科这样做行不通，因为文科很多题目没有标准答案，它就没有办法用文科题目自己训练自己，做强化学习。

那么这次豆包1.6系列在高考文科全科试卷中，拿到了 683 分（满分 750）的高分，按山东高考的赋分排名是够上清北的，靠的是什么呢？

![Image 1](https://baoyu.io/uploads/2025-06-27-image.png)

我分析下来主要有几个原因：

1.   训练数据

2.   思维链（CoT，Chain of Thought）

3.   长上下文

4.   多模态直接读图

接下来我稍微解释一下

### 1. 训练数据：人文领域语料比例更高、质量更好

虽然我们有时候开玩笑说文科要考死记硬背，但这也确实反应了文科科目是需要大量记忆的，优质的语料至关重要，不仅要保证数据更新及时，还需要对数据清洗去重，提高知识密度和领域覆盖度。这样模型在回答历史叙事、地理概念、政治与经济常识等题型上，因为“见过的例子更多”，自然可以回答的更好，分数更高。

### 2. 思维链：文科也要思考

文科考试不意味着真的只是靠死记硬背，对于复杂的题目同样需要推理，思维链可以在输出答案前进行多步内在思考，逐步拆解，再生成结构化答案，可显著提高复杂问题的正确率。一个简单的例子就是英语翻译，如果在翻译完一遍后，让 AI 自己对翻译内容进行检查，输出检查结果，再基于检查和第一次翻译的结果重新翻译，翻译质量就会显著提高。

那么是不是什么问题都要加上思维链呢？

也并非这样，因为对于很多文科题目来说，可以直接输出答案而不必借助思维链，比如一些历史事件的年份之类，思维链毕竟是有时间成本和算力成本的，考试都有时间要求，做的时间长了可能就来不及做完了。所以现在先进的模型都会根据问题的复杂程度，来决定要不要推理，已经推理时长多少，比如 Claude 4、豆包 Seed 1.6都是如此，模型可以动态决定思考模式：

*   全思考（FullCoT）：对所有 prompt 都会进行思考再给出回答，同时对 CoT 长度进行了压缩

*   不思考（NoCoT）：对所有 prompt 都不会进行思考，直接回答，效率更高

*   自适应思考（AdaCoT）：以上两种模式的融合，模型会根据不同的 prompt，自动选择是否进行思考

### 3. 长上下文：长材料题一口气读完

在我们向 AI 提问时，上下文指的是给 AI 发送、AI 推理思考的内容和 AI 最终生成的所有信息。不同的模型上下文窗口长度限制不同，比如早期 GPT-3.5 只有 4K 的上下文窗口长度，如果让它做复杂的很长的阅读分析题，它就力不从心了，而长上下文不仅意味着要能输入很长的内容，同时输入的内容多了还不能降低生成质量，所以你看很多模型虽然号称上下文窗口多大多大，但是输入的内容长了就记不住输入的内容了。

大语言模型要在高考的文科考试中取得好成绩，文科综合常见“材料阅读＋多问”——几十行材料文本接着 3-5 问，上下文长度是很重要的。豆包这次能文科拿第一，256K 上下文长度是很重要的，让模**一次性看到全部材料与提问**，避免截断信息导致的丢失或前后矛盾。

### 4. 多模态直接读图：不需要担心图片转成文字造成的损耗

高考地理、生物、化学经常出现统计图、实验装置图、地图，在需要读图的考试时，不支持多模态的大模型就吃亏了，比如 DeepSeek R1 能力不错，但是做这类题时只能借助 OCR 把图片变成文字再答题，像地图、图表这些内容是很难用文字描述清楚的，这就好比一个盲人看不见，靠另一个人来描述，就会损耗很多信息，而多模态就好比人有了眼睛，能直接看到画面，就不会丢失关键信息。

像这次考试拿高分的 Gemini、豆包 Seed 1.6，对于多模态都支持很好，在预训练里就把图像-文本混合，RL 强化训练阶段又融合了视觉奖励**能精准提取图表关键信息，再结合文本作答**。

小结
--

因此，大模型在语、史、地等文科科目的选择题、材料题、论述题上要能交出接近“优秀考生”甚至顶尖考生水平的答卷，依靠的主要是：

*   **记忆面宽**：高质量语文/历史/地理语料 + 高频人文知识蒸馏。

*   **思考后再回答**：回答复杂问题前先思考。

*   **看图能力强**：图文交织预训练 + 视觉 RM ，让地图、表格、示意图不再是盲区。

*   **材料吃得下**：上下文把“整卷+材料”全放进 prompt，减少信息割裂。

## 关联主题

- [[00-元语/llm]]
- [[00-元语/multimodal]]
- [[00-元语/context-optimization]]
- [[00-元语/evals]]
- [[00-元语/benchmark]]
- [[00-元语/Claude]]
- [[00-元语/gemini]]

## 相关文档

- [[01-博客/宝玉/当 AI 能考上一本，十年寒窗苦读还有意义吗？|当 AI 能考上一本，十年寒窗苦读还有意义吗？]]；关联理由：版本演进；说明：两文围绕同一命题的不同阶段，前文讨论文科达一本线的意义，本文进一步解释文科高分背后的技术机制。
