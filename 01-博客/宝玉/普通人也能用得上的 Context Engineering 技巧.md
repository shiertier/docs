# 普通人也能用得上的 Context Engineering 技巧

## 文档信息
- 来源：https://baoyu.io/blog/context-engineering-skills-for-normal-users
- 发布日期：2025-08-04
- 作者：宝玉

## 摘要

**1) 一句话总结**
本文总结了面向普通用户的上下文工程（Context Engineering）技巧，核心在于通过控制“更少且聚焦”与“更准确且充足”的上下文，来显著提升 AI 的任务执行效率与体验。

**2) 核心要点**
* **精简上下文**：提示词并非越长越好，核心是剔除无关信息，让 AI 聚焦于主要任务。
* **多开新会话**：避免无限延长单个会话；在阶段性任务后让 AI 总结重点，并在开始新任务时主动开启新会话。
* **拆解小任务**：避免一次性堆积复杂任务，每次只交办一个清晰简单的小任务。
* **主动提供信息**：用户需主动提供完成任务所需的全部关键背景（如写简历时的个人经历、编程时的相关代码文件）。
* **选用优质 Agent 模型**：利用表现优异的模型（如 Claude 4 Opus/Sonnet、GPT-4o/o3、Doubao Think 1.6、GLM 4.5、Kimi K2）来辅助搜寻上下文。
* **为 AI 提供工具**：通过提供 MCP 工具、测试命令（如 `npx jest`）或截图对比工具，让 AI 能够自主获取数据、运行测试并迭代修正结果。
* **执行前先做计划**：在复杂任务中启用计划模式（Plan mode），由人工审阅并确认 AI 的执行方向无误后再开始实际操作。

**3) 风险/不足**
* **幻觉风险**：当提示词包含过多无关信息时，AI 生成的结果容易混乱甚至出现幻觉。
* **信息遗漏**：长时间的单个会话容易导致 AI 难以抓住重点，进而引发信息遗漏或混乱。
* **测试作弊风险**：在让 AI 自主运行代码测试时，AI 可能会为了通过测试而直接修改测试代码，因此仍需人工审核。
* **资源浪费**：面对复杂任务时，如果 AI 一开始方向错误，可能会在错误的路线和计划上持续浪费资源与时间。

## 正文
现在讨论 Context Engineering（上下文工程）时，大多关注如何构建高级 AI Agent，但对普通用户来说，这些技术未必实用。我在这里总结了一些普通人使用 AI 时真正能用到的上下文工程技巧。

Context Engineering 的中有两个关键点可以帮助你控制好上下文：

1.   **更少的上下文**

2.   **更准确的上下文**

下面我们分别展开讲讲如何做到这两点。

* * *

一、更少的上下文：精简比繁杂更有效
-----------------

如今很多提示词（Prompt）都非常长，似乎“越长越好”，但实际上，这种方式可能适得其反。当提示词包含太多无关信息时，AI 生成的结果容易混乱，甚至出现幻觉，表现越来越差。

> 需要补充说明一下：**这里的“少”不是说越少越好，重点是让 AI “聚焦”于主要任务。**

所以要注意以下两个要点：

### 1）多开新会话，而不是无限延长单个会话

长时间的单个会话容易让 AI 难以抓住重点，导致信息遗漏或混乱。更好的做法是：

*   聊到一定阶段，让 AI 帮忙总结重点。

*   在新任务或无关联任务开始时，主动开启新的会话，保持每个会话清晰而专注。

### 2）一次只做一个小任务，而非复杂任务堆积

和人类一样，当任务过于复杂、一次性输入太多时，AI 会难以很好地完成。但如果每次只交给 AI 一个清晰简单的小任务，AI 就能更轻松地理解并高效完成。

* * *

二、更准确的上下文：让 AI 明确知道你想要什么
------------------------

“准确的上下文”听起来简单，其本质就是让 AI 明白你真正想要的结果，以及完成任务所需的全部信息。具体而言，可以通过以下两种方式实现，而这两种方式通常是互为补充的：

### （一）主动提供准确而充足的上下文

AI 并不天然了解我们掌握的信息，因此用户需要主动告诉 AI：

*   例如，让 AI 帮忙写简历时，必须清晰地把自己的经历和相关信息提供给 AI，否则它也难以编出满意的结果。

*   在编程场景中，把相关文件或代码片段提前提供给 AI，这样能有效避免遗漏重要信息或细节，减少反复调整的麻烦。

总之，“你不说，它就不知道”，主动提供充分而准确的上下文，能显著提高 AI 完成任务的效果。

* * *

### （二）借助 AI Agent 来寻找上下文

有时，我们自己也不清楚全部上下文。这时，可以利用 AI Agent 的工具能力帮助我们主动获取上下文。下面几个技巧对普通用户特别有效：

#### 1）选择擅长 Agent 任务的模型

当前表现优异的 AI Agent 模型有：

*   国外的 Claude 4 Opus/Sonnet、OpenAI 的 GPT-4o（o3）等。

*   国产的 Doubao Think 1.6、GLM 4.5、Kimi K2 等也有很强的表现。

选对模型，可以显著提升 Agent 搜寻上下文的准确性和效率。

#### 2）为 AI 提供适合的工具

Agent 最大优势就是能借助工具寻找上下文。不过，AI 默认工具有限，因此用户需要额外提供工具：

*   例如 MCP 工具，让 AI 访问内部数据、控制浏览器等，提升搜索上下文的效率。

*   在编程场景中，一个实用技巧是主动提供验证代码的机制，让 AI 自己测试和修正结果。

具体举个例子，比如在 Claude Code 或 Copilot/Cursor Agent 模式下，你可以加上一句：

```
Please write tests and verify the tests by running
npx jest <testfilepath> -c './jest.config.ts' --no-coverage
```

这样 AI 写完代码后会主动写测试，并自己执行命令验证测试结果。如果出现问题，AI 也会主动修复，直到通过测试（当然，仍需人工审核，避免 AI 为了通过测试而修改测试代码）。

类似技巧还有：

*   提供运行代码并截图的工具，让 AI 写完 UI 后自己对比实际效果和设计稿，自动迭代直到结果满意。

#### 3）让 AI 先做计划，避免在错误方向上浪费时间

面对稍微复杂的任务时，AI 如果一开始方向错了，可能会一直在错误的路线上浪费资源。这时就需要：

*   要求 AI 在执行任务前先做计划（Plan mode），比如 Claude Code 就提供了这样的模式。

*   仔细审阅 AI 提供的计划，确认方向无误后再执行。

*   如果发现 AI 方向错误，要及时纠正，甚至直接新开会话、调整提示词，让 AI 明确正确的路线，再重新开始任务。

* * *

总结一下
----

面向普通用户的 Context Engineering，可以尝试：

*   **少而精的上下文**：少提供无用信息，多用简洁清晰的新会话解决单个小任务；

*   **准确而充足的上下文**：主动明确表达需求、提供关键信息，或巧妙利用 Agent 工具，让 AI 主动获取有效信息。

掌握这些技巧，能大幅提高普通用户使用 AI 的效率与体验。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/Agent]]
- [[00-元语/context-optimization]]
- [[00-元语/llm]]
- [[00-元语/mcp]]
- [[00-元语/prompt]]
- [[00-元语/workflow]]
