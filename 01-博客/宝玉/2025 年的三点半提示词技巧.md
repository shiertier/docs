# 2025 年的三点半提示词技巧

## 文档信息
- 来源：https://baoyu.io/blog/2025-prompt-engineering-tips
- 发布日期：2025-01-01
- 作者：宝玉

## 摘要

**1) 一句话总结**
2025年随着大模型能力提升，编写提示词不再需要依赖复杂框架，核心只需掌握提供上下文、明确指令、任务原子化以及善用思维链这“三点半”技巧。

**2) 核心要点**
* **弱化复杂框架**：2025年模型能力已大幅提升，提示词编写门槛降低，无需再死记硬背繁杂的提示词技巧与框架。
* **Context（上下文）**：必须为模型提供相关的背景信息，但需注意控制文本长度，具体长度限制可通过测试不同模型来摸索。
* **Instruction（明确指令）**：需清晰说明要模型执行的任务；若自身思路不清，可先通过临时会话与模型闲聊梳理，明确后再新开会话输入指令与上下文。
* **Atom（原子化）- 任务拆分**：每次分配给模型的任务应当尽量小，避免要求模型一次性完成过多任务。
* **Atom（原子化）- 上下文独立完整**：单次会话中必须包含AI生成所需的全部完整或关键内容，确保提示词放到任何模型或应用中都能独立运作。
* **CoT（思维链）**：思维链已成为大模型（尤其是推理模型）的基本技能；若已知最优推理步骤应直接写明，未知则交由模型生成，不满意可通过多轮交互或更换模型来改进。

**3) 风险与不足**
* **上下文过长风险**：提供的上下文长度越长，模型的输出效果可能会越差。
* **外部链接访问限制**：若参考资料仅提供URL且AI应用无法访问，会导致上下文信息不完整。
* **上下文窗口截断风险**：在持续问答的长会话中，AI应用可能会因上下文窗口长度限制，自动截断或摘要前面的内容，导致后续会话缺失关键上下文。

## 正文
2025 年了，模型能力上升了一个台阶，更不需要去记提示词技巧和框架了，写提示词不再是一个多专业的活，核心就记住三点半：

1. Context：问题所需要的上下文信息，千万别以为模型会读心术，一定要把相关信息都提供；但是长度不要太长，因为长度越长效果越差，多长不同模型有区别，多试试就知道了。

2. Instruction：你想要模型做什么说清楚。如果自己都没想清楚，就先临时开个会话和模型闲聊，让它帮你梳理清楚，梳理清楚指令了再新开会话输入你的指令和上下文。

3. Atom：让你的提示词原子化，这里其实有两点含义：

- 1) 你每次的任务要小，不要想让模型一次完成太多任务

- 2) 上下文完整独立，在你的会话中把这次任务的上下文都提供清楚了

最后还有半点：

CoT：思维链（Chain of Thought）对于大语言模型来说已经慢慢成了基本技能，尤其是推理模型，高于人类平均水平，如果你明确知道最优步骤，就写上，不确认就让模型写，不满意就让模型改进，还不满意就新开会话或者换模型再试试。

* * *

补充1: 上下文完整独立的意思就是在一次会话中，你包含了AI生成所需要的完整内容，并且确保不会因为 AI 应用程序的能力限制而影响。

以写报告为例，你报告中需要参考资料1，2，3，那么这些参考资料的完整部分或者关键部分要在会话中完整包含。

如果你的参考资料是一个 URL，你的应用程序（比如ChatGPT）是无法访问这个 URL 的，那么它无法有效的把这个 URL 作为上下文的一部分，所以你的上下文就不完整了。

再比如你在前几轮会话中把参考资料放在里面了，但是你持续问答增加会话，到后面的时候，AI 应用程序会因为上下文窗口长度限制，会自作主张帮你把前面的内容砍掉或者摘要，那你后面的会话就缺少上下文了。

判断独立完整的一个标准，就是你的提示词，放到任何模型任何AI应用，信息都是完整的，不会因为 AI 应用的能力（比如URL访问、上下文窗口长度限制）而导致内容缺失。

## 关联主题
- [[00-元语/prompt]]
- [[00-元语/context-optimization]]
- [[00-元语/workflow]]
- [[00-元语/llm]]
