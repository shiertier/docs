# 什么时候该用多智能体是不是一定要用多智能体？

## 文档信息
- 来源：https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot
- 发布日期：2024-06-26
- 作者：宝玉

## 摘要

### 1) 一句话总结
本文以大语言模型翻译任务（直译、反思、意译）为例，对比了“单Prompt多步骤”与“多智能体”两种方案的优缺点，并提出了“先用多智能体拆解跑通流程，再优化合并为单Prompt”的实践原则。

### 2) 核心要点
*   **典型应用场景**：当前大语言模型翻译的最佳实践通常包含三个步骤：直译、反思和意译。这既可以通过单Prompt完成，也可以通过三个独立的智能体完成。
*   **单Prompt多步骤的优势**：最大化节约Token和时间成本，无需编写额外代码处理交互，可直接在ChatGPT等聊天应用或API中使用。
*   **单Prompt多步骤的局限**：无法对中间步骤（如直译结果）进行人工干预或修改；对模型指令遵循能力要求高。
*   **多智能体的优势**：允许在每一步中间输出后进行人工处理；每个智能体专注单一任务，Prompt编写难度低；支持混合使用不同成本的模型（如便宜模型直译，昂贵模型反思）。
*   **多智能体的局限**：需要额外代码或配置来处理智能体间的交互；Token消耗大（存在重复上下文）；串行处理会导致时间成本增加。
*   **核心决策原则**：遵循“化繁为简，分而治之”的思路，先用多智能体将复杂任务拆解为简单任务以跑通流程，避免“过早优化”。
*   **后续优化路径**：在多智能体流程跑通且Prompt优化完善后，再尝试将多个智能体合并为一个Prompt，以提升经济性和效率。
*   **低成本测试方法**：在编写代码搭建多智能体系统前，可先在聊天应用中通过手动复制粘贴中间结果来验证Prompt和流程。

### 3) 风险/不足
*   **模型能力瓶颈风险**：单Prompt多步骤方案对模型能力要求较高，能力较弱的模型（如GPT-3.5）无法胜任复杂的单Prompt多步指令。
*   **成本与性能风险**：多智能体方案由于需要独立输入输出，存在大量重复的上下文，导致Token成本显著增加；且节点间的等待会增加整体时间延迟。
*   **数据解析风险**：在单Prompt多步骤方案中，所有步骤结果集中在一次输出中，若需提取特定步骤结果，必须依赖结构化输出（如XML、JSON）并增加解析复杂度。
*   **开发策略风险**：一开始就追求单Prompt（过早优化）可能导致复杂任务的提示词难以编写和调试，增加项目失败或延期的风险。

## 正文
现在智能体的概念很火，并且很多时候都需要多个智能体配合工作。但是，真的都需要用多个智能体吗？什么时候该用多智能体？

我们以大语言模型翻译为例。众所周知，现在大语言翻译，最佳实践是直译、反思和意译三个步骤，我以前有分享过 Prompt，可以在在一个 Prompt 中，让 ChatGPT 一次性完成这三个步骤。详细内容可以参考我以前写过的文章《直译、反思、意译：提升 GPT 翻译质量的一种新策略》[https://baoyu.io/blog/prompt-engineering/translator-gpt-prompt-v2](https://baoyu.io/blog/prompt-engineering/translator-gpt-prompt-v2)

吴恩达老师前不久也分享过一个项目，同样也是直译、反思和意译的思路，但是采用的多智能体，也就是不是整个过程不是在一个 Prompt 中完成，而是有三个智能体分别完成这三个步骤，每个智能体都有独立的 Prompt。

为了方便大家理解，我来举个例子，比如我要翻译一句话：“She was born with a silver spoon in her mouth.”

[](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E4%B8%80%E4%B8%AA-prompt-%E4%B8%AD%E7%9A%84%E5%A4%9A%E6%AD%A5%E9%AA%A4)一个 Prompt 中的多步骤
----------------------------------------------------------------------------------------------------------------------------------------------------------

如果是在一个 Prompt 中（具体 Prompt 可以参考我前面的文章链接），那么 LLM 的输出大概就是这样的：

#### [](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E8%BE%93%E5%85%A5)输入

请按照直译、反思和意译的步骤，翻译下面这句话：

She was born with a silver spoon in her mouth.

好的，以下是按照直译、反思和意译的步骤翻译这句话：

1. **直译**：

她出生时嘴里含着银勺子。

2. **反思**：

这句话在英语中是一个惯用表达，意思是她生在富贵之家。直译的结果在中文中可能会让人感到困惑，因为含着银勺子并不是中文中的常见表达方式。

3. **意译**：

她出生在富贵之家。

![Image 1](https://baoyu.io/images/ai/when-to-use-multi-agent-systems-or-cot/fig1.png)

[](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E5%A4%9A%E4%B8%AA%E6%99%BA%E8%83%BD%E4%BD%93)多个智能体
----------------------------------------------------------------------------------------------------------------------

如果用多智能体来做，那么就是三个智能体分别完成这三个步骤，如果你想看吴恩达老师写的 Prompt 和程序，可以参考：https://github.com/andrewyng/translation-agent/blob/main/src/translation_agent/utils.py（`https://github.com/andrewyng/translation-agent/blob/main/src/translation_agent/utils.py`），这里我简化模拟一下：

#### [](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E7%9B%B4%E8%AF%91%E6%99%BA%E8%83%BD%E4%BD%93)直译智能体

直译智能体的输入：

请翻译这句话：

She was born with a silver spoon in her mouth.

直译智能体的输出：

她出生时嘴里含着银勺子。

![Image 2](https://baoyu.io/images/ai/when-to-use-multi-agent-systems-or-cot/fig2.png)

#### [](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E5%8F%8D%E6%80%9D%E6%99%BA%E8%83%BD%E4%BD%93)反思智能体

反思智能体的输入：

<SOURCE_TEXT>

She was born with a silver spoon in her mouth.

</SOURCE_TEXT>

<TRANSLATION>

她出生时嘴里含着银勺子。

</TRANSLATION>

请检查上面的翻译，反思其中存在的问题，输出仅包含问题列表。

反思智能体的输出：

1. 翻译缺乏成语和习语的文化背景，未能传达原文中的隐含意义。

2. 直译“银勺子”可能在中文中显得生硬，不自然。

3. 翻译没有体现出“生来富裕”这一含义，仅描述了物理现象。

![Image 3](https://baoyu.io/images/ai/when-to-use-multi-agent-systems-or-cot/fig3.png)

#### [](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E6%84%8F%E8%AF%91%E6%99%BA%E8%83%BD%E4%BD%93)意译智能体

意译智能体的输入：

<SOURCE_TEXT>

She was born with a silver spoon in her mouth.

</SOURCE_TEXT>

<TRANSLATION>

她出生时嘴里含着银勺子。

</TRANSLATION>

<EXPERT_SUGGESTIONS>

1. 翻译缺乏成语和习语的文化背景，未能传达原文中的隐含意义。

2. 直译“银勺子”可能在中文中显得生硬，不自然。

3. 翻译没有体现出“生来富裕”这一含义，仅描述了物理现象。

</EXPERT_SUGGESTIONS>

请根据直译和反思的结果，重新意译，并输出最终翻译结果，不包含任何其他信息。

意译智能体的输出：

她出生在富贵之家。

![Image 4](https://baoyu.io/images/ai/when-to-use-multi-agent-systems-or-cot/fig4.png)

[](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E4%B8%80%E4%B8%AA-prompt-%E5%A4%9A%E4%B8%AA%E6%AD%A5%E9%AA%A4-vs-%E5%A4%9A%E4%B8%AA%E6%99%BA%E8%83%BD%E4%BD%93)一个 Prompt 多个步骤 vs 多个智能体
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

从上面的例子可以看出，两者的原理类似，结果也差不多，那么他们的区别是什么呢？

### [](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E4%B8%80%E4%B8%AA-prompt-%E5%A4%9A%E4%B8%AA%E6%AD%A5%E9%AA%A4)一个 Prompt 多个步骤

先说优点：

一个 Prompt 多个步骤，可以最大化的节约 Token，充分利用 LLM 输出的内容作为上下文，不需要多次输入输出，节省了时间和资源。

使用简单，只需要一个 Prompt，不需要额外的代码来处理多个智能体之间的交互。

既可以在 ChatGPT 这类聊天应用中使用，也可以在 API 中使用，适用范围广。比如我的科技文章翻译 GPT（[https://chatgpt.com/g/g-uBhKUJJTl-ke-ji-wen-zhang-fan-yi），就是使用一个](https://chatgpt.com/g/g-uBhKUJJTl-ke-ji-wen-zhang-fan-yi%EF%BC%89%EF%BC%8C%E5%B0%B1%E6%98%AF%E4%BD%BF%E7%94%A8%E4%B8%80%E4%B8%AA) Prompt 多个步骤的方式。

再说缺点：

不能对中间输出结果进行修改，比如我希望对第一步直译的结果，人工替换一些关键字，然后再进行反思和意译，这是做不到的。

对输出的解析相对复杂，由于所有步骤的结果都在一个输出中，所以就需要输出结构化的数据，比如 XML、JSON 等，然后再解析。当然对输出解析也不是必须的，比如我的科技文章翻译 GPT，就是直接输出文本，手动把意译的结果复制出来。

对模型能力要求比较高，需要模型能有很强的理解指令的能力，像这这样的一个 Prompt 多个步骤翻译的 Prompt 在 GPT-3.5 中是做不到的。

### [](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E5%A4%9A%E4%B8%AA%E6%99%BA%E8%83%BD%E4%BD%93-1)多个智能体

优点：

可以对每一步的中间输出结果进行处理，比如我希望对直译的结果，人工替换一些关键字，然后再进行反思和意译，这是可以做到的。

每一个智能体专注于完成一件任务，Prompt 写起来容易。

可以多个模型混合使用，比如说直译的时候可以用便宜的模型，反思和意译的时候用贵的模型。（不是说这样效果会好，只是举个例子）

缺点：

需要额外的代码来处理多个智能体之间的交互，比如上面的例子，需要一个中间层来处理直译的结果，然后传递给反思智能体，再传递给意译智能体。（可能有些低代码无代码平台可以不写代码，但是也需要配置。）

时间成本和 Token 成本相对高，从上面的例子你可以看到，如果多个智能体之间不能并行处理，那么就需要等待上一个智能体的输出，然后再传递给下一个智能体，这样就会增加时间成本。另一就是 Token 成本也相对较高，因为每个智能体要独立输入输出，有很多重复输入输出在里面。

无法直接在 ChatGPT 这类聊天应用中使用多智能体，除非你愿意手动一个个复制粘贴。或者借助 ChatGPT 的 `@` 功能。

[](https://baoyu.io/blog/ai/when-to-use-multi-agent-systems-or-cot#%E4%BB%80%E4%B9%88%E6%97%B6%E5%80%99%E8%AF%A5%E7%94%A8%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E6%98%AF%E4%B8%8D%E6%98%AF%E4%B8%80%E5%AE%9A%E8%A6%81%E7%94%A8%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93)什么时候该用多智能体？是不是一定要用多智能体？
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

我的一个简单的原则： **先用多智能体把流程走通，然后再看看能不能优化成一个 Prompt 多个步骤。**

这可能有点违法直觉，因为一个 Prompt 多个步骤看起来更简单更经济，但是 Prompt Engineer 是一个相对新的领域，有时候写提示词就像是玄学，对于复杂的任务，你很难一下子写出一个完美的 Prompt。

当你用多智能体，那么你首先要做的就是把你的复杂任务拆分成了多个简单的任务，这其实是相当重要的一步，这样你才能化繁为简，分而治之。

当你拆分成简单任务后，每一个任务相对就好去完成去写 Prompt 了。

等到整个流程跑通，再看看能不能把其中某几个智能体合并成一个智能体，本质上就是把多个 Prompt 合并成一个 Prompt。

记住这句话：“**过早优化是万恶之源。**”

另外并不是说一开始就要去写代码搭建一个智能体系统，完全可以现在 ChatGPT 这样的聊天应用中，手动写 Prompt，把中间结果手动复制粘贴一下，等到 Prompt 优化好了流程走通了，再去写代码搭建智能体系统也不迟。

## 关联主题

- [[00-元语/Agent]]
- [[00-元语/prompt]]
- [[00-元语/workflow]]
- [[00-元语/llm]]
- [[00-元语/decision-making]]
- [[00-元语/context-optimization]]
