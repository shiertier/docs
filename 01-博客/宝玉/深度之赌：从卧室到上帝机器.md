# 深度之赌：从卧室到上帝机器

## 文档信息
- 来源：https://baoyu.io/blog/deep-bet-from-bedroom-to-god-machine
- 发布日期：2025-12-27
- 作者：宝玉

## 摘要

**1) 一句话摘要**
本文基于Geoffrey Hinton与Jeff Dean的对话，回顾了深度学习从早期算力探索、AlexNet突破、TPU芯片诞生到大模型团队整合的十余年关键发展历程与核心商业决策。

**2) 关键要点**
*   **早期探索失败**：1990年，Jeff Dean尝试用32个处理器并行训练神经网络，但因仅增加算力而未扩大模型规模导致效率极低。
*   **Google Brain起源**：2011年，Jeff Dean与Andrew Ng启动DistBelief项目，调用1.6万个CPU核心训练出比当时大50倍的模型，成功让机器在无标签情况下学会识别猫脸。
*   **AlexNet的突破**：2012年，Alex Krizhevsky在卧室仅用两块GPU训练出AlexNet，在ImageNet竞赛中取得碾压性胜利，向世界证明了深度学习的实用价值。
*   **黑莓错失良机**：2011年前后，黑莓因依赖实体键盘，拒绝了Hinton团队免费提供的先进语音识别技术，该技术及相关人才随后被Google吸纳。
*   **人才收购拍卖**：2012年底，Hinton与两名学生（Alex和Ilya）成立仅有三人的DNN Research公司进行技术拍卖，最终Hinton主动叫停竞价，选择加入Google。
*   **TPU芯片的诞生**：2013年，为应对新语音模型带来的庞大算力缺口，Jeff Dean利用神经网络对计算精度要求低的特性，申请5000万美元研发了第一代专用AI芯片TPU。
*   **错失聊天机器人首发**：2020年Google内部已有8万员工使用体验良好的聊天机器人，但因其会编造事实，不符合Google搜索对准确性的严格要求而未对外发布。
*   **团队与算力整合**：ChatGPT发布后，Jeff Dean通过内部备忘录推动了Google内部AI力量（Brain与DeepMind）的合并，集中算力全力研发Gemini大模型。

**3) 风险与缺口**
*   **模型幻觉与产品标准冲突**：大语言模型（聊天机器人）存在编造事实和一本正经撒谎的缺陷，这与传统搜索引擎要求100%准确的核心原则存在直接冲突。
*   **人类生存风险**：Geoffrey Hinton明确指出了AI发展可能带来的极端终极风险：“要么我们从此幸福地生活在一起，要么我们全都死了。”

## 正文
![Image 1](https://baoyu.io/uploads/2025-12-27-1766877484353-469c52c4-4908-4270-99d2-5032de8f8a7c.png)

【引子】

2012年冬天，内华达州太浩湖畔，一家赌场。

楼下，赌徒们拉着老虎机，每赢一万美元，铃声大作。楼上，一群搞机器学习的研究者正在开会——这是当年的NeurIPS，没人愿意赌钱，赌场恨死他们了。

但赌场不知道的是，楼上正在进行一场更大的赌博。一个64岁的教授和他的两个学生，正在把自己"卖"给出价最高的买家。每次加价一百万美元。

这三个人后来被称为"深度学习三巨头"中的核心力量。那个教授叫Geoffrey Hinton，刚刚拿了诺贝尔奖。他的两个学生，一个叫Ilya Sutskever，后来创办了OpenAI又离开了；另一个叫Alex Krizhevsky，他在父母家的卧室里训练出了一个叫AlexNet的东西，让整个世界意识到：深度学习真的有用。

![Image 2](https://baoyu.io/uploads/2025-12-27-1766877622893-0fbfe590-f283-4a10-887f-72cd4b36909b.png)

2024年12月，NeurIPS大会上，Hinton和另一个Jeff坐在了一起——Google首席科学家Jeff Dean，传奇工程师，Gemini的负责人。两人聊了一个多小时，把过去十几年的故事抖了出来。

这些故事，串起来就是一部现代AI的秘史。

* * *

【1】一个本科生的愚蠢错误

![Image 3](https://baoyu.io/uploads/2025-12-27-1766877668565-ff25ede5-3310-4d2e-a498-99e6b4f9b970.png)

1990年，明尼苏达大学

1990年，Jeff Dean还是个本科生。他选了两个学期的并行算法课，其中有一周讲到了神经网络。

他着迷了。

于是他跑去找教授Vipin Kumar："我想做个毕业论文，研究怎么用并行计算来训练神经网络。"

系里正好有一台32个处理器的超立方体计算机。Dean想的是：如果能用上32倍的算力，是不是能训练出更厉害的神经网络？

他动手做了两种方法。一种是把数据切开，每个处理器算一部分——三十年后，这叫"数据并行"。另一种是把模型切开，不同的处理器算模型的不同部分——这叫"模型并行"。当时他给它们起了两个怪名字，什么"模式分区"和"模型流水线"之类的。

但他犯了一个愚蠢的错误。

他只增加处理器的数量，却没有增加模型的大小。结果就是，他把一个10个神经元的小网络摊到32个处理器上，效率惨不忍睹。加速曲线难看得要命。

那篇毕业论文写完，他就把神经网络这事儿放下了。在他的脑子里，这只是个"有趣的抽象概念"。

他不知道的是，自己当时其实已经站在了通往未来的门口。他只是还没找到钥匙。

二十年后，他会在Google的微型厨房里遇见一个人，然后一切都会不一样。

* * *

【2】微型厨房里的闲聊

![Image 4](https://baoyu.io/uploads/2025-12-27-1766877678587-85472974-e511-48c0-94ee-e5fb30afa335.png)

2011年，Google总部

Google园区里有很多微型厨房。员工饿了就去拿个零食，渴了就倒杯咖啡。很多重要的对话，就发生在这些不起眼的地方。

2011年的某一天，Jeff Dean走进一间微型厨房，撞见一个面熟的人。

"你怎么在这儿？"

那人叫Andrew Ng，斯坦福的教授，刚开始每周花一天时间在Google兼职。

"我也不太确定要做什么，"Ng说，"不过在斯坦福，我的学生开始用神经网络做东西，效果还不错。"

Dean自从写完那篇本科论文之后，就没怎么关注过神经网络了。但他一直觉得这是个对的方向，只是时机没到。

"有意思，"他说，"我们这儿电脑多。要不试试训练一个特别大的神经网络？"

![Image 5](https://baoyu.io/uploads/2025-12-27-1766877693152-4b7db6c0-ff91-4ea1-ab32-cc520d4b0fc1.png)

当时Google的数据中心里没有GPU，只有成千上万的CPU服务器。Dean开始写一个软件框架，让神经网络的计算能够分摊到几千台机器上。

他们给这个项目起了个名字：DistBelief。意思是"分布式信念"。

几个月后，他们用一万六千个CPU核心，训练了一个比当时任何人都训练过的神经网络大50倍的模型。他们把它放到一千万张YouTube随机截图上，让它自己学习。

没人告诉它什么是猫。但它学会了识别猫脸。

这个项目后来有了个更响亮的名字：Google Brain。

一切都始于微型厨房里的那次闲聊。

* * *

【3】64岁的实习生

![Image 6](https://baoyu.io/uploads/2025-12-27-1766877705560-3585e72e-84e9-49f7-838d-819ad3a88d9b.png)

2012年夏天，Google总部

2012年夏天，Geoffrey Hinton从多伦多飞到加州，要在Google待一个夏天。

问题来了：怎么给他发工资？

Google有"访问学者"这个职位，但要求至少待六个月。Hinton只能待几个月，不够格。HR翻遍了系统，找到了唯一一个能用的类别：实习生。

于是，64岁的Hinton拿到了一张绿色工牌，上面写着"实习生"。

新人培训那天，他走进一间大教室。满屋子都是二十出头的年轻人，来自清华、MIT、印度理工。每个人头上都戴着一顶统一发放的小帽子。Hinton也戴上了。

他后来说："我还留着那顶帽子。"

讲师站在前面，开始讲怎么登录系统："用你的LDAP和OTP……"

Hinton举手了："什么是LDAP？什么是OTP？"

全场的年轻人都转过头来看他。这个老头是谁？怎么什么都不会？

教室里有四个助教，负责帮学生解决问题。十分钟后，其中一个被专门分配给了Hinton。

午饭时间，他端着餐盘去排队。忽然有人喊了一声："Hinton教授！"

是他以前在多伦多教过的一个本科生，碰巧也在Google实习。

全场的年轻人又转过头来看他。眼神完全变了。

多年以后，Dean回忆这件事时说："他是我的实习生。"

Hinton接话说："你们年龄字段只给了6个bit，所以我只比其他实习生大了一点点。"

* * *

【4】父母家卧室的两块GPU

![Image 7](https://baoyu.io/uploads/2025-12-27-1766877715033-df23f5f1-8d90-4388-991f-116389771c35.png)

2012年，多伦多

Alex Krizhevsky不想写文献综述。

这是多伦多大学博士生的必经之路：你得读一大堆论文，写一篇综述，证明你了解这个领域，然后才能正式开始做研究。没人喜欢这件事，Alex尤其不喜欢。

Hinton看出来了。

"这样吧，"他说，"你每周在ImageNet上提升1%的准确率，就可以推迟一周写综述。"

这是Hinton做过的最好的管理决策。

Alex开始疯狂刷分。一周，又一周，又一周。准确率一直在涨，综述一直没写。

训练用的硬件很简陋：两块Nvidia GPU，放在Alex父母家的卧室里。

"学校付的GPU的钱，"Hinton后来说，"但电费是他父母付的。我这是在帮多伦多大学省钱。"

刚开始的时候，Alex其实什么都不懂。有一次他跑来跟Hinton说："不行，跑不动。"

Hinton走过去一看，发现Alex把权重衰减参数设成了1。

"为什么设成1？"

"我觉得这个数看起来不错。"

"应该是0.001。"

Hinton后来总结说，学生看起来蠢，不是因为真的蠢，只是因为还不知道。Alex学得很快，很快就变成了顶尖高手。

另一个学生Ilya Sutskever一直在推动这件事。"我们得把这东西用在ImageNet上，"他说，"必须赶在Yann LeCun之前。"

Yann LeCun当时在纽约大学，也在做卷积神经网络。他一直想让自己的学生把这技术用在ImageNet竞赛上，但那些学生总觉得有更重要的事情要做。

Ilya没那么多顾虑。他亲自把ImageNet的数据预处理好，全部裁剪成统一尺寸，让Alex可以直接开始训练。

2012年秋天，ImageNet竞赛的结果公布。Alex他们的模型赢了，而且不是赢了一点点——是碾压式的胜利。

那个模型后来被叫做AlexNet。整个计算机视觉领域都被震动了。深度学习不再是一小撮人的信仰，而是被证明真正有用的东西。

而这一切的起点，是一个不想写综述的博士生，两块GPU，和一间父母家的卧室。

* * *

【5】黑莓说不需要语音识别

![Image 8](https://baoyu.io/uploads/2025-12-27-1766877724972-14acfac6-90d1-439b-9b66-f726fa2f16a4.png)

2011年前后，加拿大

加拿大人有个老毛病：喜欢抱怨本国的技术都被外国人抢走了。但有些时候，是他们自己不要的。

George Dahl和Abdul-Rahman Mohamed是Hinton的学生。他们用神经网络做了一个语音识别模型，比当时最好的技术还要好一点。不是好很多，但确实更好。

另一个学生Navdeep Jaitly想去企业实习。Hinton想到了黑莓——那时候黑莓还是加拿大的骄傲，每个商务人士口袋里都揣着一台。

Hinton联系了黑莓的人："我们有个更好的语音识别技术，可以免费给你们用。让我的学生去你们那儿实习，手把手教你们怎么做。"

黑莓的回复是：我们对语音识别不感兴趣。

为什么？

因为黑莓有键盘。用户可以打字，谁需要说话呢？

Navdeep只好去了别的地方。他没法去美国，因为正在申请绿卡。最后Google在蒙特利尔给他找了个位置，远程工作。

他的经理Vincent Vanhoucke一开始也不太信。Navdeep说他想改变Google做语音识别的方式。Vincent说："你的目标太大了，找个现实点的项目吧。"

Navdeep不听，坚持要做。

结果他成功了。

几年后，黑莓的市值跌到了谷底。那个曾经人手一部的小黑盒，变成了历史的注脚。

黑莓的创始人后来在公开场合抱怨：加拿大的技术总是被外国公司抢走。

Hinton听到这话，只想问一句：当年我们免费送上门的技术，是谁说不要的？

* * *

【6】赌场楼上的拍卖

![Image 9](https://baoyu.io/uploads/2025-12-27-1766877733956-7f8fee0b-8b9f-4bc8-9a01-f19610e0ecdc.png)

2012年12月，太浩湖

那年的NeurIPS开在太浩湖边的一家赌场。

这是个奇怪的选择。搞机器学习的人懂概率，懂统计，没人愿意赌博。赌场恨死这帮人了——他们只住酒店，不往老虎机里塞钱。

Hinton拿到了一张VIP卡。这种卡只发给"鲸鱼"——那些会输掉大笔钱的豪赌客。

他拿着卡去VIP餐厅吃饭，服务员问："您是豪赌客吗？"

Hinton说："我不赌博。"

服务员看着他，一脸不信。

楼下的赌徒们不知道，楼上正在进行一场更大的赌博。

AlexNet刚刚在ImageNet上碾压了所有对手。各大科技公司都坐不住了：Google、微软、百度……都想把Hinton和他的学生弄到手。

Hinton决定玩一个游戏。他发现，公司花在工资上的钱，和花在收购上的钱，完全是两个量级。后者大概是前者的十倍。

"那我们就让自己变成一个可以被收购的东西。"

他们注册了一家公司，叫DNN Research。公司一共三个人，没有产品，没有收入，只有技术和人。

拍卖在赌场楼上的一间会议室里进行。楼下的老虎机时不时响起铃声——有人赢钱了。楼上的规则是：每次加价一百万美元。

竞争进入白热化。几家公司轮番加价，价格一路飙升。

Hinton心里其实早就有了答案。那年夏天他在Google做实习生，太开心了。Brain团队的氛围太好了，每天都能学到新东西，遇到有趣的人。

他想去Google。

但问题是：拍卖还在继续，看起来要被另一个买家赢走了。

怎么办？

Hinton做了一个简单粗暴的决定：喊停。

"拍卖结束，"他宣布，"我们选Google。"

就这样，DNN Research卖给了Google。三个人，一个64岁，两个二十多岁，加入了二十来人的Brain团队，挤在一间比会议室还小的办公室里。

那是2012年底。没人知道这笔交易日后会意味着什么。

Hinton后来喜欢引用一个数字：2023年美国股市增长的80%，来自AI概念股。

而这一切的起点之一，是一间赌场楼上的会议室，和一场半途喊停的拍卖。

* * *

【7】一道改变世界的算术题

![Image 10](https://baoyu.io/uploads/2025-12-27-1766877763015-3f45a8e1-bc31-4046-bb13-774ffc5b4ff3.png)

2013年，Google总部

Jeff Dean在走廊里拦住了CFO Patrick Pichette。

他手里拿着一页纸，上面写着一道算术题。

题目是这样的：假设有一亿人，每天对着手机说三分钟话。用我们现在的新语音识别模型来处理，需要多少算力？

答案让人坐不住：需要把Google现有的服务器数量翻一倍。

"这不可能，"Dean说，"就算我们有那么多钱，也没时间去买那么多服务器部署。"

但他有一个想法。

神经网络有个特点：它不需要精确计算。普通程序算错一个bit，整个系统就崩溃。神经网络不一样——它天生就带噪音，算错几个bit根本无所谓。

Hinton后来补充说："你甚至不需要纠错内存。算错了？那就当成是dropout或者对抗训练吧。"

既然神经网络对精度要求这么低，那就可以专门为它设计一款芯片。不需要复杂的纠错电路，不需要高精度运算，只需要把矩阵乘法做得飞快。

Dean做了个估算：专用芯片的能效比，可以比通用CPU或GPU高30到80倍。

他把这个想法告诉了CFO。"我们需要五千万美元，先部署一批芯片。用途以后再说。"

Patrick Pichette同意了。

2013年，第一代TPU开始研发。那时候没人谈"AI芯片"，英伟达还只是个做游戏显卡的公司，黄仁勋还没变成T恤教父。

这是一道简单的算术题。但它改变了整个行业的方向。

十年后的今天，Google有了自己的芯片工厂，有了好几代的TPU，有了用强化学习来设计芯片布局的技术。Jeff Dean说，那篇关于TPU的论文，现在是计算机架构领域历史上被引用次数最多的论文。

一切都始于走廊里的那一页纸。

* * *

【8】为什么Google没先发ChatGPT

![Image 11](https://baoyu.io/uploads/2025-12-27-1766877774775-a80e9121-b740-4d6c-af32-62386f907c84.png)

2020-2022年

2020年，COVID让所有人都在家工作。Google内部有人做了一个聊天机器人，让员工可以边工作边聊天。

这个东西火了。

八万名Google员工在用它——这差不多是公司一半以上的人。反馈非常好。人们觉得它有用，有趣，能帮上忙。

但Google没有把它发布出去。

Jeff Dean后来解释说："我们有点短视。"

问题出在视角上。Google的核心产品是搜索。搜索最重要的原则是什么？准确。用户问一个问题，你给一个答案，这个答案必须是对的。

而那个内部聊天机器人，会胡说八道。它会编造事实，会一本正经地撒谎。这在搜索的标准下是不可接受的。

所以Google决定先解决"准确性"的问题，再考虑发布。

他们没有意识到的是，人们用聊天机器人，并不总是为了查事实。

"帮我写一封信给兽医，说我的狗生病了。"

"帮我总结一下这篇论文。"

"帮我写一个Python脚本。"

这些事情，不需要100%准确。需要的是有用，是快速，是省事。

2022年11月30日，OpenAI发布了ChatGPT。

一两周后，Jeff Dean写了一页内部备忘录。

核心观点是：我们太分散了。Google有好几个团队在做大模型——Brain团队、DeepMind团队、还有一些其他的研究项目。每个团队都有自己的方向，自己的算力预算，自己的想法。

但这没有意义。Dean说，大模型的规律我们早就知道了：模型越大，数据越多，效果越好。既然如此，为什么不把所有人集中起来，做一个最好的？

这就是Gemini团队的起源。Brain和DeepMind合并，集中算力，全力冲刺。

对话快结束的时候，Hinton问Dean："Google后悔发表Transformer论文吗？"

那篇论文是Google的人写的，但OpenAI和其他公司都在用这个架构。有人说Google把自己的核武器送给了竞争对手。

Dean说："不后悔。它对世界有好处。"

* * *

【尾声】

![Image 12](https://baoyu.io/uploads/2025-12-27-1766877787307-795f0740-ae84-4559-9eab-c1263870fcdf.png)

对话的最后，主持人问了一个问题：20年后的世界会是什么样？

Jeff Dean讲了很多：更长的上下文，更高效的硬件，科学发现的加速，教育和医疗的变革。

Hinton只说了一句话："如果有人要写一本书，标题应该是——"

他顿了一下。

"要么我们从此幸福地生活在一起，要么我们全都死了。"

全场笑了。

但他是认真的。

## 关联主题

- [[00-元语/OpenAI]]
- [[00-元语/gemini]]
- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/benchmark]]
- [[00-元语/decision-making]]
- [[00-元语/risk]]
- [[00-元语/interview]]
