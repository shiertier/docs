# OpenAI 连续 12 天 AI 发布会：第二天完整视频（中英文双语字幕）

## 文档信息
- 来源：https://baoyu.io/blog/openai-12-day-ai-event-day-2-video
- 发布日期：2024-12-06
- 作者：宝玉

## 摘要

### 1) 一句话总结
OpenAI 在发布会第二天推出了针对 o1 系列模型的强化微调（RFT）功能，允许用户利用强化学习算法和少量数据，大幅提升模型在特定专业领域的系统推理与问题解决能力。

### 2) 关键要点
*   **核心技术差异**：推出强化微调（Reinforcement Fine-Tuning, RFT），有别于让模型单纯模仿输入的传统监督微调，RFT 通过强化学习算法，强化得出正确答案的思维路径，抑制错误路径，从而提升模型的领域推理能力。
*   **极低的数据门槛**：不需要海量数据，仅需几十个（甚至少至 12 个）高质量示例，即可让模型在特定领域达到专家水平。
*   **防作弊验证机制**：微调过程需要 JSONL 格式的训练集和验证集，且两者的正确答案不能重叠，以确保模型真正学会了推理概括，而非单纯记忆数据。
*   **灵活的评分系统**：引入评分器（Scorer）机制，将模型输出与正确答案对比并给出 0 到 1 的分数（支持部分得分）。OpenAI 计划未来允许用户上传 Python 文件来自定义评分逻辑。
*   **医疗领域应用案例**：与劳伦斯伯克利国家实验室合作，使用约 1100 个罕见病病例数据对 o1-mini 进行微调，让模型根据患者的症状（包含缺失症状）预测致病突变基因。
*   **显著的性能提升**：在基因预测任务的“Top-1（首选答案命中）”评估中，微调后的 o1-mini 准确率达到 31%，大幅超越了基础版 o1-mini（17%）和 o1 正式版（25%）。
*   **多领域适用性**：该技术已在法律（如与汤森路透合作的 AI 法律助理）、金融、工程、生化和 AI 安全等领域展现出良好效果。
*   **发布时间表**：目前正通过“强化微调研究计划”开放有限的 Alpha 版申请名额，预计将于明年初正式向公众发布。

### 3) 风险与不足（基于原文明确提及）
*   **缺乏可比的基准测试数据**：在罕见病基因预测的具体案例中，研究人员指出，由于此次实验未包含基因组测序数据，目前尚无完全可比的基准数据来将该微调模型的表现与现有的传统生物信息学工具进行直接对比。

## 关联主题

- [[00-元语/OpenAI]]
- [[00-元语/AI]]
- [[00-元语/ChatGPT]]
- [[00-元语/llm]]
- [[00-元语/llmops]]
- [[00-元语/benchmark]]
- [[00-元语/evals]]
- [[00-元语/workflow]]

## 正文
视频：

[https://youtu.be/cJ6Wpyre5FQ](https://youtu.be/cJ6Wpyre5FQ)

[https://www.bilibili.com/video/BV1WrirYXEXb/](https://www.bilibili.com/video/BV1WrirYXEXb/)

强化微调，通过少量数据，让模型在专业领域到达专家水平。 跟之前的微调不一样，它不是通过把数据记住答案，而是在微调的过程中训练自己在某个领域的推理能力找到正确答案，有点像给 AI 一本棋谱，让它自己训练自己下棋。

这种微调有两个不同数据集合，一个是微调数据集，一个是测试数据集合，模型先基于微调数据集合去训练，然后用测试数据集合验证，反复自我推理训练验证，最终达到很高的水平。

完整文稿：

Mark: 大家好，我叫 Mark，我是 OpenAI 的研发负责人。昨天，我们推出了 o1 正式版，并在接下来的几天内在 ChatGPT 中向用户推送。o1 的 API 版本也很快会推出。

如果你不了解 o1 的话，它是我们最新的升级版模型，可以让模型在给出回应之前思考一会儿。

今天，我们非常兴奋地展示我们在模型定制计划中的最新进展。它将允许用户在自己的数据集上对 o1 进行微调。而且，这不是标准的微调，这是强化微调，真正利用了强化学习算法，让我们的能力从高中水平提升到博士专家水平，以便适应你自己的使用案例。

我想再次强调，这只是我们计划明年公开发布的预览版。但如果你是大学师生、研究人员或企业，我们会稍后提供一些信息，告诉你如何访问我们的输出计划。

你可能问，为什么需要这个呢？嗯，它允许你将你的优质数据集转化为独特产品，为你的用户和客户带来与我们相同的魔力。所以我会请 John、Julie 和 Justin 多谈一些。

John: 是的，大家好。嗨，大家好。我叫 John Allard，是 OpenAI 的工程师。

Julie: 嗨，大家好。我是 Julie Wong。是 OpenAI 的研究员。

Justin: 我是 Justin Reese。在伯克利实验室工作，担任计算生物学家。

John: 今天，我们很高兴为我们的 o1 系列模型介绍这种新的模型定制方式：强化微调，简称 RFT。开发人员、研究人员及机器学习工程师将首次能利用强化学习来创建能在特定领域内出色完成任务的专家模型。

Julie: 我们认为任何需要...AI 模型具有深厚专业知识的领域都能够从中受益。所以如果您在法律、金融、工程或保险领域工作，这就是为您准备的。

John: 例如，我们最近与 Thompson Reuters 合作，使用强化微调来微调 o1-mini，使其成为他们联合顾问 AI 中的法律助理。该工具帮助他们的法律专业人员完成一些最具分析性的工作。

Julie: 是的，你们中有些人会熟悉我们去年初推出的监督微调 API。监督微调非常强大。你是让模型复制它在输入文本或图像中发现的特征。如果你想改变模型的语气、风格或响应格式，这是很好的。

现在，通过强化微调，或者我们应该说"驯鹿强化学习"（注：Day 1 的段子）。通过强化微调，它实际上是不同的。你不是仅仅在教模型模仿它的输入，而是在教它以新的方式在自定义领域中进行推理。

John: 当模型看到一个问题时，我们给它空间去思考问题，然后我们评估模型的最终答案。利用强化学习的力量，我们强化那些导致正确答案的思维路径，并抑制那些导致错误答案的思维路径。

Julie: 你会看到，仅仅用几十个例子，模型就能以新的有效方式在自定义领域中推理。

John: 用 12 个例子就能做到这一点，真是太疯狂了。这不是常规微调能做到的。

Julie: 是的，确实如此。

John: 是的。我是说，在大语言模型和大规模机器学习的领域——几十个例子基本上算不了什么。

Julie: 因此，我们的模型定制平台将首次支持强化学习。值得注意的是，我们在 OpenAI 内部用于训练前沿模型（如 GPT-4o 和 o1 系列）时使用的也是相同的技术。

John: 科学研究是一个充满令人兴奋应用的领域。但不要仅仅相信我们的话。这就是为什么今天我们邀请了 Justin Reese。Justin 是劳伦斯伯克利国家实验室的研究员，他的研究领域之一是使用计算方法来理解罕见疾病背后的遗传原因。Justin，非常感谢你的到来。你可以多谈谈你的研究，以及强化学习如何对其有所帮助吗？

Justin: 当然，谢谢，能来这里真的很高兴。我的研究领域之一是罕见遗传病。与其名字相反，罕见遗传病其实并不罕见。单个罕见疾病可能很少见，但合在一起，它们其实相当普遍。因此，我们谈论的是全球有 3 亿人患有罕见疾病。更糟糕的是，这些人通常要经过长达数月甚至数年的诊断过程才能了解自己的病情。

Julie: 这相当于整个美国的人口。

Justin: 是的，这不是一个小数目。所以我们正在研究更好的计算工具和方法，以深入研究关键问题，并帮助我们理解和治疗这些疾病。我们在学术环境中研究罕见疾病及其成因，希望能够在未来改善这些人的医疗保健。评估神经疾病相对较难，因为需要具备两方面的能力。你需要具备医学专业知识以及对生物医学数据的系统推理能力。这是我们认为 o1 模型能够大有帮助的领域，因其出色的推理能力。

John: 没错。我们的各种大语言模型具备领域知识，而 o1 模型非常适合系统推理。因此，现在似乎有了一种很好的计算方法来解决这些问题。

Julie: 没错。能否介绍一下你正在使用的数据集？

Justin: 当然。这是我们团队与德国 Charité 医院、Peter Robinson 的实验室以及 Monarch Initiative 的合作成果。我们从数百份关于罕见疾病的病例报告的科学出版物中提取了疾病信息，并整理了有关患者存在和排除的体征和症状列表。然后当然是他们所患的疾病，更重要的是，在这些人中，哪一个基因发生了突变导致了这些问题。

Julie: 我明白了，所以你和一些医生可能正在做什么呢，给定患者的症状，尝试找出哪个基因可能已经发生突变，导致了这些症状。

Justin: 是的，没错，我们和 OpenAI 团队合作，一直在训练旧模型以更有效地推理疾病的原因。

John: 不可思议。谢谢你，Justin。现在我们将展示强化学习微调的工作原理，并且不抢任何人的风头，我们将通过 o1-mini 使其在该任务中超越 o1 的表现。这是我们昨天刚发布的 o1，之所以重要，是因为 o1-mini 是一个更小、更快、更便宜的模型。

Julie: 是的，借助 Justin 的数据集，我们将展示如何大大提升性能。o1-mini 在这个任务上的表现，当给出一份症状清单时，你将尝试预测哪个基因可能导致遗传疾病。

[对话继续...]

John: 为了概述这个过程，我们将从查看数据集开始，用来训练模型的以及评估模型的评估者。然后我们将在 OpenAI 的训练环境中启动一个训练任务。最后，我们将评估微调后的模型，以便了解它比最初的基础模型有何改进。

首先，我们将进入 OpenAI 开发平台。然后我们会创建一个新模型。我们已经进行了大约一年多的监督微调。现在我们要选择强化微调。我们将对 o1 进行训练，因此选择它作为基础模型。

然后我们需要上传一个训练数据集。训练数据集是 JSONL 文件，每一行表示一个你希望模型训练的示例。在这个例子中，Justin 和他的同事们整理了一个约 1100 个示例的数据集。我会上传这个数据集。

为了更好地理解这个数据集的工作原理和任务，我们将快速查看一个具体的数据点。这是一个具体的数据点的样子，主要有三个重要部分。首先是病例报告，这是对患者及其症状的描述。我们看到患者是一位 51 岁的女性，疾病的发作时间未指定，还有一个症状列表，如宽距眼、甲状旁腺功能亢进等。

正如 Justin 之前所说，我们有缺失症状。这些是不存在的症状。这很重要，因为它有助于模型排除掉它可能认为会导致现有症状的基因。

接下来，我们有说明书。我相信如果你正在观看这个直播，你会熟悉提示词。因此，我们在这里所做的只是向模型提示我们希望在这个任务中完成什么。我们所说的是，鉴于症状列表和病例报告，你能否列出所有你认为可能是这种遗传病原因的基因，同时提供为什么认为这些基因可能是原因的解释。

最后，我们还有正确答案。这是我们知道的与这种疾病有关的基因，但重要的是，我们在训练过程中并没有向模型展示它。这会造成作弊。但我们在训练过程内部使用它来评分模型的输出或检查模型是否正确。

Julie: 这是一个非常困难的任务。我绝对无法回答这个问题。

John: 是的，我是说，你可以看出，我们已经远远不只是试着数草莓这个词里的 R 字母数量了。

Julie: 是的。

John: 所以现在，当我们给模型这个提示词、案例报告和指令时，模型会输出类似这样一个基因列表，它认为这些基因可能是原因。重要的是，这些基因是按顺序排列的，列表中的第一个基因是它认为最可能的原因，第二个是它认为第二可能的，依此类推。

Julie: 酷。

John: 那么...我们回到正题。所以接下来我们需要上传一些验证数据。验证数据的格式将与训练数据完全相同。但重要的是验证数据集和训练数据集之间没有正确基因的重叠。这意味着模型不能作弊。

Julie: 或者它不能只是记住一个症状列表并将其与基因关联。

John: 它必须真正从训练数据概括到验证数据。

Julie: 明白了。那么，我是说，强化部分是在哪体现的呢？我们讨论过评分。这是这儿流程的一部分吗？

John: 是的，这是个好问题。评分是通过我们在此介绍的评分器来完成的。评分器非常简单。评分器的工作是获取模型的输出，和正确答案进行比较，并返回一个介于 0 到 1 之间的分数。0 表示模型完全答错，而 1 表示答对。

你也可以给部分分数，所以结果可以在这个范围内浮动。对于这个特定任务，我们用了这样的评分器。它获取我们已知的正确答案和模型输出的基因列表，并生成一个分数。在这种情况下，Foxy3 是正确答案，它在基因列表中排在第二，所以得分大约是 0.7。

Julie: 我明白了。如果它说 Foxy 3 是第一个，那我就会得到 1 分。

John: 是的，没错。随着它在列表中的位置越往后，分数会逐渐降到 0。

Julie: 不错。有道理。如果任务不是对一个排名列表进行评分呢？我们是否有更通用的评分器？

John: 是的，是的。我们提供了一套评分机制，用于有效覆盖强化微调时可能的各种意图。我们一直在增加更多选项。

Julie: 是的，最终我们希望你可以定义自己的评分机制。

John: 是的，是的，可能会上传一个 Python 文件或者其他东西来进行自定义评分。

Julie: 是的。很不错。

John: 我们已经定义好训练数据集。并将其分配为验证数据集。让我快速复制一个评分机制。目前，OpenAI 允许你通过设置超参数自定义微调过程，当然我们提供了不错的默认值。我现在要点击创建。现在就意味着我们启动了一个训练任务。

真正酷的是，你可以提供数据集和评分机制，这是体现你领域专长和对问题贡献的关键。你可以充分利用 OpenAI 的强化学习算法和全分布式模型训练架构，为你的应用案例定制一个先进的模型。

Julie: 作为用户，我只想上传我的数据集，OpenAI 就会处理其他一切。

John: 是的，完全没错。

Julie: 是的。

John: 因此，强化微调任务可能需要几个小时到几天的时间来运行。所以我们将查看我在本周早些时候用同一数据集运行的一个任务，以便看看结果。我在这里切换。这个任务是我本周早些时候运行的。它成功完成了。它为我们生成了一个微调模型。

有一个我想查看的，即验证奖励分数。这是评分员对验证数据集的平均评分以及微调过程中评分的变化。我们可以看到评分在上升，正如我们之前所说，由于训练和验证数据集之间没有基因的重叠，这意味着模型真正学会了在我们的任务中进行概括，而不仅仅是记忆一些症状并将其映射到基因。

虽然这很棒，图表向上并向右移动，这是我们想看到的，如果能够更好地了解模型在微调过程中的实际变化，那就更好了。那么现在我们来仔细看看这个。

好的，我们将跳转到评估仪表板，这是我们今年早些时候在开发者平台上推出的一款产品。有很多数据，但不用担心，我们会一一查看。我在这里进行了三个不同的运行。第一个是针对我们昨天发布的 o1 模型的。第二个是使用 o1-mini 作为我们微调工作的起点。最后是增强微调的 o1。

现在，看到奖励在上升，但这对这个任务实际上意味着什么？我设置了三种不同的评估来进行检测。第一个是前一名，指的是正确答案作为列表中第一个项目出现的频率。前五名是指正确答案出现在列表前五个元素中的频率。最后是最大排名，我们的列表中是否包含正确答案？

在前一名的评估中，可以看到我们的起点 o1-mini 在大约 200 的数据集中达到了 17%。o1 达到了 25%，所以表现更好。而我们的微调 o1-mini 达到了 31%。

我截了这个的图，并把它放到 ChatGPT 里，让它为我制作一个圣诞主题的图表。这是先前看到的九个数字的可视化。你可以看到起始点，o1-mini，分别是顶部一、顶部五、和最大值的表现。我们的 o1 模型，以及表现最佳的 o1-mini 微调模型，标记为红色虚线。

看这些结果，Justin，你怎么看？

Justin: 我认为表现相当出色，尤其是验证数据的提升，这表明模型在学习如何推理这类数据，这很令人兴奋。你可能会问和现有生物信息学工具相比表现如何？没有完全可比的数据，因为这种实验通常会包含基因组测序数据，而我们没有。不过在不完整的症状列表上进行开放模型查询，我认为这很新颖且令人兴奋。

John: 不错。这是汇总统计数据，但让我们看看实际的模型响应。我要浏览到数据标签。按通过情况过滤。这是给模型的输入。问题是如 John 之前描述的，识别可能导致观察到症状的基因。我们让模型输出一个字典，包括解释为什么选择这些基因的字符串，以及按顺序排列的基因。最后，我们有症状列表。患者症状为室管膜下结节、癫痫等。

之后，我们运行模型。这是我们的 o1 模型，微调过的 o1 迷你模型。我们输入这些信息，输出是我们之前提到的字典。推理表明，室管膜下结节、癫痫和皮质结节的组合指示这个综合症，通常由这些基因突变引起。还列出了其他几个潜在候选，而 TSC2 是最可能的候选基因。

如果回到我们的答案，我们会发现 TSC2 确实是正确答案。因此，我们在 top 1、top 5 和 top max 中都通过了。看这个输出，Justin，这个模型输出是否有用？

Justin: 是的，非常有用。特别是能够看到模型的推理过程，这是一个重要贡献。当然还有答案的排名列表。即使正确答案不是第一个，你仍然可以查看所有可能性。微调提升了性能和答案排名，所以正确答案更接近第一，这很令人满意。

John: Justin，稍微放大来看，强化学习如何影响你的领域？你能谈谈生物学上的一些趋势吗？

Justin: 当然，我认为研究界对利用这些模型来执行这类任务非常感兴趣。目前认为，在这种特定用例中，最好的解决方案可能是在现有生物信息学工具和像 o1 这样的模型之间的混合方案。我觉得这很好地表明了这些模型的优势，也展示了我们如何利用微调等工具来提升性能。就像我说的，没有一个可以比较的基准来对比两者，但这确实是一个进步，我们可以借此理解疾病。从更大的角度来看，我们可以思考如何将这些模型融入工作流程中，最终改善人们的医疗保健。

John: 太棒了。谢谢你，Justin。

Julie: 虽然我们刚刚展示了强化微调在科学研究中的一个激动人心的应用，但这是一种通用技术。我们在生化、AI 安全、法律和医疗保健的数据集中看到了可喜的结果。

John: 我们可以想到数百个其他例子或任务，可以使用此模型，但我们知道你也可能会想到很多。这就是为什么我们今天很兴奋地扩展 Alpha 计划让更多人能挑战 o1 模型的极限在他们最重要的任务中。

Julie: 太好了，我们一直在和一小组值得信赖的伙伴合作，测试强化微调。今天，我们通过扩展 alpha 访问权限通过我们所说的强化微调研究计划。这个计划非常适合那些组织他们目前在复杂任务上与专家团队合作并认为可能从 AI 协助中受益。如果你有兴趣申请这些有限名额，可以在直播简介中找到申请链接。

John: 如 Mark 之前所说，我们计划推出这个产品，强化微调，明年初正式公开发布。

Julie: 太好了，我们都非常期待看到你们如何应用强化微调。作为研究人员来说，没有什么比看到我们的模型被改编并用于推进科学知识更让我们开心。在现实世界中你今天有笑话吗？

John: 好吧，其实，我确实有。既然这已成为一种传统，我有一个圣诞主题的笑话。你知道，我们住在旧金山。无人驾驶车辆非常流行。实际上，圣诞老人也想参与。他一直在尝试制造一辆无人驾驶雪橇，但由于某种原因，他的模型始终无法识别树木，结果雪橇左右撞树。大家能猜到为什么吗？

Julie: 没有。

John: 因为他没有对模型进行"松（松树）调。"（谐音梗：fine-tune -> pine-tune）

Julie: 哦，天哪。

John: 好吧。请下周继续关注我们。我们会有更多内容分享。谢谢。Mark: 大家好，我叫 Mark，我是 OpenAI 的研发负责人。昨天，我们推出了 o1 正式版，并在接下来的几天内在 ChatGPT 中向用户推送。o1 的 API 版本也很快会推出。

如果你不了解 o1 的话，它是我们最新的升级版模型，可以让模型在给出回应之前思考一会儿。

今天，我们非常兴奋地展示我们在模型定制计划中的最新进展。它将允许用户在自己的数据集上对 o1 进行微调。而且，这不是标准的微调，这是强化微调，真正利用了强化学习算法，让我们的能力从高中水平提升到博士专家水平，以便适应你自己的使用案例。

我想再次强调，这只是我们计划明年公开发布的预览版。但如果你是大学师生、研究人员或企业，我们会稍后提供一些信息，告诉你如何访问我们的输出计划。

你可能问，为什么需要这个呢？嗯，它允许你将你的优质数据集转化为独特产品，为你的用户和客户带来与我们相同的魔力。所以我会请 John、Julie 和 Justin 多谈一些。

John: 是的，大家好。嗨，大家好。我叫 John Allard，是 OpenAI 的工程师。

Julie: 嗨，大家好。我是 Julie Wong。是 OpenAI 的研究员。

Justin: 我是 Justin Reese。在伯克利实验室工作，担任计算生物学家。

John: 今天，我们很高兴为我们的 o1 系列模型介绍这种新的模型定制方式：强化微调，简称 RFT。开发人员、研究人员及机器学习工程师将首次能利用强化学习来创建能在特定领域内出色完成任务的专家模型。

Julie: 我们认为任何需要...AI 模型具有深厚专业知识的领域都能够从中受益。所以如果您在法律、金融、工程或保险领域工作，这就是为您准备的。

John: 例如，我们最近与 Thompson Reuters 合作，使用强化微调来微调 o1-mini，使其成为他们联合顾问 AI 中的法律助理。该工具帮助他们的法律专业人员完成一些最具分析性的工作。

Julie: 是的，你们中有些人会熟悉我们去年初推出的监督微调 API。监督微调非常强大。你是让模型复制它在输入文本或图像中发现的特征。如果你想改变模型的语气、风格或响应格式，这是很好的。

现在，通过强化微调，或者我们应该说"驯鹿强化学习"（注：Day 1 的段子）。通过强化微调，它实际上是不同的。你不是仅仅在教模型模仿它的输入，而是在教它以新的方式在自定义领域中进行推理。

John: 当模型看到一个问题时，我们给它空间去思考问题，然后我们评估模型的最终答案。利用强化学习的力量，我们强化那些导致正确答案的思维路径，并抑制那些导致错误答案的思维路径。

Julie: 你会看到，仅仅用几十个例子，模型就能以新的有效方式在自定义领域中推理。

John: 用 12 个例子就能做到这一点，真是太疯狂了。这不是常规微调能做到的。

Julie: 是的，确实如此。

John: 是的。我是说，在大语言模型和大规模机器学习的领域——几十个例子基本上算不了什么。

Julie: 因此，我们的模型定制平台将首次支持强化学习。值得注意的是，我们在 OpenAI 内部用于训练前沿模型（如 GPT-4o 和 o1 系列）时使用的也是相同的技术。

John: 科学研究是一个充满令人兴奋应用的领域。但不要仅仅相信我们的话。这就是为什么今天我们邀请了 Justin Reese。Justin 是劳伦斯伯克利国家实验室的研究员，他的研究领域之一是使用计算方法来理解罕见疾病背后的遗传原因。Justin，非常感谢你的到来。你可以多谈谈你的研究，以及强化学习如何对其有所帮助吗？

Justin: 当然，谢谢，能来这里真的很高兴。我的研究领域之一是罕见遗传病。与其名字相反，罕见遗传病其实并不罕见。单个罕见疾病可能很少见，但合在一起，它们其实相当普遍。因此，我们谈论的是全球有 3 亿人患有罕见疾病。更糟糕的是，这些人通常要经过长达数月甚至数年的诊断过程才能了解自己的病情。

Julie: 这相当于整个美国的人口。

Justin: 是的，这不是一个小数目。所以我们正在研究更好的计算工具和方法，以深入研究关键问题，并帮助我们理解和治疗这些疾病。我们在学术环境中研究罕见疾病及其成因，希望能够在未来改善这些人的医疗保健。评估神经疾病相对较难，因为需要具备两方面的能力。你需要具备医学专业知识以及对生物医学数据的系统推理能力。这是我们认为 o1 模型能够大有帮助的领域，因其出色的推理能力。

John: 没错。我们的各种大语言模型具备领域知识，而 o1 模型非常适合系统推理。因此，现在似乎有了一种很好的计算方法来解决这些问题。

Julie: 没错。能否介绍一下你正在使用的数据集？

Justin: 当然。这是我们团队与德国 Charité 医院、Peter Robinson 的实验室以及 Monarch Initiative 的合作成果。我们从数百份关于罕见疾病的病例报告的科学出版物中提取了疾病信息，并整理了有关患者存在和排除的体征和症状列表。然后当然是他们所患的疾病，更重要的是，在这些人中，哪一个基因发生了突变导致了这些问题。

Julie: 我明白了，所以你和一些医生可能正在做什么呢，给定患者的症状，尝试找出哪个基因可能已经发生突变，导致了这些症状。

Justin: 是的，没错，我们和 OpenAI 团队合作，一直在训练旧模型以更有效地推理疾病的原因。

John: 不可思议。谢谢你，Justin。现在我们将展示强化学习微调的工作原理，并且不抢任何人的风头，我们将通过 o1-mini 使其在该任务中超越 o1 的表现。这是我们昨天刚发布的 o1，之所以重要，是因为 o1-mini 是一个更小、更快、更便宜的模型。

Julie: 是的，借助 Justin 的数据集，我们将展示如何大大提升性能。o1-mini 在这个任务上的表现，当给出一份症状清单时，你将尝试预测哪个基因可能导致遗传疾病。

[对话继续...]

John: 为了概述这个过程，我们将从查看数据集开始，用来训练模型的以及评估模型的评估者。然后我们将在 OpenAI 的训练环境中启动一个训练任务。最后，我们将评估微调后的模型，以便了解它比最初的基础模型有何改进。

首先，我们将进入 OpenAI 开发平台。然后我们会创建一个新模型。我们已经进行了大约一年多的监督微调。现在我们要选择强化微调。我们将对 o1 进行训练，因此选择它作为基础模型。

然后我们需要上传一个训练数据集。训练数据集是 JSONL 文件，每一行表示一个你希望模型训练的示例。在这个例子中，Justin 和他的同事们整理了一个约 1100 个示例的数据集。我会上传这个数据集。

为了更好地理解这个数据集的工作原理和任务，我们将快速查看一个具体的数据点。这是一个具体的数据点的样子，主要有三个重要部分。首先是病例报告，这是对患者及其症状的描述。我们看到患者是一位 51 岁的女性，疾病的发作时间未指定，还有一个症状列表，如宽距眼、甲状旁腺功能亢进等。

正如 Justin 之前所说，我们有缺失症状。这些是不存在的症状。这很重要，因为它有助于模型排除掉它可能认为会导致现有症状的基因。

接下来，我们有说明书。我相信如果你正在观看这个直播，你会熟悉提示词。因此，我们在这里所做的只是向模型提示我们希望在这个任务中完成什么。我们所说的是，鉴于症状列表和病例报告，你能否列出所有你认为可能是这种遗传病原因的基因，同时提供为什么认为这些基因可能是原因的解释。

最后，我们还有正确答案。这是我们知道的与这种疾病有关的基因，但重要的是，我们在训练过程中并没有向模型展示它。这会造成作弊。但我们在训练过程内部使用它来评分模型的输出或检查模型是否正确。

Julie: 这是一个非常困难的任务。我绝对无法回答这个问题。

John: 是的，我是说，你可以看出，我们已经远远不只是试着数草莓这个词里的 R 字母数量了。

Julie: 是的。

John: 所以现在，当我们给模型这个提示词、案例报告和指令时，模型会输出类似这样一个基因列表，它认为这些基因可能是原因。重要的是，这些基因是按顺序排列的，列表中的第一个基因是它认为最可能的原因，第二个是它认为第二可能的，依此类推。

Julie: 酷。

John: 那么...我们回到正题。所以接下来我们需要上传一些验证数据。验证数据的格式将与训练数据完全相同。但重要的是验证数据集和训练数据集之间没有正确基因的重叠。这意味着模型不能作弊。

Julie: 或者它不能只是记住一个症状列表并将其与基因关联。

John: 它必须真正从训练数据概括到验证数据。

Julie: 明白了。那么，我是说，强化部分是在哪体现的呢？我们讨论过评分。这是这儿流程的一部分吗？

John: 是的，这是个好问题。评分是通过我们在此介绍的评分器来完成的。评分器非常简单。评分器的工作是获取模型的输出，和正确答案进行比较，并返回一个介于 0 到 1 之间的分数。0 表示模型完全答错，而 1 表示答对。

你也可以给部分分数，所以结果可以在这个范围内浮动。对于这个特定任务，我们用了这样的评分器。它获取我们已知的正确答案和模型输出的基因列表，并生成一个分数。在这种情况下，Foxy3 是正确答案，它在基因列表中排在第二，所以得分大约是 0.7。

Julie: 我明白了。如果它说 Foxy 3 是第一个，那我就会得到 1 分。

John: 是的，没错。随着它在列表中的位置越往后，分数会逐渐降到 0。

Julie: 不错。有道理。如果任务不是对一个排名列表进行评分呢？我们是否有更通用的评分器？

John: 是的，是的。我们提供了一套评分机制，用于有效覆盖强化微调时可能的各种意图。我们一直在增加更多选项。

Julie: 是的，最终我们希望你可以定义自己的评分机制。

John: 是的，是的，可能会上传一个 Python 文件或者其他东西来进行自定义评分。

Julie: 是的。很不错。

John: 我们已经定义好训练数据集。并将其分配为验证数据集。让我快速复制一个评分机制。目前，OpenAI 允许你通过设置超参数自定义微调过程，当然我们提供了不错的默认值。我现在要点击创建。现在就意味着我们启动了一个训练任务。

真正酷的是，你可以提供数据集和评分机制，这是体现你领域专长和对问题贡献的关键。你可以充分利用 OpenAI 的强化学习算法和全分布式模型训练架构，为你的应用案例定制一个先进的模型。

Julie: 作为用户，我只想上传我的数据集，OpenAI 就会处理其他一切。

John: 是的，完全没错。

Julie: 是的。

John: 因此，强化微调任务可能需要几个小时到几天的时间来运行。所以我们将查看我在本周早些时候用同一数据集运行的一个任务，以便看看结果。我在这里切换。这个任务是我本周早些时候运行的。它成功完成了。它为我们生成了一个微调模型。

有一个我想查看的，即验证奖励分数。这是评分员对验证数据集的平均评分以及微调过程中评分的变化。我们可以看到评分在上升，正如我们之前所说，由于训练和验证数据集之间没有基因的重叠，这意味着模型真正学会了在我们的任务中进行概括，而不仅仅是记忆一些症状并将其映射到基因。

虽然这很棒，图表向上并向右移动，这是我们想看到的，如果能够更好地了解模型在微调过程中的实际变化，那就更好了。那么现在我们来仔细看看这个。

好的，我们将跳转到评估仪表板，这是我们今年早些时候在开发者平台上推出的一款产品。有很多数据，但不用担心，我们会一一查看。我在这里进行了三个不同的运行。第一个是针对我们昨天发布的 o1 模型的。第二个是使用 o1-mini 作为我们微调工作的起点。最后是增强微调的 o1。

现在，看到奖励在上升，但这对这个任务实际上意味着什么？我设置了三种不同的评估来进行检测。第一个是前一名，指的是正确答案作为列表中第一个项目出现的频率。前五名是指正确答案出现在列表前五个元素中的频率。最后是最大排名，我们的列表中是否包含正确答案？

在前一名的评估中，可以看到我们的起点 o1-mini 在大约 200 的数据集中达到了 17%。o1 达到了 25%，所以表现更好。而我们的微调 o1-mini 达到了 31%。

我截了这个的图，并把它放到 ChatGPT 里，让它为我制作一个圣诞主题的图表。这是先前看到的九个数字的可视化。你可以看到起始点，o1-mini，分别是顶部一、顶部五、和最大值的表现。我们的 o1 模型，以及表现最佳的 o1-mini 微调模型，标记为红色虚线。

看这些结果，Justin，你怎么看？

Justin: 我认为表现相当出色，尤其是验证数据的提升，这表明模型在学习如何推理这类数据，这很令人兴奋。你可能会问和现有生物信息学工具相比表现如何？没有完全可比的数据，因为这种实验通常会包含基因组测序数据，而我们没有。不过在不完整的症状列表上进行开放模型查询，我认为这很新颖且令人兴奋。

John: 不错。这是汇总统计数据，但让我们看看实际的模型响应。我要浏览到数据标签。按通过情况过滤。这是给模型的输入。问题是如 John 之前描述的，识别可能导致观察到症状的基因。我们让模型输出一个字典，包括解释为什么选择这些基因的字符串，以及按顺序排列的基因。最后，我们有症状列表。患者症状为室管膜下结节、癫痫等。

之后，我们运行模型。这是我们的 o1 模型，微调过的 o1 迷你模型。我们输入这些信息，输出是我们之前提到的字典。推理表明，室管膜下结节、癫痫和皮质结节的组合指示这个综合症，通常由这些基因突变引起。还列出了其他几个潜在候选，而 TSC2 是最可能的候选基因。

如果回到我们的答案，我们会发现 TSC2 确实是正确答案。因此，我们在 top 1、top 5 和 top max 中都通过了。看这个输出，Justin，这个模型输出是否有用？

Justin: 是的，非常有用。特别是能够看到模型的推理过程，这是一个重要贡献。当然还有答案的排名列表。即使正确答案不是第一个，你仍然可以查看所有可能性。微调提升了性能和答案排名，所以正确答案更接近第一，这很令人满意。

John: Justin，稍微放大来看，强化学习如何影响你的领域？你能谈谈生物学上的一些趋势吗？

Justin: 当然，我认为研究界对利用这些模型来执行这类任务非常感兴趣。目前认为，在这种特定用例中，最好的解决方案可能是在现有生物信息学工具和像 o1 这样的模型之间的混合方案。我觉得这很好地表明了这些模型的优势，也展示了我们如何利用微调等工具来提升性能。就像我说的，没有一个可以比较的基准来对比两者，但这确实是一个进步，我们可以借此理解疾病。从更大的角度来看，我们可以思考如何将这些模型融入工作流程中，最终改善人们的医疗保健。

John: 太棒了。谢谢你，Justin。

Julie: 虽然我们刚刚展示了强化微调在科学研究中的一个激动人心的应用，但这是一种通用技术。我们在生化、AI 安全、法律和医疗保健的数据集中看到了可喜的结果。

John: 我们可以想到数百个其他例子或任务，可以使用此模型，但我们知道你也可能会想到很多。这就是为什么我们今天很兴奋地扩展 Alpha 计划让更多人能挑战 o1 模型的极限在他们最重要的任务中。

Julie: 太好了，我们一直在和一小组值得信赖的伙伴合作，测试强化微调。今天，我们通过扩展 alpha 访问权限通过我们所说的强化微调研究计划。这个计划非常适合那些组织他们目前在复杂任务上与专家团队合作并认为可能从 AI 协助中受益。如果你有兴趣申请这些有限名额，可以在直播简介中找到申请链接。

John: 如 Mark 之前所说，我们计划推出这个产品，强化微调，明年初正式公开发布。

Julie: 太好了，我们都非常期待看到你们如何应用强化微调。作为研究人员来说，没有什么比看到我们的模型被改编并用于推进科学知识更让我们开心。在现实世界中你今天有笑话吗？

John: 好吧，其实，我确实有。既然这已成为一种传统，我有一个圣诞主题的笑话。你知道，我们住在旧金山。无人驾驶车辆非常流行。实际上，圣诞老人也想参与。他一直在尝试制造一辆无人驾驶雪橇，但由于某种原因，他的模型始终无法识别树木，结果雪橇左右撞树。大家能猜到为什么吗？

Julie: 没有。

John: 因为他没有对模型进行"松（松树）调。"（谐音梗：fine-tune -> pine-tune）

Julie: 哦，天哪。

John: 好吧。请下周继续关注我们。我们会有更多内容分享。谢谢。
