# 用类比的方式点评下神级 Prompt，以及它和 o1 推理模型的差距

## 文档信息
- 来源：https://baoyu.io/blog/comparing-god-level-prompts-to-o1-reasoning-models
- 发布日期：2024-11-14
- 作者：宝玉

## 摘要

**1) 一句话总结**
本文客观评价了近期热门的“让 Claude 模仿 o1 思考”的提示词，指出其虽能激发模型潜力但本质上是在“表演思考”，并深刻剖析了依赖提示词的传统大模型与具备原生推理能力的 o1 模型之间的根本差距。

**2) 关键要点**
*   **事件背景**：一名高中生编写的“Thinking-Claude”提示词引发热议，该提示词旨在让 Claude 在通用任务中输出类似 o1 模型的思维链。
*   **作者态度**：肯定该提示词质量高、能发挥模型潜力，但不赞同将其过度拔高为“神级”。
*   **模型能力演进**：随着大模型自身能力的增强，提示词的复杂度必然会随之降低。
*   **“表演思考”本质**：该提示词生成的“思考”与“答案”同属一次预先规划的输出，缺乏真正的渐进性推理，本质上是在模仿和“表演思考”。
*   **传统模型类比**：传统大模型如同靠死记硬背且逻辑基础薄弱的学生，复杂的提示词只是教其模仿解题步骤，并未改变其推理基础差的本质。
*   **o1 模型类比**：o1 模型如同经过大量严格步骤训练的学生，具备原生的自我推理、验证和错误回退能力，遇到问题无需过度依赖提示词引导。

**3) 风险与不足（原文明确提及）**
*   **提示词过长风险**：提示词变长后，无法确认模型是否全盘接受，注意力机制的计算结果可能与人类主观要求不一致。
*   **泛化能力局限**：该提示词泛化能力有限，仅在部分编程或系统化任务中通过结构化引导表现较好，整体作用有限。
*   **过度神化风险**：过度吹捧和神化开源作品有收割流量之嫌，且不利于年轻创作者的心智成长。
*   **基础能力差距**：传统模型通过提示词模仿思维过程，并不能本质上提升其数学和逻辑基础。

## 正文
昨天一个热门话题是涂同学发的让 Claude 也能输出类似 o1 思考过程的 Prompt [https://github.com/richards199999/Thinking-Claude](https://github.com/richards199999/Thinking-Claude) ，有人称之为神级 Prompt，网友们体验后评论不一：有人认为确实很强，效果很好；有人认为效果一般。

![Image 1](https://baoyu.io/uploads/2024-11-14/1731607878856.png)

首先，涂同学作为高中生，写出这么高质量的 Prompt，是很值得肯定的，能充分发挥模型潜力，让 Claude 对于通用任务也使用思维链。

然后这个 Prompt 不用拔高到“神级”这个高度，我个人比较赞同下面 Wen Yu 和 padphone 网友的看法：

> 即使不用这个提示词，Claude 也能得出差不多的结论；若进一步追问，Claude 输出答案的深度甚至比使用那个提示词更强。
>
>
> 提示词变长以后，更无法确认模型对提示词是全盘接受的；本质上注意力机制计算的结果和人主观意识要求模型接受的不一致。
>
>
> 提示工程重要，但模型能力增强一定会降低提示词的复杂度。
>
>
> [https://x.com/WenYu98767859/status/1856907303976661241](https://x.com/WenYu98767859/status/1856907303976661241) -- [Wen Yu](https://x.com/WenYu98767859)

![Image 2](https://baoyu.io/uploads/2024-11-14/1731607097973.png)

> Claude 3.5 sonnet 本身不具备真正意义上的思考链条的。 而这位高中同学提供的 prompt ,它的 thinking 与它最后提供的答案，都是同属一个答案的（一个完整的答案，用两种不同的方式划分了）。通过 prompt 实现表面上划分的思考和答案，实际上都是预先规划的一次性输出的。缺乏真正渐进性的思考的。实际上是在“表演思考”。 它这个 prompt 的泛化能力有限的，会在一些编程或者一些系统化的任务中表现出息而已，利用分解问题以及多维度分析，实现结构化的引导，对于一些编程任务是有限，但是作用有限的。 Prompt 是优秀的，也有它的局限所在，过度吹捧神化它，其实并不好。开源的作品，本质就是让大家一起探索研究，一起优化，而不是把它过度神话，去收割流量韭菜。 这不是一种好的现象，也不利于这位优秀的 17 岁的孩子的心智成长 [https://x.com/lepadphone/status/1857112426447270258](https://x.com/lepadphone/status/1857112426447270258) -- padphone

![Image 3](https://baoyu.io/uploads/2024-11-14/1731607147561.png)

最后我尝试用类比来解释一下这类 Prompt 和 o1 这类推理模型的区别，不是很严谨，不要当作理论知识看，只是帮助更好的理解其中差别，不对之处也请指正。

先说个题外话，我们那一代学生，初中开始才学英语，学习的教材和方法也相对落后，主要靠背单词记语法，整体英语基础相对是比较差的，现在的孩子从小就开始学英语，听说读写一起练，长大了就都能说的很标准了。

现在的大语言模型，就像是小学中学没好好学过数学的一批大学生，全靠死记硬背记答案混过了高考，记忆力超好，知识特别丰富，写出来的东西也漂亮，还善解人意。

用人单位一开始还挺高兴，日常找找资料写写公文那是没得说，写程序都还不错，但用了一段时间发现这帮大学生数学和逻辑真的不行，也不愿意学习新知识，都这么大了也没法回炉重造了，负责带这些大学生的导师们只好死马当活马医，告诉学生们，数学推理这种问题，列出步骤就能改善很多（Let's think step by step）！

好一点的导师甚至还会针对特定的问题耐心的列出步骤，这还真的管用，马上学生们推理水平上了一大截，甚至能解决稍微复杂一点的问题。但是遇到导师自己也不会的，或者懒得说的，学生们只好只有发挥，有时候还真蒙对了，有时候就是胡说八道，但解题过程有模有样，不懂的可能还真被忽悠了！

然后有聪明人把自己平时解题和推理的思维过程总结出来了，比如要从几个不同角度去考虑、要去反思、要验证结果，然后让大学生们执行所有任务都按照这一套来。你还别说，对于有些任务还真的效果好一点，于是有人惊呼：神级 Prompt。

但是如前面两位网友分析的，这种模仿别人思维过程的，可能只是在“表演思考”，他们的数学基础并没有本质提升，虽然在特定的一些任务会表现更好，但是并不代表真的可以改变自身数学基础不行的本质。

![Image 4](https://baoyu.io/uploads/2024-11-15/1731639407726.png)

图片来源：[https://x.com/eviljer/status/1857252258259636469](https://x.com/eviljer/status/1857252258259636469)

那么 o1 模型呢，就像新一代的大学生，从小就开始题海战术，每天做大量的数学题和编程题，并且做的时候都要严格的列出步骤，做完了就去对答案，不对重新做！

等这批大学生毕业，他们的数学推理能力已经变得很强了，遇到问题不需要导师们去引导怎么思考，而是会根据平时的训练，自行去推理，自行验证，遇到错误了能回退回去重新推演。当然对于一些已经有最佳实践步骤的问题，导师们给出步骤会结果更好。

长江后浪推前浪，前浪死在沙滩上！

## 关联主题
- [[00-元语/prompt]]
- [[00-元语/llm]]
- [[00-元语/Claude]]
- [[00-元语/OpenAI]]
- [[00-元语/数学]]
