# Google 旧闻重温：《我们没有护城河，OpenAI 也没有》

## 文档信息
- 来源：https://baoyu.io/blog/google-openai-no-moat
- 发布日期：2025-01-29
- 作者：宝玉

## 摘要

### 1) 一句话总结
泄露的 Google 内部文件指出，Google 和 OpenAI 均缺乏技术护城河，开源 AI 社区正凭借低成本、快速迭代和高效微调技术迅速赶超，建议巨头转变策略拥抱开源生态。

### 2) 关键要点
* **开源能力已逼近闭源巨头：** DeepSeek R1 的开源发布印证了文件观点，小团队通过轻量化微调和高质量数据，能迅速推出性能媲美 OpenAI o1 的模型。
* **极高的研发与运行效率：** 开源社区已实现手机端运行大模型（Pixel 6 达 5 token/秒）、单人单夜用笔记本完成微调，以及仅用 1 小时完成多模态 SOTA 模型训练。
* **成本优势呈压倒性：** 开源社区仅需约 100 美元和 130 亿参数，在几周内就能实现 Google 耗资千万美元、5400 亿参数巨型模型才能处理的复杂任务。
* **LoRA 技术是核心驱动力：** 低秩适配（LoRA）极大降低了微调成本，且更新具有“可叠加性”，使模型能以极低代价持续迭代，无需承担从头训练的高昂成本。
* **数据质量优于数据规模：** 开源项目证明，使用小规模、高质量（如合成数据或筛选优质输出）的数据集进行训练，比单纯追求庞大数据量更高效。
* **战略方向调整建议：** Google 应优先发展 200 亿参数以下、可快速迭代的小规模模型，并优先考虑为第三方集成提供支持。
* **建立生态系统是唯一出路：** 建议 Google 效仿 Chrome 和 Android 的成功经验，公布小型通用语言模型（ULM）权重，通过领导开源生态来掌握行业话语权。

### 3) 风险与缺口
* **商业模式被颠覆的风险：** 当免费、无限制且质量相当的开源模型普及后，用户将不再愿意为 Google 或 OpenAI 受限制的闭源模型付费。
* **巨型模型拖慢创新节奏：** 执迷于维护全球最大规模的模型和频繁从头训练，会导致迭代速度远落后于开源社区，使公司在竞争中处于劣势。
* **技术保密策略失效：** 随着核心研究人员的持续流失，技术机密无法守住，试图通过闭源来维持“独门秘方”的防守策略形同虚设。
* **控制欲导致用户流失：** 对模型的控制越严格，开源替代方案就越具吸引力；与开源社区正面竞争注定失败。

## 正文
**导读**

最近 DeepSeek 公布了其全新开源模型 R1。据社区最新测评结果显示，R1 的整体性能已非常接近 OpenAI 最新发布的 o1 模型。短短数月前，许多业界专家还认为要想撼动 OpenAI 的领先地位并不容易，但这一进展表明，开源创新的活力正持续爆发，带来了速度惊人的进步。

这让人联想到不久前流传于业界的一份 Google 内部文件——**《我们没有护城河，OpenAI 也没有》**，其中指出开源社区在大语言模型上的迭代与竞争力不断攀升，甚至有可能颠覆当前闭源模型的领先地位。DeepSeek 这次的发布，正是又一个有力佐证：通过轻量化微调、聚焦高质量数据以及快速版本迭代，小型团队也能迅速推出性能出众的模型。

对开发者和研究者而言，R1 的开源意味着可以自由掌握和调试模型，随时挖掘更多场景价值。同时，对于更广泛的行业应用，无论是对话机器人、自动文案生成，还是科研辅助，越来越多的开源选择都在加速降低门槛。下一步，或许将出现更多针对垂直领域和特殊需求的个性化调优模型，为用户提供与巨头竞争的替代方案。

从这一系列现象不难看出，未来人工智能领域的版图势必将从“单点领先”转向“群体协同”，创新也会来得更为迅速。DeepSeek 的 R1 与 OpenAI 的 o1 如今的“平分秋色”，只是一个起点——谁能率先拥抱开源生态、加快迭代脚步，就将更有机会在这场竞争里赢得用户和口碑。

Google “我们没有护城河，OpenAI 也没有”
---------------------------

泄露的内部 Google 文件声称：开源 AI 将在竞争中超越 Google 和 OpenAI
-----------------------------------------------

以下文字是最近泄露的一份文件，由匿名人士在一个公共 Discord 服务器上分享，并已获得其授权重新发布。它来自 Google 内部的一位研究人员。我们已核实其真实性。文件的唯一改动之处在于格式和移除了指向内部网页的链接。该文件仅代表这位 Google 员工的个人观点，而非整个公司的立场。我们并不认同以下内容，亦有其他研究人员对其提出异议。我们会在另外的文章中向订阅者阐述我们自己的观点。此处仅作为分享这份文件的载体，因为它提出了一些非常值得关注的问题。

* * *

我们没有护城河
-------

### OpenAI 也没有

我们一直在紧盯 OpenAI 的动向。谁会率先达到下一个里程碑？下一步行动会是什么？

但有一个令人不安的事实是：**我们并没有站在赢得这场军备竞赛的位置，OpenAI 也没有。** 当我们在彼此争夺的时候，第三股力量已经悄悄把我们的午餐吃掉了。

我说的，当然是开源社区。直白地说，他们已经把我们远远甩在身后。**我们认为的“重大未解决问题”，他们如今已经解决并投入使用。** 仅举几例：

*   **能在手机上运行的大语言模型（LLM）：**[有人在 Pixel 6 上运行了基础模型](https://twitter.com/thiteanish/status/1635678053853536256)，速度达 5 个 token/秒。

*   **可扩展的个人 AI：**[只需要一个晚上、用笔记本就能微调一个个性化 AI](https://github.com/tloen/alpaca-lora)。

*   **负责任的发布（Responsible Release）：** 这一点并非被“解决”，而是被“架空”了。[网上有整整一批艺术模型网站，它们对输出几乎没有任何限制](https://civitai.com/)，而文本方面[也已相距不远](https://medium.com/geekculture/list-of-open-sourced-fine-tuned-large-language-models-llm-8d95a2e0dc76)。

*   **多模态：**[当前多模态 ScienceQA 的最新 SOTA 模型仅用一小时就完成训练](https://arxiv.org/pdf/2303.16199.pdf)。

我们的模型虽然在质量上依然略有优势，但[差距正在以惊人的速度缩小](https://arxiv.org/pdf/2303.16199.pdf)。开源模型的速度更快，可定制性更强，更注重隐私，并且在同等规模下功能更全面。[他们用区区 100 美元和 130 亿参数](https://lmsys.org/blog/2023-03-30-vicuna/)就能实现我们用一千万美元、5400 亿参数都觉得棘手的事情，而且他们只需要几周时间，而非几个月。这对我们有着深远的影响：

*   **我们没有“独门秘方”。** 我们最好的希望是学习并与 Google 外部的创新者合作。我们应当优先考虑为第三方集成提供支持。

*   **当免费且无限制的可比质量模型出现时，人们不会愿意付费使用受限制的模型。** 我们要认真思考自己的价值增值点究竟在哪里。

*   **巨型模型反而拖慢了我们的脚步。** 从长远来看，最好的模型应该是那些能被快速迭代的模型。既然我们已看到 200 亿参数以下的模型也能有如此潜力，那么就应当优先考虑这类小规模模型，而不是仅把它们当作辅助思路。

* * *

事情的来龙去脉
-------

3 月初，开源社区[第一次接触到了](https://www.vice.com/en/article/xgwqgw/facebooks-powerful-large-language-model-leaks-online-4chan-llama)一个真正有能力的基础模型——Meta 的 LLaMA，因为该模型意外泄露给公众。最初它没有任何指令或对话微调，也没有经过强化学习反馈（RLHF）。尽管如此，社区立刻意识到这个模型所蕴含的意义。

接着便涌现了令人目不暇接的创新，重大进展往往只相隔几天（参见后文的“时间线”部分了解更多详情）。转眼只过了一个多月，市面上就出现了带[指令微调](https://crfm.stanford.edu/2023/03/13/alpaca.html)、[量化](https://github.com/ggerganov/llama.cpp)、[质量提升](https://lmsys.org/blog/2023-03-30-vicuna/)、[人工评测](https://arxiv.org/pdf/2303.16199.pdf)、[多模态](https://arxiv.org/pdf/2303.16199.pdf)、[RLHF](https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view)等等的变体，而且许多成果是相互构建和叠加的。

最重要的是，[他们已经解决了可扩展性问题](https://github.com/tloen/alpaca-lora)，使得任何人都可以自己动手尝试。如今许多新想法都来自普通个体。训练和实验的门槛从需要一家主要研究机构的资源，降到了只需要一个人、一晚上加上一台高性能笔记本电脑。

* * *

为什么我们本该预见到这一切
-------------

从很多方面来看，这件事并不让人意外。就在开源 LLM 迎来当前热潮之前，开源图像生成领域也经历了一场革新。社区也敏锐地发现了两者的相似之处，很多人称这次是 LLM 领域的“[Stable Diffusion 时刻](https://simonwillison.net/2023/Mar/11/llama/)”。

在这两种情况下，低成本的公众参与都得益于一种极其廉价的微调方法——[LoRA（低秩适配）](https://arxiv.org/abs/2106.09685)，再加上在规模上的重大突破（图像合成用的是[潜在扩散（latent diffusion）](https://arxiv.org/abs/2112.10752)，而 LLM 这边是[Chinchilla](https://arxiv.org/abs/2203.15556)）。同样，获得一个足够高质量的开源模型后，全世界的个人和机构纷纷在此基础上进行创新，迭代速度远超大型企业。

这些贡献在图像生成领域起到了决定性作用，让 Stable Diffusion 与 DALL·E 走上了截然不同的道路。拥有一个开源模型促成了[产品集成](https://github.com/AbdullahAlfaraj/Auto-Photoshop-StableDiffusion-Plugin)、[市场平台](https://civitai.com/)、[用户界面](https://github.com/AUTOMATIC1111/stable-diffusion-webui)和[相关创新](https://stablediffusionweb.com/ControlNet)，而这些并没有发生在 DALL·E 上。

其影响力是显而易见的：Stable Diffusion 在文化影响力方面[迅速超越了](https://trends.google.com/trends/explore?date=2022-08-01%202023-04-10&q=Stable%20Diffusion,Dall-E&hl=en)OpenAI 的解决方案，DALL·E 逐渐变得无关紧要。LLM 是否会重蹈这个覆辙还需观望，但两者在总体的结构和情况上非常相似。

* * *

我们忽视了什么
-------

推动开源取得近期成功的技术创新，恰恰也能直接解决我们仍在困扰的问题。关注他们的工作或许能让我们避免重复造轮子。

* * *

### LoRA 是一种极其强大的技术，我们可能需要更加重视

[LoRA](https://arxiv.org/abs/2106.09685) 通过将模型更新表示为低秩分解，将更新矩阵的大小最多缩小数千倍。这让模型的微调只需要极少的成本和时间。能在消费者级硬件上，用几小时就完成对语言模型的个性化微调，这是一件大事，**尤其是**对于我们那些[想要在近乎实时的环境中整合新鲜、多元知识](http://www.internalgooglesitescrubbedbyus.com/)的愿景。我们在 Google 内部对这项技术的利用远远不足，尽管它对一些最雄心勃勃的项目有直接影响。

* * *

### 从头训练模型是最困难的道路

LoRA 之所以高效，部分原因就在于它——和其他微调方式类似——是“可叠加”的。像指令微调这样的改进可以先行完成，然后再让其他贡献者在其基础上添加对话、推理或工具使用等功能。虽然单个微调是低秩的，但它们的总和不一定是低秩的，这意味着全秩的更新会随时间在模型中不断累加。

也就是说，随着不断出现更新、更好的数据集和任务，模型能以低廉的代价不断维持“现代化”，而无需为每次迭代都承担完整训练的成本。

相比之下，每次从零开始训练巨型模型不仅会丢弃预训练成果，也会丢弃在此基础上所积累的一切迭代改进。在开源世界里，这些改进用不了多久就会占据主导，使得完全重头训练的成本变得极为高昂。

我们应当认真思考是否真的为每个新应用或新想法都要重新训练一个全新模型。如果我们确实有重大结构改进，导致无法直接重用模型权重，那么应该投资于更激进的蒸馏方法，以尽可能保留上一代模型的能力。

* * *

### 长期来看，如果我们能更快地迭代小模型，大模型未必更强

对于最受欢迎的模型规模（通常在十几亿到几十亿参数），LoRA 更新的成本大约在 100 美元左右。这意味着几乎任何有想法的人都能产生自己的微调版本并进行分发。通常在一天内即可完成训练。以这样的速度，不久之后，一系列小步迭代的累积效应就会弥补起初规模上的劣势。实际上，就工程师人力投入来看，这些小模型的迭代速度远远超过我们对超大模型的迭代速度，而且[它们中的佼佼者与 ChatGPT 已经难分伯仲](https://bair.berkeley.edu/blog/2023/04/03/koala/)。

**一味地维护全球最大规模的模型，实际上可能让我们处于不利地位。**

* * *

### 数据质量比数据规模更重要

许多开源项目[使用小而高质量的数据集](https://bair.berkeley.edu/blog/2023/04/03/koala/)进行训练，从而大大节省了时间。这表明在数据扩展规律上还有一定的灵活性。这样的数据集呼应了[《Data Doesn’t Do What You Think》](http://www.internalgooglesitescrubbedbyus.com/)中的思路，现已成为 Google 之外训练的常见手段。这些数据集通常通过合成方法（例如筛选现有模型输出中的最佳响应）或整合其他项目的资源来构建，而这些方式在 Google 内部还没有占据主流。

**值得庆幸的是，这些高质量数据集都是开源的，我们可以免费使用。**

* * *

与开源正面竞争是必然的败局
-------------

最近的进展对我们的商业战略有着直接且立竿见影的影响。**如果能免费获得质量可比、且没有使用限制的模型，谁还会愿意付费使用 Google 的受限产品？**

我们也不应该奢望能够迎头赶上。[现代互联网建立在开源之上](https://openuk.uk/wp-content/uploads/2021/07/State-of-Open-Phase-Two.pdf)，这是有原因的。开源具备一些我们无法复制的重大优势。

* * *

### 我们对他们的需求大于他们对我们的需求

让技术保密本来就很难。Google 的研究员不断流向其他公司，我们可以假设他们对我们所有的技术都了如指掌，而只要这种人员流动不停，这种情况就会一直存在。

但随着在 LLM 领域做前沿研究的门槛日益降低，要守住“技术保密”的竞争优势将更加困难。世界各地的研究机构在相互成果上持续构建，以远超我们产能的广度去探索各种解决方案。我们可以死守秘密，让外部的创新不断稀释它的价值，也可以互相学习、合作。

* * *

### 个人与公司相比，不受版权许可的限制

许多创新是在使用 Meta 泄露出来的模型权重的基础上完成的。虽然随着[真正开源的模型](https://bigscience.huggingface.co/blog/bloom)不断变得更好，这一点会发生改变，但关键是社区无需等待。个人在“个人使用”这一法律框架以及实际无法追踪处罚的背景下，可以在第一时间获取这些前沿技术。

* * *

### 当自己就是用户，就能更好地理解需求

回顾在图像生成领域出现的那些用户自制模型，从动漫生成器到 HDR 风景，无不展现出惊人的创意。而这些模型正是由对各自领域有深入理解与热爱的人打造的，我们很难与他们在特定细分领域所积累的专业性与同理心相提并论。

* * *

拥抱生态系统：让开源为我们所用
---------------

矛盾的是，这次所有动向中，唯一明确的受益者就是 Meta。因为被泄露的权重是他们的，他们实际上获得了全球范围内免费的人力资源。大部分开源创新都基于他们的体系结构，而这并不妨碍他们将这些成果直接纳入自己的产品。

**拥有一个生态系统的价值是难以估量的。** Google 也曾经通过类似的开源策略在 Chrome 和 Android 上尝到过甜头。通过拥有进行创新的平台，Google 巩固了自己作为行业“思想领袖”和“方向制定者”的地位，并能在超越自身的更宏大议题上掌握话语权。

**我们对模型的控制越严格，开源替代方案就越有吸引力。** Google 和 OpenAI 都出于防御性考虑，倾向于以严密可控的方式发布模型。但这种控制其实只是空想。任何想要用 LLM 做“未授权用途”的人，大可以直接使用那些完全开源的模型。

Google 应当成为开源社区的领导者，通过协作（而不是忽视）来参与到更广泛的对话里。这可能需要采取一些让人不安的举措，比如公布小型通用语言模型（ULM）变体的权重。这必然意味着放弃对我们模型的部分控制。但这个妥协是不可避免的。我们无法一边带动创新，一边又完全操纵创新。

* * *

尾声：那 OpenAI 呢？
--------------

对于 OpenAI 目前的闭源策略，或许有人会觉得这对他们并不公平——为什么我们要分享，而他们却不分享？但事实是，我们已经通过人才流失的方式在“分享”一切了。只要我们无法阻止核心研究人员被挖走，保密就形同虚设。

更关键的是，**OpenAI 并不重要。** 他们在与开源的博弈中犯下了和我们相同的错误，他们能否保持领先地位也面临质疑。开源替代方案迟早会赶超他们，除非他们改变这种立场。在这方面，至少我们可以先行一步。

* * *

时间线
---

### 2023 年 2 月 24 日 – LLaMA 上线

[Meta 发布了 LLaMA](https://ai.facebook.com/blog/large-language-model-llama-meta-ai/)，开源了代码，但未开源权重。此时，LLaMA 并未进行指令微调或对话微调。和许多现有模型类似，它参数规模相对较小（提供 7B、13B、33B、65B 四种），但训练时长较长，相对模型规模来说表现相当不错。

### 2023 年 3 月 3 日 – 不可避免的事情发生了

不到一周后，[LLaMA 权重在网上被泄露](https://www.vice.com/en/article/xgwqgw/facebooks-powerful-large-language-model-leaks-online-4chan-llama)。其对社区的影响无法估量。虽然基于 Meta 的许可条款无法进行商业用途，但任何人都能拿来做实验。从这天起，创新接踵而至。

### 2023 年 3 月 12 日 – 在树莓派上运行语言模型

仅仅一周多以后，Artem Andreenko [成功在树莓派上运行模型](https://github.com/ggerganov/llama.cpp/issues/58)。此时由于需要频繁从存储中读写权重，速度非常慢，还无法实际应用。但它为后续的一系列精简努力奠定了基础。

### 2023 年 3 月 13 日 – 在笔记本上进行微调

第二天，斯坦福发布了 [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html)，为 LLaMA 添加了指令微调。不过，比模型本身更重要的是 Eric Wang 的 [alpaca-lora](https://github.com/tloen/alpaca-lora) 仓库，它利用了[低秩微调（LoRA）](https://arxiv.org/abs/2106.09685)，在一张 RTX 4090 显卡上“用几小时”就能完成微调。

突然间，任何人都能在此基础上做指令微调，无论用途如何，开启了一场“低预算微调”竞赛。论文中甚至会特意写明微调只花了几百美元。此外，低秩更新可以独立于 Meta 的原始权重进行分发，不受其许可限制。任何人都能分享和应用这些更新。

### 2023 年 3 月 18 日 – 现在速度也快了

Georgi Gerganov [使用 4 位量化](https://github.com/ggerganov/llama.cpp)在 MacBook CPU 上运行 LLaMA。这是首个“无需 GPU”且足够快可实际使用的方案。

### 2023 年 3 月 19 日 – 130 亿参数的模型就能“媲美” Bard

次日，一个跨多所大学的团队发布了 [Vicuna](https://lmsys.org/blog/2023-03-30-vicuna/)，并使用 GPT-4 进行评测，给出了模型输出的定性对比。虽然评测方法有一定争议，但该模型确实比此前的变体强。**训练成本：300 美元。**

值得注意的是，他们能够在绕过 ChatGPT API 限制的情况下使用其对话数据——他们只是在网上收集用户分享到 [ShareGPT](https://sharegpt.com/) 等平台的优质 ChatGPT 对话样本。

### 2023 年 3 月 25 日 – 自己选择你想要的模型

Nomic 创建了 [GPT4All](https://github.com/nomic-ai/gpt4all)，包含一个[模型](https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf)，但更重要的是一个[生态系统](https://github.com/nomic-ai/gpt4all#gpt4all-compatibility-ecosystem)。这是首次将（包括 Vicuna 在内的）多个模型汇集在一个平台上。**训练成本：100 美元。**

### 2023 年 3 月 28 日 – 开源的 GPT-3

Cerebras（与 Google 的 Cerebra 不同）使用 Chinchilla 给出的最优计算调度和[μ 参数化（μ-parameterization）](https://arxiv.org/abs/2203.03466)的最优规模来训练 GPT-3 架构，大幅度超越已有的 GPT-3 克隆。这是 μ 参数化“在野外”首次得到确认应用。该模型是从头训练，意味着社区不再完全依赖 LLaMA。

### 2023 年 3 月 28 日 – 一小时内完成多模态训练

通过一种新的参数高效微调（PEFT）方法，[LLaMA-Adapter](https://arxiv.org/pdf/2303.16199.pdf) 在一小时内同时完成了指令微调和多模态微调。令人惊叹的是，他们只训练了 120 万个可学习参数，就达成了新的多模态 ScienceQA SOTA。

### 2023 年 4 月 3 日 – 真实人类无法分辨一个 130 亿参数的开源模型和 ChatGPT

伯克利推出 [Koala](https://bair.berkeley.edu/blog/2023/04/03/koala/)，这是一个完全使用免费可用数据集训练的对话模型。

他们迈出了关键一步：用真实人类偏好来比较这个模型和 ChatGPT。尽管 ChatGPT 仍略胜一筹，但超过 50% 的情况下，用户要么更喜欢 Koala，要么无明显偏好。**训练成本：100 美元。**

### 2023 年 4 月 15 日 – 开源 RLHF 能力达到 ChatGPT 水平

[Open Assistant](https://open-assistant.io/) 发布了[一个模型，尤其是一个数据集](https://drive.google.com/file/d/10iR5hKwFqAKhL3umx8muOWSRm7hs5FqX/view)，用于通过 RLHF 进行对齐（Alignment）。他们的模型在人工偏好上已接近（48.3% vs 51.7%）ChatGPT。此外，他们还展示了如何把该数据集应用于 Pythia-12B，让用户可以实现从底层到上层全开源的模型。更重要的是，因为这个数据集是公开的，RLHF 从过去的“难以企及”一下子变得既便宜又简便，方便小规模研究者进行尝试。

* * *

## 关联主题
- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/lora]]
- [[00-元语/OpenAI]]
- [[00-元语/github]]
- [[00-元语/decision-making]]
- [[00-元语/meta]]
- [[00-元语/community]]
- [[00-元语/multimodal]]
- [[00-元语/risk]]
