# 问答：如何使用 GPT 知道我写 R 代码？

## 文档信息
- 来源：https://baoyu.io/blog/ai/qa-how-to-use-gpt-to-write-code
- 发布日期：2024-06-07
- 作者：宝玉

## 摘要

### 一句话总结
针对如何使用大语言模型辅助修改和理解现成的 R 代码，本文建议一次性提交完整的参考代码与需求，并遵循提供清晰上下文、控制输入长度以及选择强能力模型的原则。

### 关键要点
* **工具适用场景**：GitHub Copilot 适合局部功能模块的代码自动完成；大语言模型（如 MS Copilot）更适合处理和调整完整代码。
* **GitHub Copilot Chat 限制**：该工具基于针对代码微调的 GPT-4，代码能力强，但上下文窗口长度仅约 8K。
* **提问策略**：建议先一次性将所有需求和参考代码提交给大模型，然后根据输出结果进行多轮追问或调整。
* **代码理解辅助**：对于看不懂的现成代码，不仅可以要求模型修改，还可以让其逐行写注释和解释代码。
* **上下文完整性**：提供的上下文越完整、要求越清晰，结果越好。若代码过长，可提取独立模块输入，并用注释说明外部引用的作用。
* **上下文长度控制**：模型上下文限制包含“输入+输出”（如 ChatGPT Plus 的 GPT-4 限制为 32K Tokens，约 2 万单词），建议单次输入内容不超过总限制的 1/2。
* **模型选择**：强烈建议使用能力最强的模型（如付费的 GPT-4 或 Claude 3），其效果会显著优于免费的 GPT-3.5。

### 风险/不足
* **会话截断风险**：在 App（如 ChatGPT）的同一个会话中持续聊天过久，最前面的对话会被截断或摘要，导致历史信息丢失。
* **幻觉与质量下降**：单次输入的内容越多，模型出现幻觉的可能性就越大，输出质量也会下降（建议在保证完整性的前提下尽量精简输入）。

## 正文
问：我用文字描述的方式请教 copilot 指导我写 R 代码（科研作图用），但效果不好。与此同时我查到一现成的完美代码，但因为看不懂，无法根据实际情况调整，所以也无法复现。这个时候我想让 copilot 帮我协调一下，即用现成的代码基础上根据我的说明进行调整，promote 我应该一次性说清楚，还是分多次？

答：

不确认是说的 GitHub Copilot 还是 MS Copilot，前者是辅助代码自动完成，后者是大语言模型。如果是完整代码，那么大语言模型会效果更好，如果是某个功能模块内部代码，那么代码自动完成效果好。GitHub Copilot 也有 Copilot Chat，是针对代码微调的 GPT-4 版本，代码能力很强，缺点是上下文窗口长度只有 8K（我记忆中）

问题中这种情况适合大语言模型，因为可以完整输入你所有代码（如果不是特别长）。所以建议先一次性将所有需求包括要参考的代码提交给大语言模型，然后看输出的结果是不是满足要求，根据输出的内容进一步提要求或者追问。不仅限于生成代码，还可以让其对参考的代码写注释，解释代码。

这种写代码、解释代码任务记住几个基本原则：

1.   你提供的上下文信息越完整，要求越清晰，越能得到好的结果。 所以尽可能输入完整代码内容。如果代码太长，可以把一个独立模块输入，如果模块有外部引用的代码，加上注释说明其作用也可以的。

2.   注意上下文长度限制 每个模型都有其限制的上下文长度，比如 ChatGPT Plus 中的 GPT-4，最长上下文是 32K Tokens，相当于 2 万左右单词。如果你输入的上下文太长，需要手动整理拆分，输入的内容不要超过上下文长度限制 1/2，因为上下文窗口限制不仅仅是针对输入，是输入和输出加一起。

但也不是说限制 32K，你就可以顶格输入输出到 32K，这里面还有两个问题： 1). App 本身会对输入的长度进行优化，比如说你在 ChatGPT 里面聊天，同一个会话一直聊，那么最前面的会话到一定时候就会被截断或者摘要，会丢失很多信息 2). 输入的内容越多，模型出现幻觉的可能越大，输出质量也会下降，所以尽可能让输入小一些会质量更高一些

1.   尽可能使用能力最强的模型 比如你使用免费的 GPT-3.5 和收费的 GPT-4，效果会差别很大，有条件的话建议花钱订阅高质量的模型，例如 GPT-4 或者 Claude 3 等

最后就是多试试不同的方式，比如解释代码、先实现个小模块，肯定是能帮到你的。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/copilot]]
- [[00-元语/ChatGPT]]
- [[00-元语/Claude]]
- [[00-元语/prompt]]
- [[00-元语/context-optimization]]
- [[00-元语/workflow]]
