# 迈向神经符号AI：从逻辑到概率逻辑，再到神经概率逻辑

## 文档信息

- 来源：用户提供的讲座转写文本
- 形式：视频字幕转写整理
- 讲者：Luke De Raedt（字幕转写中称 LUKE，以转写为准）
- 主题：ProbLog、DeepProbLog、DeepStochLog 与神经符号推理的构建路径
- 整理说明：由转写整理成文，已做断句、去口癖与结构化；部分人名与系统名可能存在转写误差
- 记录日期：2026-02-22

## 摘要

**1) 一句话总结**
讲者 Luke De Raedt 提出，通过融合神经网络（感知）、逻辑（推理）与概率（不确定性），并借助神经谓词与概率逻辑编程（如 DeepProbLog 和 DeepStochLog），可以构建出兼具“快思考”与“慢思考”能力的端到端神经符号 AI 系统。

**2) 关键要点**
*   **核心动机**：现实系统（如自动驾驶）不能仅依赖端到端的数据驱动，应将人类已知的明确规则作为先验知识接入系统，结合深度学习的感知能力与逻辑的推理能力。
*   **神经符号 AI 三要素**：系统必须结合神经网络（提取原始信息）、逻辑（提供可组合、可解释的结构化知识）与概率（处理不确定性并在连续空间中优化）。
*   **概率与模糊逻辑的区别**：模糊逻辑面向“程度”表达，概率面向“不确定性”建模；在处理严格的独立性与互斥性时，模糊逻辑不能直接替代概率推理。
*   **逻辑接入的两条传统主线**：一是将逻辑转化为网络结构（如神经定理证明器，偏证明论）；二是将逻辑作为学习目标的约束（如语义损失，偏模型论）。
*   **基于“神经谓词”的构建路径**：将神经网络封装为逻辑中的谓词（作为叶子节点），使其输出可用于逻辑组合的数值，并支持梯度从查询结果一路反传到神经网络参数。
*   **证明结构的电路编译**：在概率语义下，由于不同证明路径可能共享底层事实（既不互斥也不独立），必须将证明结构编译成特定的电路形式，才能安全地执行加乘运算与反向传播。
*   **DeepProbLog 系统**：在 ProbLog 基础上扩展，保留了完整的逻辑推理能力；通过注入已知逻辑结构（如手写数字加法任务中的加法规则），将学习压力集中在感知端（数字识别）。
*   **DeepStochLog 系统**：转向随机游走与概率上下文无关文法语义，将解析树对应为证明结构；在同一输入有多种解析方式时，可通过概率相加提升综合计算的工程效率。

**3) 风险与缺口**
*   **规模化瓶颈**：系统在扩展规模（Scaling up）时面临现实困难。
*   **符号实例化（Symbol Grounding）难题**：当输入（如图像）中存在多个干扰物体时，将符号正确“落地”到对应对象上依然困难，存在歧义。
*   **推理效率低下**：严格的概率推理计算开销极大，未来可能需要更多地依赖采样式推理来缓解性能压力。

## 正文

这段分享以一个直观的动机开场：深度学习擅长“快速思考”的感知任务，例如从图像中识别人和物体；而现实系统还需要“慢思考”的推理能力，例如把规则、约束与规划整合进决策过程。讲者认为，要把两者真正接起来，仅仅把“神经网络 + 逻辑”放在一起还不够，还需要把概率（或更广义的连续数值语义）作为第三个关键组件纳入系统设计。

### 1. 快思考与慢思考：为什么自动驾驶不是纯端到端就能解决

讲者用驾照考试式的场景题说明“组合能力”的必要性：

- 感知：识别车辆、行人、交通标志等对象，这是数据驱动方法的强项。
- 规则推理：依据交通规则判断“该不该走、谁先行”等，这是知识驱动方法更自然的表达方式。

他强调：很多规则本来就已经被人类明确写出并长期使用，因此更合理的路线是把这些规则作为先验知识接入系统，而不是完全依赖数据去隐式“学出规则”。

### 2. 神经符号AI的三要素：神经网络、逻辑与概率

讲者提出一个判断标准：真正的神经符号系统需要至少三块能力拼在一起：

- 神经网络提供从原始信号中提取信息的能力。
- 逻辑提供可组合、可复用、可解释的结构化知识与推理方式。
- 概率提供处理不确定性的机制，使系统可以在连续空间里学习和优化。

他还提醒：模糊逻辑常被当作概率推理的“简化替代”，但两者关注点不同。模糊逻辑主要面向“程度”的表达，而概率面向“不确定性”的建模；在需要严格符合概率公理、处理独立性与互斥性时，直接用模糊逻辑替代可能带来意料之外的推理行为。

### 3. 两条主线：逻辑做结构，逻辑做约束

讲者回顾神经符号系统时，强调了两种常见的组织方式：

1) 逻辑用来塑造网络结构（偏证明论视角）

- 代表性的早期路线是把逻辑规则改写成“与或结构”，再把它嵌进神经网络中训练（转写中提到 KBANN 等思想）。
- 现代变体包括神经定理证明器一类方法：通过“软统一”等机制，把符号匹配变成可微的相似度计算，再在此基础上学习。

这一路线的特点是：逻辑强烈影响模型结构与学习路径，但训练完成后，逻辑往往不再作为一个“可独立推理的组件”被保留。

2) 逻辑用来约束学习目标（偏模型论视角）

讲者以语义损失为例：当任务本质是多分类时，“只能有一个类别为真”是一条明确的逻辑约束；系统把“约束被满足的程度”转成损失项，作为对神经网络输出的正则化。

这一路线的特点是：逻辑进入了损失函数，成为学习的偏好或约束条件，但它同样不一定等价于“保留一个可复用的逻辑推理机”。

### 4. 一条可复用的构建路径：用神经谓词把神经网络接进逻辑

讲者给出一套他认为更“接口化”的构建步骤，核心是神经谓词：

1) 选一个逻辑体系，写出事实与规则。
2) 把神经网络封装成逻辑里的谓词，使其能被推理过程调用，并输出可用于后续组合的数值。
3) 选择数值语义：概率语义或模糊语义等。
4) 生成证明结构，把逻辑中的与或关系转成可计算的结构。
5) 让梯度能从查询结果一路反传到神经网络参数，完成端到端训练。

讲者特别强调了第 4 步在概率语义下的难点：同一查询可能存在多条证明路径，而不同路径可能共享同一组底层随机事实，导致路径之间既不互斥也不独立。这会使“把或节点当加法、把与节点当乘法”的直觉失效。为此，需要把证明结构进一步编译成更适合概率计算的电路形式，使分支满足所需的结构性质，从而可以安全地执行加乘运算并进行反向传播。

### 5. DeepProbLog：在 ProbLog 上引入神经谓词，保留推理与学习

讲者以 ProbLog 为基础，介绍了 DeepProbLog 这一扩展的核心想法：

- 逻辑部分仍然存在：你仍然可以做推理，构造证明结构。
- 神经网络位于结构的叶子节点：叶子上的“神经谓词”负责从数据（如图像）中给出概率分布或置信度。
- 概率推理通过编译后的电路执行：得到可微的计算图后，可以用反向传播训练神经网络。

他用“手写数字加法”的经典任务来说明“知识注入”带来的好处：训练样本只给出两张图片与它们的和；系统把“加法”作为已知结构写进逻辑层，从而让学习压力集中在识别数字这一步，而不是同时从数据里摸索出运算规则。

### 6. DeepStochLog：从随机图走向随机游走与概率文法

讲者随后介绍 DeepStochLog，把语义视角从“随机图式的概率事实选择”转向“随机游走式的规则选择”：

- 以概率上下文无关文法为例：在同一个非终结符下，多条产生式规则的概率之和为 1；生成解析树的概率等于沿途选用规则概率的乘积。
- 当把文法扩展进逻辑（包含统一与信息传递）后，解析树可以对应到证明结构；在此基础上再引入神经谓词，就得到面向语法与结构的神经符号模型。

讲者指出，这类语义在某些计算流程上更直接：同一输入若存在多种解析方式，可以把不同解析的概率相加完成综合，从而在工程上获得更高的效率。

### 7. 问答摘录：规模化、符号实例化与并行

在问答部分，讲者把困难归结到一个现实瓶颈：扩展规模。

- 符号实例化：当图像里有多个干扰物体时，如何把符号正确“落地”到对象上依然困难；一种思路是为不同符号设计不同的神经谓词，并结合关系约束与常识约束来减少歧义。
- 推理效率：概率推理的开销很大，未来可能更多依赖采样式推理。
- 并行化：原则上可以对不同样本构建不同电路并行处理，或在电路层面做并行计算。
- 解析树与证明的关系：在讲者的视角下，两者在逻辑层面高度对应；把语法写进逻辑之后，解析就可以被视为一种证明过程。

总体来看，这段分享把神经符号系统放回“逻辑、概率、学习”三者的共同问题域中：既要保持可表达、可推理的结构，又要让计算能落到可扩展的训练与推理流程上。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/数学]]
- [[00-元语/learning-resource]]
