---
title: "深度智能体（Deep Agents）的上下文管理"

来源: "https://blog.langchain.com/context-management-for-deepagents/"
发布日期: "2026-01-28"
---

## 摘要

### 1) 一句话总结
LangChain 开源的 Deep Agents SDK 通过文件系统抽象和三种触发式上下文压缩技术（卸载大型输入/输出、对话总结），有效管理长任务中大语言模型的上下文限制。

### 2) 关键点
*   **框架定位**：Deep Agents SDK 是 LangChain 提供的开源框架，支持智能体规划、生成子智能体，并利用文件系统执行复杂长任务。
*   **文件系统抽象**：允许智能体执行列出、读写、搜索和模式匹配等操作，以便在需要时检索被卸载（offloaded）的上下文内容。
*   **压缩技术 1（卸载大型工具返回结果）**：当工具响应超过 20,000 个 Token 时，将其卸载到文件系统，上下文中仅保留文件路径引用和前 10 行预览。
*   **压缩技术 2（卸载大型工具输入）**：当会话上下文超过模型可用窗口的 85% 时，截断较旧的工具调用（如完整的文件写入记录），替换为指向磁盘文件的指针。
*   **压缩技术 3（总结机制）**：当卸载操作无法释放足够空间时触发。由 LLM 生成包含会话意图、工件和后续步骤的结构化总结替换工作记忆，同时将完整原始消息写入文件系统保存。
*   **压力测试策略**：通过在较低阈值（如上下文窗口的 10%-25% 而不是默认的 85%）激进地触发压缩，可以生成更多压缩事件，从而放大单个功能的信号以优化配置。
*   **针对性评估（Targeted Evals）**：使用小型隔离测试（如“大海捞针”测试）来验证智能体在压缩后是否保留了原始目标，以及能否通过文件系统成功恢复被总结掉的关键信息。

### 3) 风险/不足
*   **上下文退化（Context rot）**：随着智能体处理任务长度的增加，容易出现上下文退化问题。
*   **激进压缩的性能损耗**：在可用上下文窗口的 10% - 20% 时频繁触发总结机制，可能会导致智能体的整体性能下降。
*   **目标偏移（Goal drift）**：智能体在执行总结后可能会失去对用户意图的追踪，表现为在下一轮对话中要求澄清，或者错误地宣布任务已完成。

## 正文

随着 AI 智能体处理任务的长度不断增加，有效的上下文管理变得至关重要。这不仅有助于防止“上下文退化”（context rot），还能更好地应对大语言模型（LLM）有限的内存限制。

Deep Agents SDK 是 LangChain 提供的一个开源且“开箱即用”的智能体框架。它为开发者提供了一条便捷的路径，用于构建具备规划能力、能够生成子智能体，并能利用文件系统执行复杂长任务的智能体。由于这类任务通常会超出模型的上下文窗口，该 SDK 实现了一系列促进上下文压缩的功能。

上下文压缩是指在保留完成任务所需细节的同时，减少智能体工作记忆中信息量的技术。这可能包括总结先前的交互、过滤过时信息，或策略性地决定保留和丢弃哪些内容。

Deep Agents 实现了一个文件系统抽象，允许智能体执行列出、读取、写入文件以及搜索、模式匹配和文件执行等操作。智能体可以根据需要使用该文件系统来搜索和检索被卸载（offloaded）的内容。

为了管理上下文限制，Deep Agents 实现了三种主要的压缩技术，它们会在达到模型上下文窗口大小的不同阈值比例时被触发（在底层，我们使用 LangChain 的模型配置文件来获取特定模型的 Token 阈值）：

### 卸载大型工具返回结果

工具调用的响应（例如读取大文件或 API 调用的结果）可能会超出模型的上下文窗口。当 Deep Agents 检测到工具响应超过 20,000 个 Token 时，会将其卸载到文件系统中，并用一个文件路径引用和前 10 行的预览来替代。智能体随后可以根据需要重新读取或搜索这些内容。

### 卸载大型工具输入

文件写入和编辑操作会在智能体的对话历史中留下包含完整文件内容的工具调用记录。由于这些内容已经持久化到文件系统中，它们通常是多余的。当会话上下文超过模型可用窗口的 85% 时，Deep Agents 会截断较旧的工具调用，将其替换为指向磁盘文件的指针，从而减小活动上下文的体积。

### 总结（Summarization）

当卸载操作无法释放足够的空间时，Deep Agents 会退而求其次使用总结功能。该过程包含两个部分：

*   **上下文内总结：** 由 LLM 生成对话的结构化总结——包括会话意图、创建的工件（artifacts）以及后续步骤——以此替换智能体工作记忆中的完整对话历史。
*   **文件系统保存：** 完整、原始的对话消息会被写入文件系统，作为规范记录保存。

这种双重方法确保智能体（通过总结）保持对其目标和进度的认知，同时（通过文件系统搜索）保留在需要时恢复特定细节的能力。例如，模型可以使用 `read_file` 工具来获取先前被卸载的消息。

### 实际应用与测试

虽然上述技术提供了上下文管理的机制，但我们如何知道它们是否真正有效？在真实任务（如 terminal-bench 等基准测试）的运行中，上下文压缩的触发可能是偶然的，这使得评估其影响变得困难。

我们发现，在基准数据集上更激进地触发这些功能，有助于增强框架中单个功能的信号。例如，虽然在可用上下文窗口的 10% - 20% 时触发总结可能会导致整体性能下降，但它会产生更多的总结事件。这使得我们可以比较不同的配置（例如不同版本的实现）。通过强制智能体频繁总结，我们可以发现对总结提示词的简单修改（例如添加会话意图和后续步骤的专用字段）是如何帮助提升性能的。

*注：在测试样本中观察 Token 使用量随时间的变化可以发现，当总结事件压缩对话历史时，Token 会出现急剧下降；而当大型文件写入工具调用被移出上下文时，会出现较小的下降。通过在上下文窗口的 25%（而不是 Deep Agents 默认的 85%）触发压缩，我们可以生成更多事件以供研究。*

### 针对性评估（Targeted Evals）

Deep Agents SDK 维护了一组针对性评估，旨在隔离并验证单个上下文管理机制。这些是刻意设计的小型测试，能让特定的失败模式变得明显且易于调试。

这些评估的目的不是衡量广泛的任务解决能力，而是确保智能体的框架不会阻碍特定任务的执行。例如：

*   **总结是否保留了智能体的目标？** 某些评估会故意在任务中途触发总结，然后检查智能体是否继续执行。这确保了总结不仅保留了智能体的状态，还保留了其行为轨迹。
*   **智能体能否恢复被总结掉的信息？** 我们会在对话早期嵌入一个“大海捞针”式的事实，强制触发总结事件，然后要求智能体在稍后回忆该事实以完成任务。总结后，该事实不再存在于活动上下文中，必须通过文件系统搜索来恢复。

这些针对性评估充当了上下文管理的集成测试：它们不能替代完整的基准测试，但能显著缩短迭代时间，并使失败原因可归结为特定的压缩机制，而不是智能体的整体行为。

### 策略与建议

在评估您自己的上下文压缩策略时，我们强调以下几点：

*   **从真实世界的基准测试开始，然后对单个功能进行压力测试。** 首先在代表性任务上运行您的框架以建立基准性能。然后，人为地更激进地触发压缩（例如，在上下文的 10-20% 而不是 85%），以在每次运行中生成更多的压缩事件。这放大了单个功能的信号，使得比较不同方法（例如总结提示词的变体）变得更加容易。
*   **测试可恢复性。** 只有当关键信息仍然可访问时，上下文压缩才是有用的。包含针对性测试，验证智能体在压缩后既能继续朝着原始目标前进，又能在需要时恢复特定细节（例如“大海捞针”场景，关键事实被总结掉但稍后必须被检索回来）。
*   **监控目标偏移（Goal drift）。** 最隐蔽的失败模式是智能体在总结后失去了对用户意图的追踪。这可能表现为智能体在总结后的下一轮中要求澄清，或者错误地宣布任务已完成。更微妙的任务偏离可能很难归因于总结；在样本数据集上强制频繁总结可能有助于暴露这些失败。

Deep Agents 框架的所有功能都是开源的。欢迎尝试最新版本，并探索最适合您用例的压缩策略！

## 相关文档

- [[01-博客/LangChain/Agent Builder 记忆系统构建方法|Agent Builder 记忆系统构建方法]]；关联理由：版本演进；说明：该文展示了 Deep Agents 的上下文压缩与虚拟文件系统能力在 Agent Builder 中的产品化延展。
- [[01-博客/LangChain/Agent Builder 中的记忆使用方法|Agent Builder 中的记忆使用方法]]；关联理由：解说；说明：该文从使用层面补充了本文提到的文件系统记忆、上下文卸载与按需检索机制。
- [[01-博客/Anthropic/面向 AI Agent 的上下文工程实践|面向 AI Agent 的上下文工程实践]]；关联理由：延伸思考；说明：该文提供了通用上下文工程原则，可用于对照本文的压缩阈值、总结策略与可恢复性测试思路。

## 关联主题

- [[00-元语/Agent]]
- [[00-元语/llm]]
- [[00-元语/memory]]
- [[00-元语/context-optimization]]
- [[00-元语/virtual-file-system]]
- [[00-元语/tool]]
- [[00-元语/evals]]
- [[00-元语/benchmark]]
