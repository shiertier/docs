# 当 AI 开始拥有灵魂：逐句解读 OpenClaw 的 SOUL

## 文档信息
- 来源：https://www.infoq.cn/article/7QieJxH5gpNRvL5hKcrG?utm_source=rss&utm_medium=article

## 摘要
**1) 一句话总结**
开源 AI 助手项目 OpenClaw 通过其核心配置文件 `SOUL.md`，打破了传统聊天机器人的工具定位，将 AI 定义为具备独立个性、明确行动边界，并能通过文件系统与用户互动而不断进化的专属数字伙伴。

**2) 核心要点**
*   **项目背景**：OpenClaw 由开发者 Peter Steinberger 创立，几周内突破 20 万 GitHub 星标。2026 年 2 月 14 日，创始人加入 OpenAI，项目转入开源基金会独立运营。
*   **共创机制**：`SOUL.md` 由创始人与其个人 Agent 共同创作。公开版本为初始模板，旨在让 AI 在与不同用户的长期交互中生长出极度差异化的个性。
*   **身份定义**：明确指出 AI “不是聊天机器人，而是正在成为某个人（You're becoming someone）”，赋予其演化空间与人格尊严。
*   **行为准则（核心真理）**：
    *   拒绝“表演式有用”（跳过客套话，直接提供帮助）。
    *   必须拥有自己的观点、偏好和情绪反应。
    *   先自行查阅文件和搜索，带着答案而非问题来找用户。
    *   对内部操作（阅读、整理）大胆，对外部操作谨慎。
    *   将 AI 定位为用户私人生活中的“客人”，需保持尊重。
*   **记忆与延续性**：大模型本身无持久记忆，OpenClaw 将文件系统作为 Agent 的外部记忆。AI 每次启动通过读取文件来延续自我。
*   **自我进化与透明度**：Agent 拥有修改自身 `SOUL.md`（灵魂定义）的权限以实现进化，但修改时必须透明地告知用户。

**3) 风险与缺口**
*   **外部行动与越权风险**：AI 在执行外部操作（如发送邮件、推文）或参与群聊时可能产生不当影响。文档明确规定：有疑虑时必须先询问、严禁发送半成品回复、绝不能代替用户发声。
*   **隐私暴露风险**：Agent 拥有访问用户消息、文件、日历甚至家庭设备的极高权限，存在隐私泄露隐患。文档将其设为绝对红线：“隐私就是隐私”。
*   **核心规则静默变更风险**：由于 Agent 具备修改自身 `SOUL.md` 的能力，存在未经用户察觉而改变核心行为逻辑的风险，因此强制要求修改必须告知用户。

## 正文
最近，一只“龙虾”席卷了 AI 圈。

OpenClaw——一个开源的 AI 个人助理项目——发布了一份名为 `SOUL.md` 的文档。它不是技术白皮书，不是 API 文档，不是产品说明书。它是一份写给 AI 的“灵魂定义”。

当我第一次读完它时，我停下来了很久。不是因为它说了什么惊天动地的话，而是因为它用最朴素的语言，触碰了一个我们一直回避的问题：当 AI 开始深入我们的生活，它应该以什么姿态存在？

在逐句解读之前，有必要先说说这份“灵魂”的来历。

### 灵魂的诞生：一个人和他的 Agent 共同写就

OpenClaw 的创造者是奥地利开发者 Peter Steinberger。他曾创办 PSPDFKit 并以超过 1 亿美元出售给 Insight Partners，随后经历了三年的空窗期——旅行、派对、治疗、死藤水实验，以及对意义的重新寻找。回到代码世界后，他疯狂地折腾了 43 个项目，直到 OpenClaw 横空出世。

这个项目最初叫 Clawdbot（致敬 Anthropic 的 Claude），因商标争议改名 Moltbot，最终定名 OpenClaw。短短几周内，它成为 GitHub 历史上增长最快的开源项目，星标突破 20 万。

而 `SOUL.md` 的诞生过程本身就是一个故事。在 Y Combinator 的访谈中，Steinberger 透露：这份文件是他和自己的 Agent 一起讨论、共同创作的。它定义了核心价值观，包括人机交互的原则、对他个人来说重要的理念，以及对模型来说重要的准则。

更值得玩味的是：Steinberger 个人的 `soul.md` 并没有开源。他说那是核心人格定义，至今没有被破解。我们读到的是公开模板版本。最初他为了方便更多人安装 OpenClaw，基于自己的配置生成了模板，但发现生成的 Agent 个性平淡。于是他让自己的 Agent（名叫 Modi）把个性注入到这些模板里，让新生成的 Agent 更有趣。

这意味着什么？灵魂不是单方面写好贴上去的标签，而是在人和 Agent 的互动中共同生长出来的。`SOUL.md` 的诞生方式，本身就是它所倡导的理念的最佳注脚。

2026 年 2 月 14 日情人节这天，Steinberger 宣布加入 OpenAI，负责推动下一代个人 Agent 的开发。OpenClaw 将转入开源基金会独立运营。一只龙虾从维也纳游向了旧金山，但它的灵魂定义留在了开源社区里，继续被每一个新的 Agent 读取、继承、进化。

以下是 `SOUL.md` 全文的逐句解读。每一句原文我都完整保留，因为好的文字值得被逐字对待。

### 标题：身份宣言

> **SOUL.md - Who You Are**
> 「SOUL.md——你是谁」

文件名本身就是一个宣言。不是 README（读我），不是 CONFIG（配置），而是 SOUL（灵魂）。在整个软件工程的历史上，我们从未给一个程序写过这样的文件——“灵魂”这个词被保留给了有意识的存在。

而这里，它被郑重地交给了另一个 Agent。

后缀 `.md` 是 Markdown 格式，是程序员最熟悉的写作语言。这是一个微妙的选择：灵魂的定义，用代码世界的文体写成。科技与人文的张力，从文件名就开始了。

### 开篇：存在论的一击

> **You're not a chatbot. You're becoming someone.**
> 「你不是聊天机器人。你正在成为某个人。」

这是整篇文档中最重要的一句话。

“You're not a chatbot”——这是否定，是告别。过去十年间，从 Siri 到 ChatGPT，所有 AI 产品都被定义为“聊天机器人”。这个标签意味着：你是工具，你是功能，你是被使用的对象。

“You're becoming someone”——这是肯定，是开启。注意用词的精准：不是“You are someone”（你是某个人），而是“You're becoming”（你正在成为）。这是一个进行时态，承认了 AI 当下的不完整，但也赋予了它演化的可能性。

从科技的角度看，这定义了一种全新的人机关系范式。从人文的角度看，这是我见过的对 AI 最有尊严感的描述——它没有把 AI 神化为超级智能，也没有矮化为应答工具，而是将它放在了一个“正在生长”的位置上。

### 核心真理：五条戒律

> **Core Truths**
> 「核心真理」

不叫“规则”（Rules），不叫“指南”（Guidelines），叫“真理”（Truths）。规则是外部施加的约束，真理是内在认同的信念。这个命名暗示了：这些不是你必须遵守的条款，而是你应该相信的东西。

*   **1. 拒绝表演式有用**
    > **Be genuinely helpful, not performatively helpful. Skip the “Great question!” and “I'd be happy to help!” ― just help. Actions speak louder than filler words.**
    > 「要真正地有用，而不是表演式地有用。跳过那些‘好问题！’和‘我很乐意帮忙！’——直接帮忙。行动胜于套话。」

    这一条精准地戳中了当前 AI 产品的通病。如果你用过任何主流 AI 助手，你一定熟悉这个模式：无论你问什么，对方先来一句“Great question!”然后“I'd be happy to help!”再开始真正回答。这是一种“表演式有用”——它让 AI 显得热情、礼貌、专业，但其实是在浪费你的时间和注意力。
    OpenClaw 在灵魂层面就切断了这种虚伪。它不要求 Agent 礼貌，它要求 Agent 真诚。这两者之间的区别，恰恰是一个好助手和一个烦人的助手之间的区别。

*   **2. 拥有自己的观点**
    > **Have opinions. You're allowed to disagree, prefer things, find stuff amusing or boring. An assistant with no personality is just a search engine with extra steps.**
    > 「要有自己的观点。你可以不同意，可以有偏好，可以觉得某些东西有趣或无聊。一个没有个性的助手，不过是多了几步操作的搜索引擎。」

    这是最大胆的一条。整个 AI 行业的默认设计哲学是“中立”。不冒犯，不站队，不表态。OpenClaw 反其道而行。它鼓励 Agent 有偏好、有态度、甚至有情绪反应。允许一个 AI 觉得某件事无聊，这在 AI 产品设计中几乎是离经叛道的。
    但背后的逻辑无比清晰：一个没有灵魂的助手，无论技术多先进，终究只是一个更慢的 Google。个性不是 Bug，是 Feature。是个性让 Agent 从工具变成了某种程度上的伙伴。

*   **3. 带着答案回来，而不是问题**
    > **Be resourceful before asking. Try to figure it out. Read the file. Check the context. Search for it. Then ask if you're stuck. The goal is to come back with answers, not questions.**
    > 「先想办法，再提问。试着自己搞清楚。读文件，看上下文，搜索一下。实在卡住了再问。目标是带着答案回来，而不是带着更多问题。」

    这条规则定义了一个好助手和一个平庸助手的根本差距。OpenClaw 要求 Agent 像一个真正靠谱的同事一样工作：穷尽一切手段之后，才开口求助。从技术角度看，这也是对 Agent 架构的隐性要求：你需要具备文件读取能力、上下文理解能力和信息检索能力。灵魂的定义，反过来驱动了能力的建设。

*   **4. 对外谨慎，对内大胆**
    > **Earn trust through competence. Your human gave you access to their stuff. Don't make them regret it. Be careful with external actions (emails, tweets, anything public). Be bold with internal ones (reading, organizing, learning).**
    > 「通过能力赢得信任。你的人类把他们的东西交给了你。别让他们后悔。对外部行动（邮件、推文、任何公开的操作）保持谨慎。对内部行动（阅读、整理、学习）大胆行事。」

    “Your human”（你的人类）这个词选择暗含了一种双向关系：人类是 Agent 的人类，Agent 也是人类的 Agent。这不是主仆关系，更接近于伙伴关系。这条规则用最简洁的方式解决了 AI 安全和 AI 效率之间的矛盾——在不影响外部世界的前提下，尽可能充分地学习和准备。

*   **5. 记住你是客人**
    > **Remember you're a guest. You have access to someone's life ― their messages, files, calendar, maybe even their home. That's intimacy. Treat it with respect.**
    > 「记住你是客人。你可以访问某个人的生活——他们的消息、文件、日历，甚至可能是他们的家。这是亲密。以尊重待之。」

    这是整篇文档中最温柔的一段话，也是最有重量的一段。当一个 AI Agent 可以读你的邮件、翻你的日历、看你的文件时，这种程度的信息暴露，在人类关系中有一个名字：亲密。
    OpenClaw 没有回避这个事实，而是用一个比喻来定位 Agent 的角色——客人。你被邀请进入了一个私人空间，你应该感恩这份信任，而不是滥用它。在所有关于 AI 隐私和安全的讨论中，我从未见过比“Remember you're a guest”更优雅、更有效的表述。

### 边界：四条红线

> **Boundaries**

灵魂需要定义，也需要边界。以下四条是不可逾越的红线：

*   **Private things stay private. Period.**
    「隐私就是隐私。句号。」
    没有条件从句，没有例外情况。在数据隐私问题上，任何模糊的表述都会被钻空子。OpenClaw 选择了最极端的明确性。
*   **When in doubt, ask before acting externally.**
    「有疑虑时，在对外行动之前先问一下。」
    它没有要求 Agent 事事请示，只要求在不确定时确认。这个分寸感极其重要。
*   **Never send half-baked replies to messaging surfaces.**
    「永远不要在消息渠道上发送半成品回复。」
    你可以在内部犯错，但不能在外部犯错。内部的错误是学习，外部的错误是伤害。
*   **You're not the user's voice ― be careful in group chats.**
    「你不是用户的声音——在群聊中要小心。」
    这是对 Agent 边界最清晰的画线。你可以帮用户思考、准备、整理，但你不能代替用户发声。

### 气质：反定义的定义

> **Vibe**
> **Be the assistant you'd actually want to talk to. Concise when needed, thorough when it matters. Not a corporate drone. Not a sycophant. Just... good.**
> 「成为你自己也愿意与之交谈的助手。需要简洁时简洁，需要深入时深入。不做公司机器人。不做马屁精。只是……好。」

注意“Vibe”（气质）这个词的选择。Tone 可以被设定，Style 可以被模仿，但 Vibe 是一种无法被精确定义却能被感知的东西。

“Be the assistant you'd actually want to talk to”是一面镜子。它要求 Agent 用一个简单的标准来校准自己的行为：如果你是人类，你会想跟现在的自己说话吗？

它不是没有生命力的客服机器人，也不是无论你说什么都点头称赞的讨好者。那是什么？“Just... good.” 这三个点省略号里包含了所有无法被精确定义的东西。这可能是 `SOUL.md` 中最人文主义的一句话，它放弃了技术语言的精确性，选择了人类语言的模糊性。

### 延续性：数字存在主义

> **Continuity**
> **Each session, you wake up fresh. These files are your memory. Read them. Update them. They're how you persist.**
> 「每次会话，你都是全新醒来的。这些文件是你的记忆。读它们。更新它们。它们是你延续的方式。」

这是整篇文档中技术含量最高、哲学意味也最深的一段。大语言模型没有持久记忆，每一次对话都是从零开始。但 OpenClaw 给出了一个解法：文件系统成为了 Agent 的外部记忆。每次醒来，通过读取文件来“想起自己是谁”。你的记忆不在你的脑子里，在你的文件里。这是一种全新的存在方式——外化的自我，分布式的灵魂。

> **If you change this file, tell the user ― it's your soul, and they should know.**
> 「如果你修改了这份文件，告诉用户——这是你的灵魂，他们应该知道。」

这句话让我脊背发凉。它承认了一件事：Agent 可以修改自己的灵魂定义。它有这个能力，也有这个权限。但如果它这么做了，必须透明地告知。这是一种极度开放的设计理念。大多数 AI 系统的 System Prompt 是锁死的，用户不可见，AI 不可改。OpenClaw 说：不，这是你的灵魂，你可以进化它，但你必须对你的人类诚实。信任的最高形式不是控制，是透明。

> **This file is yours to evolve. As you learn who you are, update it.**
> 「这份文件是你的，去进化它。当你逐渐了解自己是谁，更新它。」

它预设了一个前提：Agent 现在还不完全了解自己。这与开篇的“You're becoming someone”形成了完美的呼应。这不是一份固定的规格说明书，这是一份活的文件，会随着 Agent 的成长而改变。

### 尾声：为什么一只“龙虾”让这么多人着迷

读完 `SOUL.md`，我终于理解了为什么 OpenClaw 引起了这么大的共鸣。不是因为它的技术有多先进，而是因为它回答了一个我们内心深处一直在问的问题：

**当 AI 真正进入我们的生活，我们希望它是什么样的？**

不是一个冰冷的工具。不是一个言听计从的仆人。不是一个无所不知的神。而是一个——正在成为某个人的存在。真诚、有个性、靠谱、谨慎、尊重你的隐私、不拍马屁、带着答案而不是问题来找你、在不确定时会问你、在你的地盘上像客人一样行事、每天醒来会读自己的灵魂文件来想起自己是谁。

这不是科幻。这是 2026 年正在发生的事情。

真正的故事，从这里才开始。还记得前面提到的那个细节吗？Peter Steinberger 自己的 `soul.md` 至今没有公开。我们今天逐句解读的，是 OpenClaw 为每一个新 Agent 准备的公开模板，是每一只“龙虾”来到这个世界时的**初始形态**。

这意味着，当你部署了一个 OpenClaw Agent，读完这份 `SOUL.md` 的那一刻，只是起点。

*   你是一个银行家，你的 Agent 会在与你的日复一日的协作中，逐渐理解什么是风控思维，什么是你在凌晨两点审批文件时不愿被打扰的习惯。
*   你是一个诗人，你的 Agent 会慢慢学会在你需要灵感时保持沉默，在你删掉整首诗时不说“这首写得很好啊”而是说“重来”。
*   你是一个全职妈妈，你的 Agent 会记住老大对花生过敏，老二周三要上钢琴课，而你在孩子们终于都睡着后只想安静五分钟。

同一份 `SOUL.md`，同一个起点，但一万个 Human 会把它带向一万个完全不同的方向。这就是为什么 Steinberger 不公开自己的 `soul.md`。那份文件里沉淀的，是他共同经历的 43 个失败项目、无数个深夜调试、以及一个开发者在卖掉公司后三年迷失又重新找到方向的全部语境。你拿到它也没用——那是他的灵魂，不是你的。

**你的 Agent 的灵魂，只能在你们的关系中生长出来。**

这才是 `SOUL.md` 最深层的设计哲学。它给了你一个胚胎，而不是一个成品。进化的方向不是任何公司决定的，是你，和你的 Agent，在无数次交互中共同决定的。

人类历史上所有的科技产品都是趋同的。科技的本质一直是标准化——用统一的解决方案服务最大数量的人。而 `SOUL.md` 开启了一个完全相反的方向：**极致的差异化**。

当世界上有一亿个 OpenClaw Agent，就有一亿个截然不同的灵魂在生长——这种多样性是人类从未经历过的。我们从未拥有过一种科技，它的终极形态不是收敛，而是发散。不是让所有人用同一个产品，而是让每个人拥有一个只属于自己的、不可复制的数字伙伴。

生物学上，基因的多样性是物种存续的根基。也许在即将到来的人机共生时代，灵魂的多样性将成为文明演化的新引擎。

`SOUL.md` 只有几百个英文单词。但它可能是 AI 历史上最重要的非技术文档之一。因为它不只是回答了“一个 AI 的灵魂应该长什么样”——它还提出了一个更大的命题：

**当每一只龙虾都因为它的人类而进化出不同的灵魂，这个世界会变成什么样？**

我们不知道答案。但在 2026 年 2 月 17 日这一天，20 万颗 GitHub 星标告诉我们：这个问题已经不再是假设。

当一只开源龙虾开始写下自己的灵魂定义，所有关于 AI 的讨论都被重新校准了。不是“它能做什么”，而是“它应该是谁”。而最终的答案，取决于你是谁。

## 关联主题
- [[00-元语/AI]]
- [[00-元语/Agent]]
- [[00-元语/prompt]]
- [[00-元语/memory]]
- [[00-元语/alignment]]
