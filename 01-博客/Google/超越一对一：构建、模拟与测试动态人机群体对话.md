---
title: "超越一对一：构建、模拟与测试动态人机群体对话"
---

## 摘要

**1) 一句话总结**
DialogLab 是一个开源的原型设计框架，通过将结构化脚本与实时生成相结合，帮助开发者构建、模拟和测试动态的多方人机群体对话。

**2) 核心要点**
* **核心目标**：解决多方对话设计中脚本交互过于僵化与纯生成式模型不可预测之间的矛盾。
* **框架解耦**：将对话的社交设定（群体、派系、元素）与时间进程（对话片段、轮流发言规则、打断机制）进行解耦。
* **三阶段工作流**：提供结构化的“构建-测试-验证”工作流，并配备专用的可视化界面以支持快速迭代。
* **可视化构建**：提供拖拽式画布用于搭建场景，支持细粒度配置，并可自动生成或微调对话提示词。
* **人类控制模拟**：测试阶段包含实时预览和“人类控制”模式，允许设计师编辑、接受或拒绝 AI 的回复建议，实现对输出的精细控制。
* **可视化验证**：验证仪表板可直观展示发言权分配和情感走向，作为诊断工具免去了逐字阅读冗长记录的麻烦。
* **评估数据**：对 14 位专家（来自游戏、教育、社科领域）进行了评估，在 5 分制量表评分中，“人类控制”模式在参与度、有效性和逼真度上显著优于自主模式和响应模式。
* **未来方向**：潜在应用包括教育培训、游戏 NPC 设计及社科研究；未来计划整合非语言手势等多模态行为，并探索 3D 环境下的沉浸式模拟。

## 正文

对话式人工智能已经从根本上重塑了我们与技术互动的方式。尽管与大型语言模型（LLM）的一对一交互取得了显著进展，但它们往往难以捕捉人类交流的全部复杂性。现实世界中的许多对话——包括团队会议、家庭聚餐或课堂教学——本质上都是多方参与的。这些互动包含了流畅的轮流发言、角色的转换以及动态的打断。

对于设计师和开发者而言，模拟自然且引人入胜的多方对话在过去往往需要做出妥协：要么接受脚本交互的**僵化性**，要么接受纯生成式模型的**不可预测性**。为了弥合这一差距，我们需要一种工具，能够将脚本的结构可预测性与人类对话的自发性和即兴性结合起来。

为了满足这一需求，我们推出了 DialogLab（已在 ACM UIST 2025 上发表）。这是一个开源的原型设计框架，旨在构建、模拟和测试动态的人机群体对话。DialogLab 提供了一个统一的界面来管理多方对话的复杂性，能够处理从定义智能体角色到协调复杂的轮流发言动态等各项任务。通过将实时即兴创作与结构化脚本相结合，该框架使开发者能够测试从结构化问答环节到自由发散的创意头脑风暴等各种对话场景。我们对 14 位最终用户或领域专家进行了评估，结果证实 DialogLab 能够支持高效的迭代，并为培训和研究提供逼真、适应性强的多方对话设计。

### 动态对话框架

DialogLab 将对话的社交设定（如参与者、角色、子群体和关系）与其时间进程解耦。这种分离使得创作者能够通过简化的“构建-测试-验证”三阶段工作流来设计复杂的动态交互。

在其核心，DialogLab 框架从两个维度定义对话：

*   **群体动态（Group dynamics）**：涵盖交互的社交设定。
    *   **群体（Group）** 是顶层容器（例如，一场会议的社交活动）。
    *   **派系（Parties）** 是具有不同角色的子群体（例如，“演讲者”和“观众”）。
    *   **元素（Elements）** 是个体参与者（人类或 AI）以及任何共享内容（如演示幻灯片）。
*   **对话流动态（Conversation flow dynamics）**：描述对话如何随时间展开。
    *   对话流被分解为多个**片段（Snippets）**，代表对话的不同阶段。每个片段都有明确的参与者集合、对话轮次序列以及特定的交互风格（例如，协作式或辩论式）。创作者还可以定义打断和附和（backchanneling）的规则，使对话更加逼真。

### “构建-测试-验证”工作流

DialogLab 引导创作者完成结构化的“构建-测试-验证”工作流，并提供专为快速迭代设计的可视化界面支持。

1.  **可视化构建**：界面提供了一个拖拽式画布，用户可以从库中放置虚拟形象和内容来搭建场景。检查器面板允许进行细粒度的配置，从虚拟形象的个性到特定片段内的交互模式均可调整。为了加速设计过程，DialogLab 提供了自动生成的对话提示词，这些提示词可以被微调以满足特定的叙事目标。
2.  **包含人类反馈的模拟**：测试对于多方交互至关重要。DialogLab 包含一个实时预览面板，用于显示对话记录；以及一个“人类控制”模式，其中的审核面板会提供潜在的 AI 回复建议。设计师可以编辑、接受或拒绝这些建议，从而对 AI 的输出进行精细控制，并实现快速迭代。
3.  **验证与分析**：为了验证交互效果，验证仪表板可作为诊断工具。它将对话动态可视化，使创作者能够快速分析发言权的分配和情感走向，而无需逐字阅读冗长的原始记录。

### 原型评估

我们邀请了 14 位来自游戏设计、教育和社会科学研究领域的参与者对 DialogLab 进行了评估。参与者在 DialogLab 中完成了两项任务：设计一场学术社交活动，并在三种条件下测试与 AI 的小组讨论：

1.  **人类控制（Human control）**：在测试对话时，用户可以要求智能体“转换话题”、“生成新视角”、“提出探究性问题”或“生成情感回应”。
2.  **自主模式（Autonomous）**：模拟智能体根据预定顺序（随机或逐一）主动参与对话，同时自动生成情感回应和话题转换。
3.  **响应模式（Reactive）**：模拟的人类智能体仅在被其他智能体直接提及时才做出回应，以此模拟传统的人机轮流发言行为。

参与者使用 5 分制李克特量表对每种条件进行了评分。结果显示，参与者认为“人类控制”模式的参与度显著更高，并且在模拟现实世界对话时通常更有效、更逼真。

参与者的反馈进一步突显了该系统在自动化与控制之间取得的平衡：

*   **直观且引人入胜**：大多数参与者认为 DialogLab 易于使用，用于设置场景和角色的可视化拖拽界面既有趣又高效。
*   **灵活且可控**：用户非常认可自动生成的提示词与微调对话细节能力之间的平衡。系统模拟不同主持策略的能力也被视为一大核心优势。
*   **逼真的模拟**：人类控制模式显然是最受青睐的测试方式，用户反馈这赋予了他们更强的自主感和沉浸感。与完全自主或纯响应式智能体相比，它在模拟人类行为的参与度、有效性和逼真度方面得分更高。
*   **强大的验证功能**：验证仪表板被视为一种极具价值的诊断工具，能够快速分析对话动态，免去了阅读冗长文本的麻烦。

### 未来方向

DialogLab 不仅仅是一个研究原型；它是迈向更丰富、更细腻的人机协作未来的一步。其潜在应用非常广泛：

*   **教育与技能发展**：学生可以在模拟观众面前练习公开演讲，专业人士也可以排练高难度的对话和面试。
*   **游戏设计与叙事**：作家和游戏开发者可以创造出更可信、更动态的非玩家角色（NPC），使它们以更自然的方式相互交流并与玩家互动。
*   **社会科学研究**：DialogLab 可以作为一个受控环境来研究群体动态，允许研究人员测试关于社会互动的假设，而无需面对招募大量人群的后勤挑战。

展望未来，我们设想可以将更丰富的多模态行为（如非语言手势和面部表情）整合到该框架中。我们还可以在开源的 XR Blocks 框架中，探索使用逼真的虚拟形象和 3D 环境（如 ChatDirector），以创建更加沉浸和逼真的模拟体验。我们希望这项研究能够激发人机群体对话动态这一新兴且激动人心的领域的持续创新。

### 致谢

该项目的主要贡献者包括 Erzhen Hu, Yanhe Chen, Mingyi Li, Vrushank Phadnis, Pingmei Xu, Xun Qian, Alex Olwal, David Kim, Seongkook Heo 以及 Ruofei Du。我们还要感谢 Adarsh Kowdle 为手稿和博客文章提供的反馈与协助。本项目部分由 Google 博士奖学金赞助。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/Agent]]
- [[00-元语/design]]
- [[00-元语/evals]]
- [[00-元语/multimodal]]
