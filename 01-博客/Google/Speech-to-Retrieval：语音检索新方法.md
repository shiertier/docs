# Speech-to-Retrieval：语音检索新方法

## 文档信息

- 发布日期：2025-10-07
- 原文链接：https://research.google/blog/speech-to-retrieval-s2r-a-new-approach-to-voice-search/

## 摘要

**1) 一句话摘要**
Google 推出了一种名为语音到检索（S2R）的新型语音搜索技术，该技术通过双编码器架构将语音直接映射为检索意图，绕过了传统的文本转录步骤，从而显著提升了多语言语音搜索的准确性并已投入实际应用。

**2) 关键要点**
*   **传统级联模型的缺陷**：现有的语音搜索通常先通过自动语音识别（ASR）将语音转为文本再进行搜索，这种方法容易丢失上下文线索，且微小的识别错误（如将“scream”错认为“screen”）会导致错误传播，返回无关结果。
*   **S2R 的核心理念**：S2R 绕过了创建文本转录这一中间步骤，直接从音频中理解并检索信息，将重点从“说了什么词”转变为“在寻找什么信息”。
*   **双编码器架构**：系统由音频编码器和文档编码器组成。音频编码器将原始音频转化为捕获语义的向量（音频嵌入），文档编码器则将文档转化为类似的向量。
*   **模型训练方式**：使用大型配对数据集进行训练，确保匹配的音频查询向量与文档向量在表示空间中保持几何上的接近。
*   **搜索排名机制**：S2R 生成初始的高相似度候选结果后，搜索排名系统会结合数百个其他信号进行评估，在几分之一秒内完成最终排序。
*   **显著的性能提升**：评估显示，S2R 的性能显著优于传统的基线级联 ASR 模型，并逼近拥有完美转录文本的“级联真实值”模型的理论上限。
*   **开源 SVQ 数据集**：Google 开源了简单语音问题（SVQ）数据集，包含 17 种语言和 26 个地区的简短音频问题，作为大规模声音嵌入基准（MSEB）的一部分供社区使用。
*   **已投入生产环境**：S2R 已不再是理论模型，目前正以多种语言在 Google 搜索的实际产品中为用户提供服务。

**3) 风险与差距**
*   **未达到理论上限**：尽管 S2R 表现出色，但其性能与完美语音识别（级联真实值模型）所建立的上限之间仍存在剩余差距，表明还需要进一步的研究。
*   **评估指标的局限性**：实验表明，较低的词错误率（WER）并不一定能在不同语言中可靠地带来较高的平均倒数排名（MRR），传统的 WER 指标无法完全捕捉转录错误对下游搜索任务的复杂影响。

## 正文

基于语音的网络搜索已经存在了很长时间，并继续被许多人使用，其底层技术也在快速发展，以支持更多的用例。Google 最初的语音搜索解决方案使用[自动语音识别](https://en.wikipedia.org/wiki/Speech_recognition) (ASR) 将语音输入转换为文本查询，然后搜索与该文本查询匹配的文档。然而，这种[级联建模方法](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/36340.pdf)面临的一个挑战是，语音识别阶段的任何微小错误都可能显著改变查询的含义，从而产生错误的结果。

例如，假设有人通过语音网络搜索爱德华·蒙克 (Edvard Munch) 的名画[《呐喊》(The Scream)](https://en.wikipedia.org/wiki/The_Scream)。搜索引擎使用典型的级联建模方法，首先通过 ASR 将语音查询转换为文本，然后再将文本传递给搜索系统。理想情况下，ASR 能够完美地转录查询。然后，搜索系统接收到正确的文本——“the Scream painting（呐喊画作）”——并提供相关的结果，如这幅画的历史、含义以及展出地点。但是，如果 ASR 系统将“scream”中的“m”错认成了“n”会怎样？它会将查询误解为“screen painting（丝网印刷/屏风画）”，并返回关于丝网印刷技术的无关结果，而不是关于蒙克杰作的详细信息。

为了防止网络搜索系统中出现此类错误，如果系统能够直接将语音映射到所需的检索意图，完全绕过文本转录过程，结果会怎样呢？

语音到检索 (Speech-to-Retrieval, S2R) 应运而生。S2R 的核心是一项直接从语音查询中解释和检索信息的技术，无需经过创建完美文本转录这一可能存在缺陷的中间步骤。它代表了机器处理人类语音方式在架构和理念上的根本性转变。当今常见的语音搜索技术主要关注“说了什么词？”这个问题，而 S2R 旨在回答一个更强大的问题：“正在寻找什么信息？”本文探讨了当前语音搜索体验中存在的巨大质量差距，并展示了 S2R 模型将如何填补这一差距。此外，我们正在开源[简单语音问题](https://huggingface.co/datasets/google/svq#:~:text=Simple%20Voice%20Questions%20(SVQ)%20is,languages%20under%20multiple%20audio%20conditions.) (Simple Voice Questions, SVQ) 数据集，这是一个包含在 17 种不同语言和 26 个地区录制的简短音频问题集合，我们使用它来评估 S2R 的性能潜力。SVQ 数据集是新的[大规模声音嵌入基准](https://github.com/google-research/mseb) (Massive Sound Embedding Benchmark) 的一部分。

评估 S2R 的潜力
-------------------------------

当传统的 ASR 系统将音频转换为单一文本字符串时，它可能会丢失有助于消除歧义的上下文线索（即信息丢失）。如果系统在早期误解了音频，该错误就会传递给搜索引擎，而搜索引擎通常缺乏纠正它的能力（即错误传播）。因此，最终的搜索结果可能无法反映用户的意图。

为了调查这种关系，我们进行了一项旨在模拟理想 ASR 性能的实验。我们首先收集了一组具有代表性的测试查询，这些查询反映了典型的语音搜索流量。关键是，这些查询随后由人类标注员手动转录，从而有效地创建了一个“完美 ASR”场景，其中转录文本是绝对的真实值 (ground truth)。

然后，我们建立了两个不同的搜索系统进行比较（见下图）：

*   **级联 ASR (Cascade ASR)** 代表了典型的真实世界设置，其中语音由自动语音识别 (ASR) 系统转换为文本，然后将该文本输入到检索系统中。
*   **级联真实值 (Cascade groundtruth)** 通过将完美无瑕的真实文本直接发送到同一个检索系统，模拟了一个“完美”的级联模型。

然后，将来自这两个系统（级联 ASR 和级联真实值）的检索文档与原始的真实查询一起呈现给人类评估员（或称“评分员”）。评估员的任务是比较两个系统的搜索结果，对它们各自的质量提供主观评估。

我们使用[词错误率](https://en.wikipedia.org/wiki/Word_error_rate) (WER) 来衡量 ASR 质量，并使用[平均倒数排名](https://en.wikipedia.org/wiki/Mean_reciprocal_rank) (MRR) 来衡量搜索性能——这是一种统计指标，用于评估任何为样本查询生成可能响应列表的过程，这些响应按正确概率排序，其计算方式为所有查询中第一个正确答案排名的倒数的平均值。真实世界系统与真实值系统之间在 MRR 和 WER 上的差异，揭示了 SVQ 数据集中[一些最常用的语音搜索语言](https://vocal.media/education/the-rise-of-voice-search-and-its-impact-on-indian-businesses)的潜在性能提升（如下所示）。

这项比较的结果得出了两个关键的观察结论。首先，通过比较上面的两张图表可以看出，我们发现较低的 WER 并不一定能在不同语言中可靠地带来较高的 MRR。这种关系很复杂，表明转录错误对下游任务的影响并未被 WER 指标完全捕捉到。错误的具体性质（而不仅仅是它的存在）似乎是一个关键的、与语言相关的因素。其次，更重要的是，在所有测试的语言中，两个系统之间存在显著的 MRR 差异。这揭示了当前的级联设计与完美语音识别在理论上可能达到的水平之间存在巨大的性能差距。这一差距清楚地表明了 S2R 模型在从根本上提高语音搜索质量方面的潜力。

S2R 的架构：从声音到意义
----------------------------------------------

我们 S2R 模型的核心是双编码器架构。该设计包含两个专门的神经网络，它们从海量数据中学习，以理解语音和信息之间的关系。音频编码器处理查询的原始音频，将其转换为捕获其语义的丰富向量表示。与此同时，文档编码器学习文档的类似向量表示。

该模型的关键在于它的训练方式。使用包含成对音频查询和相关文档的大型数据集，系统学习同时调整两个编码器的参数。

训练目标确保音频查询的向量在表示空间中与其对应文档的向量在几何上保持接近。这种架构允许模型直接从音频中学习更接近检索所需的基本*意图*，绕过了转录每个单词这一脆弱的中间步骤，而这正是级联设计的主要弱点。

S2R 模型的工作原理
-----------------------

当用户说出一个查询时，音频会被流式传输到预训练的音频编码器，该编码器会生成一个查询向量。然后，通过复杂的搜索排名过程，该向量被用于从我们的索引中高效地识别出一组高度相关的候选结果。

上面的动画演示了 S2R 如何理解和回答语音查询。它从用户语音请求“The Scream painting（呐喊画作）”开始。音频编码器将声音转化为丰富的[音频嵌入](https://dev.to/josethz00/audio-embeddings-understanding-the-basics-4pc1)，这是一个代表查询深层含义的向量。然后，该嵌入被用于扫描海量的文档索引，浮现出具有高相似度分数的初始候选结果，例如《呐喊》的维基百科页面 (0.8) 和蒙克博物馆网站 (0.7)。

但找到相关文档仅仅是个开始。关键的最后一步由搜索排名系统来精心策划。这种强大的智能远超初始分数，它将这些分数与数百个其他信号交织在一起，以深入理解相关性和质量。它在几分之一秒内权衡所有这些信息，编排最终的排名，确保向用户呈现最有用和最值得信赖的信息。

评估 S2R
--------------

我们在 SVQ 数据集上评估了上述 S2R 系统：

S2R 模型的性能（橙色条）显示了两个关键结果：

*   它显著优于基线级联 ASR 模型。
*   它的性能接近由级联真实值模型建立的上限。

尽管前景广阔，但剩余的差距表明还需要进一步的研究。

语音搜索的新时代现已开启
----------------------------------------

转向由 S2R 驱动的语音搜索并非理论演习；它已成为现实。在 Google Research 和 Search 团队的密切合作下，这些先进的模型现在正以多种语言为用户提供服务，实现了超越传统级联系统的准确性飞跃。

为了帮助推动整个领域的发展，我们还开源了 [SVQ 数据集](https://huggingface.co/datasets/google/svq)，作为[大规模声音嵌入基准](https://github.com/google-research/mseb) (MSEB) 的一部分。我们相信，共享资源和透明的评估能够加速进步。本着这种精神，我们邀请全球研究社区使用这些数据，在公共基准上测试新方法，并加入到构建下一代真正智能的语音界面的努力中来。

致谢
----------------

_作者衷心感谢所有为本项目做出贡献的人，是他们的关键投入使之成为可能。我们特别感谢我们的同事 Hawi Abraham、Cyril Allauzen、Tom Bagby、Karthik Kumar Bandi、Stefan Buettcher、Dave Dopson、Lucy Hadden、Georg Heigold、Sanjit Jhala、Shankar Kumar、Ji Ma、Eyal Mizrachi、Pandu Nayak、Pew Putthividhya、David Rybach、Jungshik Shin、Venkat Subramanian、Sundeep Tirumalareddy 和 Trystan Upstill。我们还要感谢那些帮助准备这篇文章的人：感谢 Mark Simborg 的大量编辑工作，感谢 Kimberly Schwede 提供的精美插图，以及感谢 Mickey Wurts 提供的宝贵协助。_

## 关联主题

- [[00-元语/AI]]
- [[00-元语/asr]]
- [[00-元语/audio]]
- [[00-元语/multimodal]]
- [[00-元语/benchmark]]
- [[00-元语/evals]]
