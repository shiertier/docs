---
title: "鸟类数据训练的AI如何揭开水下世界的神秘面纱"
---

## 摘要

### 一句话总结
Google DeepMind 于2025年8月发布的生物声学基础模型 Perch 2.0，尽管仅基于鸟类等陆地动物数据训练，却通过迁移学习在水下声音分类（如鲸鱼发声）任务中展现出了卓越的性能。

### 关键点
*   **模型发布与训练数据**：2025年8月发布的 Perch 2.0 模型主要基于鸟类和其他陆地发声动物的数据进行训练，训练集中完全不包含水下音频。
*   **技术路径（迁移学习）**：利用 Perch 2.0 将庞大的音频数据压缩为“嵌入向量（embeddings）”，并将其作为简单逻辑回归分类器的输入特征，从而免去了从头训练深度神经网络的庞大计算量和时间。
*   **评估数据集**：模型在三个水下数据集上进行了少样本线性探测评估：NOAA PIPAN（须鲸物种）、ReefSet（珊瑚礁及人为噪音）和 DCLDE（虎鲸亚群及座头鲸）。
*   **性能表现**：在不同数据集和样本规模（每类4至32个样本）下，Perch 2.0 的 AUC_ROC 表现始终位居第一或第二，在多数水下任务中优于 AVES-bird、AVES-bio 等对比模型。
*   **特征分离能力**：tSNE 可视化结果显示，相较于其他模型，Perch 2.0 能够为高度相似的水下声音（如北部居留型、过客型和近海虎鲸）生成边界更清晰的聚类。
*   **跨域有效性归因**：论文将模型在水下任务中的成功归结为三点：大规模模型的泛化能力、区分相似鸟鸣迫使模型学习到的精细声学特征（“麻鳽教训”），以及鸟类与海洋哺乳动物发声机制的进化相似性。
*   **工程应用与开源**：该敏捷建模方法允许在几小时内利用少量样本创建自定义分类器；Google 已更新端到端教程，支持使用 Google Cloud 和 Perch Hoplite 数据库处理 NOAA 数据集。

### 风险与不足
*   **数据标签不确定性**：在用于评估的 DCLDE 数据集中，关于区分虎鲸、座头鲸、非生物声音和未知水下声音的标签存在一定的不确定性。

## 正文

水下声音对于理解海洋物种及其环境中那些肉眼无法观察到的规律至关重要。海洋的声景中充满了神秘的噪音和未知的发现。例如，美国国家海洋和大气管理局（NOAA）最近将神秘的“biotwang”声音归因于难以捉摸的布氏鲸，这说明了科学家们在不断识别新叫声类型和物种归属时所面临的持续挑战。

Google 在利用生物声学监测和保护鲸鱼方面，有着与外部科学家合作的悠久历史。这包括我们最初用于检测座头鲸分类的研究模型，以及 2024 年发布的多物种鲸鱼模型。为了跟上新发现的步伐，Google 在生物声学领域的 AI 方法正在不断演进，旨在更高效地将新发现转化为大规模的科学洞察。

2025年8月，Google DeepMind 发布了最新的生物声学基础模型 Perch 2.0。该模型主要基于鸟类和其他陆地发声动物的数据进行训练。令人惊讶的是，尽管训练数据中完全没有包含水下音频，Perch 2.0 在海洋验证任务中作为迁移学习的嵌入模型时，依然表现出了极佳的性能。

在 Google Research 和 Google DeepMind 合作并发表于 NeurIPS 2025 “非人类动物交流中的 AI” 研讨会上的最新论文《Perch 2.0 将“鲸鱼”迁移至水下任务》中，我们对这些结果进行了深入探讨。我们展示了这种主要在鸟类数据上训练的生物声学基础模型，如何被用于实现和扩展对水下海洋生态系统的洞察，特别是在鲸鱼发声分类方面。

### 生物声学分类的工作原理

如果一个预训练的分类模型（例如我们的多物种鲸鱼模型）已经具备必要的标签，并且在研究人员的数据集上表现良好，那么它可以直接用于为音频数据生成评分和标签。然而，如果要为新发现的声音创建自定义分类器，或提高在新数据上的准确性，我们可以利用**迁移学习**，而不是从头开始构建新模型。这种方法大幅减少了创建新自定义分类器所需的计算量和实验时间。

在生物声学迁移学习中，预训练模型（如 Perch 2.0）被用来为每个音频窗口生成“嵌入向量（embeddings）”。这些嵌入向量将庞大的音频数据压缩成一个小得多的特征数组，作为简单分类器的输入。

为了针对任何带有标签的音频数据集创建新的自定义模型，我们将预训练模型应用于音频数据以获取嵌入向量，然后将这些向量作为逻辑回归分类器的输入特征。这样一来，我们不再需要学习深度神经网络的所有参数，而只需学习最后一步逻辑回归的新参数。这对于研究人员的时间和计算资源来说都高效得多。

### 模型评估与数据集

我们使用少样本线性探测（few-shot linear probe）在海洋任务上对 Perch 2.0 进行了评估，例如区分不同的须鲸物种或不同的虎鲸亚群。我们将其性能与支持敏捷建模和迁移学习的预训练模型进行了对比，包括 Perch 2.0、Perch 1.0、SurfPerch 以及多物种鲸鱼模型。

对于水下数据的评估，我们使用了三个数据集：

*   **NOAA PIPAN**：来自 NOAA 太平洋岛屿渔业科学中心录音的被动声学数据档案的标注子集。它包含了我们早期鲸鱼模型中使用的标签，以及针对须鲸物种（如普通小须鲸、座头鲸、塞鲸、蓝鲸、长须鲸和布氏鲸）的新标注。
*   **ReefSet**：为 SurfPerch 模型训练而开发，利用了 Google 艺术与文化项目“呼唤我们的珊瑚”中的数据标注。它包含生物礁石噪音（如呱呱声、噼啪声、咆哮声）、特定物种/属类（如雀鲷、海豚和石斑鱼），以及人为噪音和海浪声。
*   **DCLDE**：该数据集使用三种不同的标签集进行评估：
    *   *物种*：用于区分虎鲸、座头鲸、非生物声音和未知水下声音（虎鲸和座头鲸的标签存在一定的不确定性）。
    *   *已知生物物种*：用于虎鲸和座头鲸的确定标签。
    *   *生态型*：用于区分虎鲸亚群（生态型），包括过客型/比格斯虎鲸、北部居留型、南部居留型、阿拉斯加东南部虎鲸和近海虎鲸。

在评估协议中，对于给定的目标标记数据集，我们计算每个候选模型的嵌入向量。然后，我们为每个类别选择固定数量的样本（4、8、16 或 32 个），并在嵌入向量之上训练一个简单的多类逻辑回归模型。我们使用生成的分类器计算接收者操作特征曲线下面积（AUC_ROC），该值越接近 1，表明区分不同类别的能力越强。

结果表明，除了 ReefSet 数据（在该数据集中，即使每个类别只有 4 个样本，除多物种鲸鱼模型外的所有模型表现都很高）之外，每个类别增加更多样本都能提高所有模型的性能。值得注意的是，在每个数据集和样本规模下，Perch 2.0 始终是表现最好或第二好的模型。

我们还将 Perch 2.0 与 AVES-bird、AVES-bio（地球物种项目训练的 Transformer 生物声学模型）以及康奈尔大学鸟类学实验室的 BirdNet v2.3 进行了对比。Perch 2.0 在大多数水下任务中优于 AVES-bird 和 AVES-bio。

### 为什么 Perch 2.0 在水下任务中表现如此出色？

对于这个主要在鸟类数据上训练的模型为何能在水下声音中表现出如此好的迁移性能，我们提出了几个可能的原因：

1.  **大规模模型的泛化能力**：先前的研究表明，拥有海量训练数据的更大模型具有更好的泛化能力，这使得我们的生物声学模型即使在对训练数据集中未包含的物种和声音进行分类的下游任务中也能表现良好。
2.  **“麻鳽教训”（The bittern lesson）**：对极其相似的鸟鸣进行分类的挑战，迫使模型学习非常详细的声学特征，这些特征随后可用于其他生物声学任务。例如，北美有 14 种鸽子，每种都有微妙不同的“咕咕”声。一个能够提取特征以区分每种特定“咕咕”声的模型，很可能也会分离出有助于区分其他声音类别的特征。
3.  **发声机制的进化相似性**：不同类型物种之间的特征迁移也可能与发声机制本身有关。许多物种（包括鸟类和海洋哺乳动物）在进化过程中形成了相似的发声方式。

一个高性能的模型会为其应用的目标类别生成信息丰富且线性可分的嵌入向量。通过 tSNE 可视化技术（不同颜色代表不同类别），我们可以看到：信息丰富的模型会为每个类别显示出清晰的聚类，而在信息较少的模型中，类别会交织在一起。

虽然几乎所有模型都为南部居留型虎鲸和阿拉斯加南部居留型虎鲸显示出了一些明显的聚类，但在 AVES-bio、AVES-bird 和 SurfPerch 等模型中，北部居留型、过客型和近海虎鲸的声音嵌入向量是混合在一起的；而在 BirdNet v2.3 和 Perch 2.0 中，这些类别被区分得更加清晰。

### 展望与未来

Google DeepMind 的 Perch 团队与 Google Research 及外部合作伙伴合作，开创了一种用于生物声学的敏捷建模方法，能够在几个小时内利用少量标记样本创建自定义分类器。

为了支持 Google Research 的合作伙伴以及更广泛的鲸类声学社区，我们创建了一个端到端的演示教程，展示如何处理托管在 Google Cloud 上的 NOAA 被动声学档案数据集，并使用更高效的 Perch Hoplite 数据库来管理嵌入向量，从而更新了我们之前的教程。

### 致谢

开发 Perch 2.0 模型的 Perch 团队隶属于 Google DeepMind，成员包括 Tom Denton、Bart van Merriënboer、Vincent Dumoulin、Jenny Hamer、Isabelle Simpson、Andrea Burns 以及 Lauren Harrell（Google Research）。特别感谢 Ann Allen（NOAA 太平洋岛屿渔业中心）和 Megan Wood（支持 NOAA 的 Saltwater Inc.）为 NOAA PIPAN 数据集提供了额外的标注，以及 Dan Morris（Google Research）和 Matt Harvey（Google DeepMind）的支持。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/audio]]
- [[00-元语/benchmark]]
- [[00-元语/evals]]
