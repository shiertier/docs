---
title: "D4RT：教人工智能在四维空间中观察世界"
---

## 摘要

**1) 一句话总结**
D4RT（动态四维重建与追踪）是一个基于统一Transformer架构的AI模型，它通过高效的并行查询机制将2D视频转化为动态的4D空间表征，处理速度比传统方法快18至300倍，为机器人和增强现实等实时应用提供了强大的空间感知能力。

**2) 关键要点**
*   **统一架构：** D4RT采用统一的编码器-解码器Transformer架构，摒弃了传统方法中拼凑多个专用模型（深度、运动、摄像机角度）的碎片化流程。
*   **查询机制：** 模型通过轻量级解码器并行处理独立查询，直接计算“特定像素在任意时间点位于3D空间中的位置”，从而在单一接口下解决多种任务。
*   **核心能力：** 支持三大4D任务：点追踪（即使物体被遮挡也能预测轨迹）、点云重建（无需单独的摄像机估计或逐视频迭代优化）以及摄像机姿态估计。
*   **极速处理：** 运行速度比以往最先进方法快18到300倍；在单个TPU芯片上处理1分钟视频仅需约5秒（效率提升120倍）。
*   **应对复杂动态：** 在MPI Sintel基准测试中，能够高保真地准确重建包含快速运动模糊和非刚性变形的复杂场景。
*   **处理真实遮挡：** 在Aria Digital Twin数据集测试中，D4RT在真实的家庭环境中展现出顶级的3D点追踪性能，能有效处理复杂的自身运动和遮挡。
*   **稳定几何锁定：** 在RE10k数据集的摄像机姿态估计评估中获得最高AUC分数，无需昂贵的测试时优化即可锁定稳定的几何结构。
*   **应用前景：** 其高效性与准确性适用于机器人安全导航与操作、AR眼镜的低延迟端侧部署，并为构建通向AGI的物理现实“世界模型”提供了基础。

## 正文

人类在观察世界时，能够轻松进行记忆和预测。我们不仅能理解事物当下的状态，还能知晓它们过去的模样，并预判它们未来的走向。我们在大脑中建立了一个持久的现实表征模型，并利用这个模型直观地推断出过去、现在和未来之间的因果关系。

为了让机器能像人类一样观察世界，仅仅为它们配备摄像头是不够的，这只解决了输入的问题。要真正理解这些输入，计算机必须解决一个复杂的逆向问题：将由平面2D投影组成的视频序列，还原并理解为丰富的、动态的3D体积世界。

为此，我们推出了 **D4RT（动态四维重建与追踪，Dynamic 4D Reconstruction and Tracking）**。这是一个全新的统一AI模型，它将动态场景重建整合到了一个高效的框架中，引领我们迈向人工智能的下一个前沿：对动态现实的全面感知。

### 第四维度的挑战

要理解2D视频捕捉到的动态场景，AI模型必须追踪每个物体中每个像素在三维空间以及第四维（时间）中的运动轨迹。此外，它还必须将物体的运动与摄像机的运动区分开来，即使物体相互遮挡或完全离开画面，也要保持连贯的表征。

传统上，从2D视频中获取这种级别的几何和运动信息需要计算密集型的过程，或者拼凑多个专门的AI模型（分别用于深度、运动或摄像机角度），这导致AI的重建过程既缓慢又碎片化。

D4RT 凭借其简化的架构和新颖的查询机制，站在了4D重建的最前沿。它的效率比以往的方法高出多达300倍，足以满足机器人、增强现实（AR）等领域的实时应用需求。

### D4RT 的工作原理：基于查询的方法

D4RT 采用统一的编码器-解码器 Transformer 架构。

首先，编码器将输入视频处理为场景几何和运动的压缩表征。与过去为不同任务使用独立模块的系统不同，D4RT 仅通过一个灵活的查询机制来计算所需内容，该机制围绕一个核心问题展开：

**“从选定的摄像机视角来看，视频中的特定像素在任意时间点位于3D空间中的什么位置？”**

基于我们之前的研究，一个轻量级的解码器随后会查询这一表征，以回答上述问题的具体实例。由于各个查询是独立的，它们可以在现代AI硬件上并行处理。这使得 D4RT 极其快速且具有高度可扩展性，无论是追踪几个点还是重建整个场景都能轻松应对。

简而言之，D4RT 结合了强大的编码器（用于建立对视频丰富的全局理解）和轻量级的解码器（用于并行回答数千个查询）。通过提出具体问题，该模型通过单一、灵活的接口高效地解决了追踪、深度估计和姿态估计等多种任务。

### 核心能力：快速准确的四维理解

借助这种灵活的公式化设计，该模型现在可以解决各种4D任务，包括：

*   **点追踪（Point Tracking）：** 通过查询像素在不同时间步的位置，D4RT 可以预测其3D轨迹。重要的是，即使物体在视频的其他帧中不可见，模型也能进行预测。
*   **点云重建（Point Cloud Reconstruction）：** 通过冻结时间和摄像机视角，D4RT 可以直接生成场景的完整3D结构，从而省去了单独的摄像机估计或逐视频迭代优化等额外步骤。
*   **摄像机姿态估计（Camera Pose Estimation）：** 通过生成并对齐同一时刻不同视角的3D快照，D4RT 可以轻松恢复摄像机的运动轨迹。

在各种4D重建任务中，D4RT 均优于以往的方法。定性比较表明，当其他方法在处理动态物体陷入困境（经常出现物体重复或完全无法重建）时，D4RT 能够对运动世界保持稳定、连续的理解。

关键在于，D4RT 的高精度并没有以牺牲效率为代价。在测试中，它的运行速度比之前的最先进方法快18到300倍。例如，D4RT 在单个 TPU 芯片上处理一分钟的视频大约只需5秒钟，而以往的最先进方法完成相同任务可能需要长达10分钟——实现了120倍的效率提升。

*   **应对复杂动态场景：** 在包含快速运动模糊和非刚性变形的复杂合成场景（MPI Sintel 基准测试）中，D4RT 展现出优于近期强大基准模型的保真度，证明了其在物体或摄像机快速移动时准确重建几何结构的能力。
*   **处理真实环境遮挡：** 在使用 Aria Digital Twin 数据集的智能眼镜画面进行测试时，D4RT 在3D点追踪方面达到了顶级性能，验证了其在真实的家庭环境中处理复杂自身运动（ego-motion）和遮挡的鲁棒性。
*   **锁定稳定几何结构：** 在评估 RE10k 数据集中各种室内外场景的摄像机姿态估计时，D4RT 获得了最高的 AUC 分数。这表明该模型能够锁定稳定的几何结构，而无需进行昂贵的测试时优化。

### 下游应用前景

D4RT 证明了我们在4D重建中无需在准确性和效率之间做出妥协。其灵活的、基于查询的系统可以实时捕捉我们的动态世界，为下一代空间计算铺平了道路。这包括：

*   **机器人技术（Robotics）：** 机器人需要在充满移动的人和物体的动态环境中导航。D4RT 可以提供安全导航和灵巧操作所需的空间感知能力。
*   **增强现实（AR）：** 为了将数字物体叠加到现实世界中，AR眼镜需要对场景几何结构有即时、低延迟的理解。D4RT 的高效性有助于让端侧部署成为现实。
*   **世界模型（World Models）：** 通过有效解耦摄像机运动、物体运动和静态几何结构，D4RT 让我们离拥有物理现实真正“世界模型”的AI更近了一步——这是通向通用人工智能（AGI）的必经之路。

我们将继续探索该模型在机器人、增强现实及更广泛领域的应用潜力和能力。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/video]]
- [[00-元语/benchmark]]
- [[00-元语/paper]]
