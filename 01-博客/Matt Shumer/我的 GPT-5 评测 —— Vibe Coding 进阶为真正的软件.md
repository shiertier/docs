# 我的 GPT-5 评测 —— Vibe Coding 进阶为真正的软件

## 文档信息
- 原文标题：My GPT-5 Review — Vibe Coding Graduates to Real Software
- 作者：Matt Shumer
- 发布日期：2025-08-07
- 原文链接：https://shumer.dev/gpt5review

## 摘要
### 一句话总结
GPT-5 凭借极快的响应速度、卓越的长上下文处理能力以及在全栈开发和机器学习任务中的高度自治性，实现了从“氛围编程（Vibe Coding）”到真正软件工程的跨越，大幅提升了开发效率。

### 关键要点
*   **开发效率实现飞跃**：将原本评估需要数周至数月才能完成的复杂全栈项目（包含复杂前端与 GPU 自动扩缩容后端），在1小时内成功构建出工作原型。
*   **前端生成接近人类水平**：生成的 UI 约 80% 难以与人类作品区分，能够快速且精准地克隆 Figma 设计图，对微交互和间距等细节处理极佳。
*   **强大的后端与 ML 自治能力**：仅需3轮提示即可完成 GPU 基础设施的自动化部署；在遇到过时的训练数据时，能自主查阅文档（如 TRL 库）并正确实现微调/强化学习代码。
*   **极快的响应速度**：大多数任务在几秒内返回结果，最长提示的响应极少超过一分钟，极大减少了开发者的上下文切换成本。
*   **卓越的长上下文处理**：在数十万 Token 的超长编码会话中，能持续保持对项目架构和文件组织的清晰理解，表现优于 Gemini 2.5 Pro。
*   **三种运行模式**：包含 Auto（默认，内置分类器）、Thinking（绕过分类器，专为复杂任务设计）以及 Pro（最高级模式，推测采用集成方法，作者暂未获准访问）。
*   **API 定价降低**：输入为 $1.25/百万 Token（提供 90% 的缓存折扣，利好长上下文查询），输出为 $10/百万 Token，整体成本低于 GPT-4o。

### 风险与不足
*   **提示词结构敏感**：在处理复杂提示词（如使用 RepoPrompt）时容易偏离指令，必须在提示词顶部明确重复关键指令才能解决。
*   **深度搜索能力不及 o3**：在显性搜索任务中容易过早停止挖掘（例如只查到城市而非具体城镇），不如 o3 坚持深入。
*   **情感与创意写作不及 GPT-4.5**：在处理复杂邮件、语气把控、幽默感和说服力等情感/敏感任务上，表现明显弱于 GPT-4.5。
*   **指令遵循存在瑕疵**：偶尔难以严格遵循指令，需要用户非常谨慎地措辞和构建提示词。
*   **对话结尾过度热情**：在简单查询后经常附加不必要的提问（如“需要我为您制定计划吗？”），对重度用户造成干扰。
*   **疑似“小模型”特征**：作者根据其极快的速度、在创意/情感任务上的弱点以及特定的失败模式推测，GPT-5 的实际参数规模可能远小于外界预期。

## 正文
太长不看 (TL;DR)
-----

*   显然，GPT-5 相比之前的模型实现了巨大飞跃。但你必须挑战它的极限，才能充分发挥它的潜力。
*   相比之前的模型，现在 Vibe Coding（直觉编程）能做到的上限已经大幅提高。
*   超越 o3 的智能，加上**_极快的速度_**……我的生产力达到了前所未有的高度。
*   出色的长上下文处理能力，在编码任务上具有令人难以置信的精确度。
*   极其注重细节：犯的低级错误比其他模型少得多。
*   模式：Auto（默认）、Thinking（用于复杂工作）、Pro（此处未评估）。
*   o3 更适合进行深度的专项研究；GPT-4.5 依然更擅长写作；指令敏感度（instruction sensitivity）是个小问题。
*   总结：目前综合表现最好的模型；行业标杆已被再次拉高。

我在 7 月 21 日获得了 GPT-5 的访问权限。

老实说，刚开始测试时，我并没有感到震撼。事实上，我甚至觉得有些失望，尤其是考虑到围绕它的种种炒作和极高的期望。

这个模型充其量给人的感觉就像是 GPT-4.2……速度更快，确实比 4.1 更敏锐，但算不上什么巨大的飞跃。我尝试将它用于我的日常工作（在我看来，这是评估任何新模型的最佳方式），虽然它很好地处理了我交代的任务，但我并没有发现它比 GPT-4.1、Claude 4 Opus 或我一直在使用的任何其他模型有极其显著的提升。

我不禁在想：*难道就这？*

我开始习惯于用 GPT-5 来处理我原本会用现有 LLM 处理的几乎所有事情，这种情况持续了大约一周。它比我之前的日常主力模型 Claude 4 Opus 更好吗？是的，毫无疑问，但也只是好了一点点。感觉就像是一个微小的、渐进式的改进。

但随后事情发生了意想不到的转折。Josh（我在 HyperWrite 的首席工程师）和我花了一个下午讨论一个复杂的新产品想法……我们估计，哪怕只是弄出一个概念验证（PoC），也需要数周甚至数月的专注工程开发。这个想法非常复杂，涉及一个带有紧密集成组件的精密前端，以及一个用于管理 GPU、自动扩展资源和生命周期管理的复杂后端基础设施。这不是那种你随便靠 Vibe Coding 就能搞定的东西；即使有 AI 的帮助，它也需要在每一步都进行深思熟虑的人工监督——至少我们当时是这么认为的。

Josh 和我已经决定，我们至少需要整整一个月的探索调研，才能确定是否值得尝试进行开发。

那天晚上，纯粹出于好奇，我把一份产品规格说明书喂给了 GPT-5，满心以为它会立刻翻车。

一个小时后，我给 Josh 发去了一个完全可运行的原型。

![图 1：发给 Josh 的消息及反应](https://shumer.dev/images/messagetojosh.png)

发给 Josh 的消息及反应

他的第一反应是：“卧槽。”

### 只能说……太震撼了。

那一刻彻底颠覆了我对 GPT-5 的看法。我们毫不夸张地跳过了一个月的前期客户调研和规划。我们可以直接去和真实用户进行测试了。（顺便说一句，如果你正在积极训练模型，请联系我——我很乐意向你展示它，而且我想确保我们正在构建的东西是你真正会去用的。）

从那以后，事情迅速变得有趣起来。我开始进行更深入的探索，尝试那些我以前甚至都懒得让旧模型去做的、更具野心的任务。我尝试得越多，就越清楚地意识到：GPT-5 绝不是什么渐进式的改进。

GPT-5 彻底拿下的一个领域就是前端代码。如果你以前用过 AI 写前端，当你听到我说它通常有一种“AI 制造”的感觉时，你大概就知道我的意思。这些设计通常有点笨拙、千篇一律，明显是机器生成的。然而，有了 GPT-5，这些 UI 感觉更接近令人信服的人类作品……乍一看有 80% 难以与人类作品区分。它甚至能以极快的速度通过截图克隆出一个 Figma 设计稿……虽然一些小细节有偏差，但作为第一版，它比我以前见过的任何东西都要好得多。偶尔，我仍然需要再次提示它进行响应式调整，但这些调整都是微不足道的，几秒钟就能完成。前端已经接近成为一个被解决的问题了。

它惊人地注重细节，通常在第一遍就能把微交互、间距和状态处理得恰到好处。

示例：让每个 ChatGPT 模型克隆 ChatGPT 的 UI。

### 模型 UI 对比

点击每个模型的名称，查看其创建的 UI 克隆。

GPT-4o GPT-4.5 o3 GPT‑5

![图片 2：4o 克隆的 ChatGPT 原型](https://shumer.dev/images/4o.png)

4o

![图片 3：4.5 克隆的 ChatGPT 原型](https://shumer.dev/images/4.5.png)

4.5

![图片 4：o3 克隆的 ChatGPT 原型](https://shumer.dev/images/o3.png)

o3

![图片 5：GPT‑5 克隆的 ChatGPT 原型](https://shumer.dev/images/clonegpt.png)

GPT‑5

←→

在后端和基础设施方面，GPT-5 同样出色，甚至可能更令人印象深刻。再次以 GPU 基础设施任务为例：仅仅经过三轮简短的提示，GPT-5 就设置好了 GPU 的自动配置、扩缩容和销毁。这感觉像是真正的自主性，模型从头到尾构建出了稳定且可用的东西。

我深入得越多，就越清楚地看到 GPT-5 有多么与众不同。在小众的机器学习任务上，尤其是涉及像 TRL 这样的库的棘手问题时，GPT-5 始终让我感到惊艳。有一次，它显然无法直接从其训练数据中得知最新的 TRL 模式，但它并没有卡住或胡乱产生幻觉，而是自主地直接查阅文档，找到了完全正确的答案，并正确地实现了它。不需要手把手指导，也不需要粘贴文档给它。我见过其他模型偶尔也会做类似的事情，但 GPT-5 做得足够稳定，以至于我现在严重依赖它来编写微调/RL 代码，这在以前的模型中是我从未做到过的。

我也比以往任何时候都更深入技术栈的底层。我不再仅仅依赖它来编写高层的训练脚本；我正在修改以前根本不会碰的代码。如果我过去最深入的程度只是“训练循环和配置”，那么我现在可以轻松地编辑更下一层的代码——自定义损失函数、数据管道等，因为这个模型非常可靠。以前，模型经常会在这些地方出错，所以我无法“放手”去信任它们处理高层以外的任何事情。现在不同了。效果很简单：无论你以前使用 Claude 4 Opus、o3 等模型的天花板在哪里，GPT-5 都能让你再深入一层。

GPT-5 也成为了我进行实际模型训练时的首选搭档。毫不夸张地说，它手把手指导我完成了调整超参数、调试离奇的报错、缓解奖励作弊（reward hacking）等工作。根据我的经验，它的建议一针见血！几周前，当我和 OpenPipe 团队发布 [AutoRL](https://github.com/OpenPipe/ART/tree/auto-rl?tab=readme-ov-file#-autorl-train-models-for-any-task) 时，GPT-5 仅凭我对需求的描述，就一次性写出了（one-shotted）整个训练循环。我也让它去处理我们主要的 HyperWrite 代码仓库，它同样轻松搞定（这尤其令人印象深刻，因为该仓库已经积累了多年，里面有大量废弃和混乱的代码，模型需要自己去梳理）。

GPT-5 之所以能为我带来如此天翻地覆的改变，主要原因不仅仅在于其能力的提升。GPT-5 速度极快。哪怕它仅仅和 o3 一样聪明，但只要能快这么多，也足以具有颠覆性。而事实上，它不仅在处理大多数提示词（prompts）时更聪明，而且快如闪电，这直接让它跃升到了一个完全不同的级别。大多数任务只需几秒钟就能返回结果；即使是最长的提示词，也很少超过一分钟。这种速度意味着我能始终保持在心流状态……中断更少，等待更少，思维上下文的切换也更少。这种无比流畅的体验，彻底改变了我的工作流。

不过，它仍然存在一些需要注意的细节和令人烦恼的地方。例如，GPT-5 对提示词结构出奇地敏感，尤其是在使用 RepoPrompt 等工具构建复杂的提示词时。在早期使用时，它有时会“跑偏”，无视我的指令并做出毫不相关的修改。我最终找到了一个简单的解决办法：在提示词的开头明确重复关键指令，就能可靠地解决这个问题（查看示例）。这是一个简单直接的变通方法，但非常值得注意。希望 OpenAI 团队能尽快通过新的快照版本（snapshot）修复这个问题。

另一个小烦恼是：GPT-5 在对话结尾时显得“过于热情”。我可能只是问个简单的问题，比如快速查一下天气，它却会附带问一句多余的话，比如：“需要我为您制定一份全天的综合计划吗？”这虽然无伤大雅，但对于重度用户来说，确实相当烦人。

### Auto、Thinking 和 Pro 模式

GPT-5 提供了三种主要模式。

Auto（自动）是默认模式，也是大多数用户应该使用的模式。其底层实际上运行着两个模型：一个会立即给出回答，另一个则会在回答前进行思考。系统中有一个分类器，会根据你输入的提示词来决定使用哪一个模型。

其次是 Thinking（思考）模式，这也是我现在几乎唯一在用的模式。它会绕过分类器，对每一个提示词都强制使用具备思考能力的模型版本。这个模式速度较慢（尽管与竞品相比依然很快），但当你处理复杂或具有创造性的任务时，这才是它真正展现魔力的地方。

最后是 Pro（专业）模式，这是最进阶的模式。我目前还没有获得该模式的访问权限，因此只能对其能力进行推测。它的核心理念可能与 o3 Pro 模式相似，即（同样是推测）并行运行多个 o3 实例，并使用某种集成（ensemble）策略将它们的输出合并，从而生成一个单一的、最优的回答。考虑到 o3 Pro 相比标准版 o3 的提升幅度，如果 GPT-5 的 Pro 模式也能带来同等程度的能力飞跃，我一点也不会感到惊讶。老实说，基于我目前使用 GPT-5 的体验，我甚至很难想象 Pro 模式究竟能解锁怎样级别的能力和可靠性。

### API 定价

对于基于 GPT-5 进行开发的开发者，定价如下：

*   输入（Input）：每百万 tokens 1.25 美元（提供 90% 的缓存折扣，这对于长上下文查询来说意义重大）
*   输出（Output）：每百万 tokens 10 美元

这比 GPT-4o 更便宜，真是太棒了。每美元的智能水平在持续提升。

注意：OpenAI 还提供了 GPT-5 的 Mini（较小）和 Nano（最小）版本，它们价格更低但能力较弱。我尚未测试过这些版本，因此不予置评。

### GPT-5 的不足之处

对于明确的搜索任务，我仍然更倾向于 o3。为什么？因为 GPT-5 往往过早停止深挖。例如，我曾尝试让 GPT-5 查找一位公众人物的家乡。它只查到了所在的城市，然后就停手了。我需要多次提示，才能让它真正深入查找并找到具体的城镇。相比之下，o3 则会不断深挖，直到找到你所需的信息。对我来说，这算不上是致命缺陷，但如果你在研究中严重依赖模型，这一点值得注意。

另一方面，在隐性研究方面，例如在编码过程中途查阅文档或快速检查依赖库，GPT-5 显然优于 o3。

对于情感类或敏感任务，例如撰写棘手的电子邮件或策划对话策略，我仍然强烈倾向于使用 GPT-4.5。我会配合我专门设计的思考提示词来使用它（[点击此处尝试](https://shumerprompt.com/prompts/gpt-45-extended-thinking-prompt-6728ff88-2895-4ba4-8693-61a9f6678bc3)）。在语气、微妙感、幽默感和说服力方面，GPT-4.5 依然遥遥领先。

我还注意到，GPT-5 在遵循指令方面确实有些吃力。情况不算太糟，但如果你想获得最佳结果，仍然需要非常谨慎地组织和构建提示词的措辞。

我可能判断有误，但感觉 GPT-5 虽然具备大模型的能力，却带有一种小模型的“味道”。考虑到它惊人的速度、在创意写作和情感任务上的弱点、对提示词的敏感度，以及一些奇怪的失败模式，我总觉得 GPT-5 的实际参数规模比人们预期的要小得多。如果真是这样，考虑到它所展现出的强大能力，这反而让它整体上显得更加令人惊叹。这不应成为你使用它的阻碍，这仅仅是我在整个测试过程中感受到和注意到的一点。

### 长上下文处理

这里有一点出乎意料，尤其是考虑到我对该模型规模的怀疑：GPT-5 在非常、非常长的编程会话中，保持一致性的能力极其出色。我使用的提示词可能涵盖了数十万个 Token。它始终能以惊人的水平保持上下文。在长上下文处理方面，感觉它比 Gemini 2.5 Pro 要好得多（不过，我是通过 ChatGPT 界面访问该模型的，因此 OpenAI 有可能在模型之上做了一些额外处理）。直到亲身体验，我才意识到这有多么宝贵。对于深度、长时间的编程会话而言，这实现了真正的飞跃。

这种上下文保留能力，体现为在漫长的会话中对微小细节的一丝不苟。

即使被扔进庞大且混乱的代码库中，GPT-5 依然能对架构、文件组织和项目上下文保持清晰的理解，而以前的模型如果不经过不断提醒，往往很难做到这一点。随着上下文窗口的增大，它似乎并没有变“笨”……通常情况下，它甚至显得更聪明了，对项目的整体结构以及各个部分如何协同工作有了更深刻的认知。

这就是新的标准，我绝不可能再用回其他模型了。

### 我错了。我心甘情愿地收回我之前的话。

所有这一切都蕴含着更深远的意义。GPT-5 是一次真正的飞跃。我真心认为，现在整个行业的其他参与者都必须开始冲刺追赶了。发布其他模型或编程平台的研发机构需要注意了：开发者们将会迅速转向 GPT-5。自主性与速度的结合是一项重大突破。使用 GPT-5 的团队在产品交付速度上将远超不使用的团队。

如果你正在围绕这些模型进行开发，这就是让你的产品实现 10 倍提升的绝佳机会。如果你是风险投资人（VC），请密切关注：由 GPT-5 赋能的团队的采用曲线，将清晰地体现在他们构建和交付产品的速度上。预计市场动态将发生显著的转变。

最重要的是，正如模型智能的每一次跃升一样，新的应用场景将成为可能，新的公司也将应运而生并从中获利。你可以确信，我已经发现了几个这样的应用场景，并且目前会暂时保密，目的是围绕它们构建一些全新的东西。至少可以说，这令人无比激动。

归根结底，GPT-5 不仅仅会提升 vibe coding（直觉编程）的体验，它还将从根本上改变那些我认为在没有大量人工干预和引导的情况下即可完成的项目类型。在过去的一周里，它把我原本确信需要耗时数月的工程挑战，变成了一次轻松的一小时冲刺。

这是严肃的、真正的、自主的软件工程。

## 关联主题

- [[00-元语/OpenAI]]
- [[00-元语/ChatGPT]]
- [[00-元语/Claude]]
- [[00-元语/gemini]]
- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/vibe-coding]]
- [[00-元语/Agent]]
- [[00-元语/软件工程]]
- [[00-元语/productivity]]
- [[00-元语/prompt]]
