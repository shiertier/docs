# GPT-5.2 评测：令人惊艳，但速度太慢

## 文档信息
- 原文标题：GPT-5.2 Review: Incredibly Impressive, But Too Slow
- 作者：Matt Shumer
- 发布日期：2025-12-09
- 原文链接：https://shumer.dev/gpt52review

## 摘要
### 一句话总结
GPT-5.2 及其 Pro 版本在遵循复杂指令、长上下文处理和代码生成方面取得了显著进步，尤其适合深度推理和复杂编程任务，但在响应速度和部分空间生成能力上仍存在局限。

### 关键要点
*   **指令遵循与任务执行**：模型能完整执行复杂指令（如生成50个构思后再做选择，而非走捷径），并愿意尝试如构建200页书籍结构及 PDF 等高难度任务。
*   **代码生成与自主性**：能处理更大规模的任务并持续输出更多代码；在 Codex CLI 中表现出极高的自主性，会先收集上下文（提问、读取文件、探索代码库）再编写代码。
*   **视觉与长上下文**：视觉能力（特别是空间关系理解）显著提升；在处理大型代码库和海量数据时，长上下文的稳定性极佳。
*   **Pro 模式的深度推理**：Pro 版本具备极高的智能和深度思考意愿，能精准理解用户隐性需求（如在食谱测试中理解“没时间”意味着需要简化采购和备菜心智）。
*   **提示词编写**：擅长编写提示词并能预判边缘情况，该能力与 Claude Opus 4.5 相当，优于 Gemini 3 Pro。
*   **多模型场景定位**：日常快速问答首选 Claude Opus 4.5；深度研究与复杂推理首选 GPT-5.2 Pro；前端 UI 视觉设计 Gemini 3 Pro 最佳；复杂 Agent 编程任务首选 GPT-5.2。
*   **界面与生态限制**：OpenAI 的 Canvas 界面目前无法承载模型输出的大量代码；Pro 模式仅限 ChatGPT 界面可用，尚未接入 API 或 Codex CLI（开发者需借助 RepoPrompt 等工具绕过限制）。
*   **输出风格**：默认过度依赖项目符号（Bullet points），整体写作风格略逊于 Claude Opus 4.5，但已开始学会在面对简单问题时给出简明回答。

### 风险与不足
*   **响应速度缓慢**：标准 Thinking 模式和 Codex CLI 中的超高推理模式运行速度非常慢，导致其在日常快速任务中实用性不佳。
*   **空间生成缺陷**：尽管视觉理解有所提升，但在代码生成（如 Three.js 棒球场测试）中的空间感知和对象布局能力仍需大幅改进。
*   **推理死循环（Quirks）**：Pro 模式偶尔会在冲突的指令间陷入长时间的纠结，耗费数分钟思考后直接放弃任务或执行失败（OpenAI 已知晓此问题）。

## 正文
自11月25日以来，我就获得了GPT-5.2的访问权限。在经过两周的全面测试，涵盖编程、研究、创意写作和日常任务之后，我有_很多_想法。这篇评测涵盖了标准的GPT-5.2 Thinking模型以及GPT-5.2 Pro；不过我也写了一篇[更深入的针对Pro版本的评测](https://shumer.dev/gpt52prodeepdive)，因为那个模型值得单独写一篇文章。

简而言之：GPT-5.2向前迈出了有意义的一步，特别是在遵循复杂指令的能力，以及它真正_尝试_困难任务的意愿方面。Pro模式在GPT-5.1 Pro（这已经是我最喜欢的系统）的基础上进行了改进，在深度推理工作方面令人印象非常深刻。但也有一些值得了解的怪癖。

让我们一探究竟。

GPT-5.2 Thinking：直觉的提升
------------------------------------

GPT-5.2最引人注目的地方在于它遵循指令的能力……不是那种基本的“按我说的做”，而是“真正完成我描述的整个任务”。

举个例子。在设置一个创意写作测试时，我要求它在为故事决定最佳情节之前，先想出50个情节构思。大多数模型会在这里走捷径。它们可能只会给你10个构思，挑一个，然后继续。GPT-5.2实际上在做出选择之前生成了全部50个构思。这听起来微不足道，但事实并非如此。当你进行创意工作或研究时，那额外的40个构思中可能就包含真正有趣的那个。模型相信这个过程而不是为了速度去优化，这一点很重要。

我进一步增加了难度。我要求它写一本200页的书。虽然这些页面本身内容单薄且简短……这并不是一个能一次性写出可出版小说的模型。但是，令人印象深刻的是，它确实尝试去做了，这比我能评价的其他模型要好得多。它构建了整本书的结构，甚至将其排版为PDF。大多数模型认为自己做不到，甚至连试都不试。它们会告诉你“那太长了”，或者给你一个大纲，并提议逐节完成。GPT-5.2只是……直接放手去做了。这种愿意尝试宏大任务的意愿，即使做得不完美，也开启了新的工作流。

### 代码生成：真正的进步

GPT-5.2中的代码生成相比之前的模型确实是一个真正的进步。它写出的代码更好，并且能够处理比以前更大的任务。但它仍然不完美。例如，我在Three.js动画上对它进行了测试，以对空间推理进行压力测试。我要求它构建一个棒球场场景，它生成了比大多数模型更逼真的样式（纹理/光照非常棒），但空间感知和物体放置仍然需要_大量_的改进。但抛开任何特定框架不谈，代码输出的整体质量有了显著提高。

![图1：物体放置不正确的Three.js棒球场测试](https://shumer.dev/images/gpt52threejsfail.png)

Three.js棒球场测试：纹理/光照非常棒，但布局有偏差。

该模型还愿意编写比以前版本多得多的代码，并且能够不间断地工作更长时间。这是一项真正的能力提升。

关于代码生成的更多细节，请参见下方我的Codex CLI部分。

### 视觉与长上下文

5.2的视觉能力有了显著提升。在理解图像的能力上有了很大的不同……尤其是位置和空间关系（尽管空间生成仍在完善中）。这对于计算机操作智能体（computer-use agents）来说非常棒。

它在处理长上下文时也非常出色。处理庞大的代码库、大量数据和冗长的分析线程感觉比以前更稳定，这也是 GPT-5.2 在智能体编码工作流（agentic coding workflows）中表现如此出色的原因之一。

顺便提一句：模型变得如此强大，而 OpenAI 的 ChatGPT 界面却完全没有跟上，这实在有些荒谬。例如，ChatGPT 中的 Canvas 界面仍然无法处理大量代码……我最初在 Canvas 中尝试了我的 Three.js 测试，但模型输出的代码量超出了 Canvas 的处理能力。拜托，谁来让它变得合理一点吧！OpenAI 需要在这方面下点功夫了。

正如我在之前的评测中提到的，Pro 模式仍然只能在 ChatGPT 中使用……在 Codex CLI 中无法使用。这依然让我感到沮丧。如果你想在代码上使用 Pro 的推理能力，你就只能忍受 ChatGPT 界面的限制。我使用 RepoPrompt 来弥补这个差距……它提取我的本地代码库，将其转换为提示词（prompt），我将其粘贴到 5.2 Pro 中，然后当模型回复时，我再将其粘贴回 RepoPrompt，由它将更改应用到我的代码库中。这是一个额外的步骤，但它让我能在真实的代码库上获得 Pro 级别的推理能力。而且在代码方面，Pro 简直是个他妈的怪物……我在[专门的 Pro 评测](https://shumer.dev/gpt52prodeepdive)中对此有更多讨论。

### 风格

如果你用过 OpenAI 的模型，你就会知道它们有多喜欢用要点列表（bullet points）。GPT-5.2 延续了这一传统。让它解释一些东西，你通常会得到一个带有项目符号的列表，而实际上几个清晰的段落会表达得更好。如果你仔细编写提示词——明确要求使用流畅的文字，或者展示你想要的风格，你可以绕过这个问题。但那些只是随意输入提示词的普通用户，无论他们是否愿意，都会得到“要点列表”的待遇。

除了要点列表的问题，这次发布的版本在写作风格上有所改进。相比 GPT-5.1，它并没有大幅度的飞跃，但确实好了一些。

尽管如此，至少对我来说，它还是比 Claude Opus 4.5 逊色一筹。话虽如此，在处理繁重的写作任务时，我有时比 Opus 更倾向于使用 GPT-5.2 Pro，因为它思考得更深入；虽然文字可能稍微粗糙一些，但信息的清晰度和结构往往表现得更强。

积极的一面是，GPT-5.2 已经学会了在回复时何时该保持简洁。并非每个问题都需要 500 字的解释，而这个模型_有时_能意识到这一点。当我问一些简单的问题时，我偶尔会得到一个简单的答案。这种情况发生的频率仍然没有我希望的那么高……我希望这成为默认状态，而不是例外……但这已经是进步了。

如果你想要我用来让 GPT-5.2 保持简洁且不使用要点列表的自定义指令提示词，可以在这里获取：[简洁回复风格提示词](https://shumerprompt.com/prompts/gpt-52-concise-response-style-custom-instructions-prompt-bfa38620-cda5-4a47-b937-7a5793537907)。

### 速度问题

有一件事影响了我的日常使用：标准的 GPT-5.2 Thinking 速度很慢。根据我的经验，对于大多数问题，甚至是很直接的问题，它都非常非常慢。话虽如此，我看到其他测试人员报告了不同的（好坏参半的）速度表现……在某些任务上更快，在其他任务上更慢。我几乎从不使用 Instant；Thinking 要好得多，而 Pro 更是强得离谱，但这意味我通常要付出速度上的代价。

在实践中，这意味着我极少使用 GPT-5.2 Thinking。我实际的工作流变成了：快速的问题交给 Claude Opus 4.5，而当需要深度推理时，我直接使用 GPT-5.2 Pro。标准的 Thinking 模型处于一个尴尬的中间地带……比 Opus 慢，又没有 Pro 完整的推理优势。

### 综合对比

我一直在同时使用 Claude Opus 4.5、Gemini 3 Pro 和 GPT-5.2，它们在我的工作流中已经确立了各自明确的定位。

对于快速提问：比如“X 的语法是什么”或“提醒我 Y 是怎么用的”这类问题，Claude Opus 4.5 胜出。它速度更快，也更切中要害。当我只需要直奔主题获取信息时，我就会用它。

对于研究任务和复杂推理，GPT-5.2 Pro 明显更胜一筹。当我需要从多个角度对某件事进行深入思考时，当任务需要处理大量上下文并进行仔细的综合分析时，Pro 的表现更为出色。

对于前端 UI 生成，GPT-5.2 的 Thinking 和 Pro 模式都比之前的 GPT 模型提升了一个台阶。但在这项工作上，它们都无法与 Gemini 3 Pro 媲美。这里有一个值得解释的微妙之处：Gemini 3 Pro 拥有最棒的*风格*感——它生成的 UI 很好看，审美选择非常出色。但它在*布局*和实际的前端工程方面不够可靠。因此，如果我需要能够准确无误运行并处理边缘情况的代码，我仍然会选择 Opus 或 GPT。如果我需要外观精美的界面，并且愿意自己动手修复工程问题，那么 Gemini 3 Pro 是目前最好的选择。

GPT-5.2 Pro：缓慢的天才
--------------------------

Pro 模式才是真正有趣的地方。这是 ChatGPT 内部的一个独立系统，正如我之前提到的，它仅在 ChatGPT 中可用，Codex CLI 中没有，API 中也没有，其他任何地方都不提供。

简而言之：Pro 聪明得离谱。Thinking 和 Pro 之间的智力差异显而易见。但除了纯粹的智力之外，让 Pro 脱颖而出的是它*思考的意愿*。在解决问题时，它花费的时间会比之前的 Pro 模型长得多。对于研究任务，如果任务有要求，它会花上长得离谱的时间去进行研究。

### 食谱测试

我来举一个具体的例子，很好地体现了 Pro 的优势。我让它帮忙制定膳食计划，并强调我没有时间做饭。我想要一份 7 天的计划，每天包含一日三餐和两顿零食。Pro 给出了非常棒的食谱计划，但最引人注目的是食材清单……比其他模型建议的要简单得多。它明白“我没有时间”不仅仅是对烹饪时间的限制；它同样限制了购物的复杂程度、备菜工作以及心理负担。它领会了我的*心态*，而不仅仅是字面上的要求。这着实令人震惊。我曾将相同的提示词发给了所有其他前沿模型，但没有一个考虑到这一点。

正是这种理解力让 Pro 显得与众不同。

### 提示词编写

GPT-5.2 非常擅长编写提示词……这不仅有助于充分发挥各类 AI 模型的潜力，对构建集成了 LLM 的软件也大有裨益。如果你正在开发使用语言模型的应用程序，让 GPT-5.2 帮你精心打磨提示词会非常有帮助。它编写的提示词非常周密，往往能预判到我根本想不到的边缘情况。在这方面，它与 Claude Opus 4.5 旗鼓相当，并且绝对完胜 Gemini 3 Pro。

### Codex CLI

我在 Codex CLI 中对 GPT-5.2 进行了大量测试（Pro 模式从未在那里提供过……唉），而且越用越觉得惊艳。这是我在 CLI 环境中体验过的最接近 Pro 模型的表现。它一次性把事情做对的概率，比我用过的任何其他模型都要高得多。唯一的问题是，我只能使用它的超高推理模式（extra-high reasoning mode），这可能会耗费极其漫长的时间……通常比 Pro 还要久，这挺让人抓狂的。

自主性相比之前的模型有了显著提升。但真正的区别在于它处理上下文收集的方式。Claude Opus 4.5 倾向于在完全理解问题之前就开始编写代码。它会做出假设，开始实现，然后因为没有掌握所需的所有上下文而遇到问题（我知道其他人在这一点上有不同或更好的体验，但这是我的亲身经历）。GPT-5.2 不会这样。它会提问。它会读取文件。它会探索代码库。它会_首先_收集上下文，然后再编写代码。

这改善了我的工作流。这些模型一直在稳步改进，随着时间的推移，我检查它们工作的次数也越来越少。但 GPT-5.2 让人感觉是一个显著的飞跃。除非任务至关重要——比如生产环境代码，否则我通常只是让它自己运行，而不会去审查每一个更改。

## 关于一些小毛病的说明

我确实在 Pro 模式下遇到了一些奇怪的行为，它似乎陷入了相互冲突的指令之间……花了整整几分钟时间权衡，然后把一个简单的任务踢回给我，而不是直接去完成它。偶尔，它会思考很长时间，但最终还是失败了，这非常令人恼火，而且浪费了大量时间。OpenAI 已经意识到了这个问题并正在调查。这并非致命缺陷，但需要了解的是，这些推理模型偶尔会陷入奇怪的死循环中。

![图片 2：GPT-5.2 Pro 陷入冲突指令的示例](https://shumer.dev/images/gpt52proweirdbehavior.png)

Pro 模式的推理摘要陷入了开发者/用户冲突的指令之间。

## 何时使用哪个模型

经过两周的测试，以下是我的实用分类建议：

对于快速提问和日常任务，Claude Opus 4.5 依然是我的首选。它速度快、准确率高，而且不浪费我的时间。当我只需要一个答案时，我会从它开始。

对于深度研究、复杂推理以及需要缜密思考的任务，GPT-5.2 Pro 是目前可用的最佳选择。对于那些“做对”比“做得快”更重要的任务来说，速度上的牺牲是值得的。

对于前端样式和美观的 UI 工作，Gemini 3 Pro 目前能生成最漂亮的结果。只是要做好事后进行一些工程代码清理的准备。

对于在 Codex CLI 中进行的严肃编程工作，GPT-5.2 表现出色。其收集上下文的行为和可靠性使其成为我处理代理式编程任务（agentic coding tasks）的默认选择。

## 总结

GPT-5.2 是一次真正的进步。其遵循指令的能力有了显著提升。Pro 模式的智能和可靠性令人印象深刻。对于需要缜密推理的复杂任务，这是我用过的最好的模型。

标准 Thinking 模型（思考模型）的速度让我无法在日常中频繁使用它。我最终会用 4.5 Opus 处理快速任务，用 Pro 处理深度工作。但在 GPT-5.2 擅长的任务上，它确实大放异彩。

我专门撰写的 [Pro 模式深度解析在这里](https://shumer.dev/gpt52prodeepdive)。如果你还在犹豫是否要尝试它：答案是肯定的，特别是当你的工作涉及研究、复杂推理或编程时。

## 关联主题

- [[00-元语/OpenAI]]
- [[00-元语/ChatGPT]]
- [[00-元语/Codex]]
- [[00-元语/Claude]]
- [[00-元语/gemini]]
- [[00-元语/llm]]
- [[00-元语/prompt]]
- [[00-元语/benchmark]]
- [[00-元语/Agent]]
- [[00-元语/cli]]
- [[00-元语/multimodal]]
