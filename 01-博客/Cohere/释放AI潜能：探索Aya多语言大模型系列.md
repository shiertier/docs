---
title: "释放AI潜能：探索Aya多语言大模型系列"

来源: "https://cohere.com/research/aya"
---

## 摘要

**1) 一句话总结**
Cohere Labs 发起的 Aya 全球开放科学计划通过推出 Tiny Aya、Aya Vision、Aya Expanse 等系列模型与数据集，致力于推动多语言及多模态 AI 技术的普及与前沿发展。

**2) 关键要点**
* **项目背景**：Aya 是机器学习领域迄今最大规模的开放科学协作项目，由 Cohere Labs 发起，汇聚了全球独立研究人员。
* **Tiny Aya**：33.5亿（3.35B）参数的紧凑型模型，支持70多种语言本地运行，提供全球均衡版（Global）及针对非洲/西亚（Earth）、南亚（Fire）、亚太/欧洲（Water）的区域特化版。
* **Aya Vision**：支持23种语言的多模态模型，通过优化训练技术将计算开销降低高达40%，并解决了数据稀缺和灾难性遗忘问题。
* **Aya Expanse**：支持101种语言，通过指令微调和跨语言迁移技术，将基础设施成本降低高达30%。
* **Aya 101**：由全球3000多名研究人员协作开发，支持101种语言的指令微调，作为开源框架发布。
* **核心驱动力**：Aya 系列的发展依赖于开放协作与透明度、资源高效型创新以及高质量数据集三大支柱。
* **发布里程碑**：项目自2024年2月起陆续发布 Aya Dataset/Model、Aya 23、Aya Expanse，并规划于2025年5月发布 Aya Vision，2026年2月发布 Tiny Aya。
* **学术荣誉**：Aya Model 荣获 ACL 2024 最佳论文奖，Aya Dataset 入选斯坦福大学 HAI 2024 年度精选发布。

## 正文

Aya 是由 Cohere Labs 发起的一项全球性开放科学计划。它汇聚了全球的研究人员，致力于推动多语言 AI 的前沿发展，弥合世界各地人与文化之间的鸿沟。

作为机器学习领域迄今为止最大规模的开放科学协作项目，Aya 将来自世界各地的独立研究人员社区聚集在一起，为未来的创新奠定了强大的基础。这一初步的努力为后续的研究计划和更多模型的开发铺平了道路，不断拓宽 AI 所能触及的世界边界。

### 全新发布：Tiny Aya

Tiny Aya 是一个紧凑型的多语言 AI 模型系列，支持在任何设备上进行本地运行。我们的 33.5 亿（3.35B）参数基础模型支持 70 多种语言，并针对不同地区提供了专门的变体版本。它无需依赖云端即可提供强大的性能。

您可以根据实际的真实应用场景，选择全球均衡版或区域特化版模型：

*   **Tiny Aya Global**：针对均衡的多语言性能进行了全面优化。
*   **Tiny Aya Earth**：在非洲和西亚地区的语言上表现最为强劲。
*   **Tiny Aya Fire**：在南亚语言上表现最为强劲。
*   **Tiny Aya Water**：在亚太和欧洲地区的语言上表现最为强劲。

### Aya 系列核心模型

除了轻量级的 Tiny Aya，Aya 系列还包含多款强大的研究模型，致力于让多语言 AI 变得更加普及：

*   **Aya Vision**
    这是一款推动多语言多模态 AI 发展的研究模型。通过创新的合成数据生成、跨模态模型融合以及全面的基准测试套件，它在 23 种语言中实现了业界领先的性能。该模型超越了许多更大规模的模型，并通过优化的训练技术将计算开销降低了高达 40%，有效解决了数据稀缺和灾难性遗忘问题。（官方还为此发起了“Aya Vision 挑战赛”，探索模型与其创造者之间谁能更胜一筹。）
*   **Aya Expanse**
    Aya Expanse 重新定义了多语言 AI，它是一款掌握了 101 种语言的研究模型。通过创新的指令微调和跨语言迁移技术，结合精选的开源数据集与计算高效的预训练，它在低资源和高资源语言上均实现了无与伦比的性能，同时将基础设施成本降低了高达 30%。它为可扩展、包容性的语言建模树立了新标杆，致力于发展和加深全球各地人们之间的联系。
*   **Aya 101**
    这是一款具有突破性的研究模型，由 3000 多名研究人员组成的全球协作团队共同开发，在 101 种语言上具备出色的指令微调能力。作为 Cohere Labs 多语言计划的基石，它在各项基准测试中取得了领先成绩，同时保持了跨资源语言的高效性。该模型作为开源框架发布，旨在加速全球语言技术的公平发展。

### 核心驱动力

Aya 系列不断向前迈进、推动多语言生成式 AI 发展的背后，离不开三大核心支撑：
1.  开放协作与透明度
2.  资源高效型创新
3.  高质量数据集

### 发展历程与荣誉里程碑

Aya 项目在多语言 AI 领域不断取得突破，其重要发布历程如下：

*   **2024年2月13日**：发布 **Aya Dataset**（多语言指令微调开源数据集）与 **Aya Model**（开源多语言语言模型）。
*   **2024年5月23日**：发布 **Aya 23** 开放权重模型，进一步推动多语言发展。
*   **2024年12月6日**：发布 **Aya Expanse**，推进多语言 AI 研究。
*   **2025年5月14日**：发布 **Aya Vision**，实现多语言多模态 AI 的进步。
*   **2026年2月17日**：发布 **Tiny Aya**，在模型规模与多语言深度之间架起桥梁。

**学术与行业认可：**
*   **ACL 2024 最佳论文奖**：授予《Aya Model: An Instruction Finetuned Open-Access Multilingual Language Model》。
*   **斯坦福大学 HAI 2024 年度精选发布**：授予《Aya Dataset: An Open-Access Collection for Multilingual Instruction Tuning》。

## 相关文档

- [[01-博客/Cohere/Tiny Aya：在规模与多语言深度之间架起桥梁.md|Tiny Aya：在规模与多语言深度之间架起桥梁]]；关联理由：版本演进；说明：本文把 Tiny Aya 作为 Aya 系列里程碑之一，该文提供这一版本的独立技术细节。
- [[01-博客/Cohere/塑造机器学习研究的前沿：Cohere Labs 的使命与愿景.md|塑造机器学习研究的前沿：Cohere Labs 的使命与愿景]]；关联理由：上下游；说明：该文解释 Cohere Labs 的研究使命与开放科学路径，是 Aya 系列发布背景的上游语境。

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/multimodal]]
- [[00-元语/benchmark]]
- [[00-元语/paper]]
- [[00-元语/community]]
