---
title: "Anthropic的“安全至上”原则与五角大楼的激烈碰撞"
---

## 摘要

**1) 一句话总结**
Anthropic在发布具备强大自主能力的AI模型后，因坚持“安全至上”的军事使用限制而与五角大楼发生激烈冲突，面临被列为“供应链风险”的威胁。

**2) 关键信息**
*   **新模型发布**：2月5日，Anthropic发布了支持多智能体协作的Claude Opus 4.6模型；12天后推出成本更低、具备人类水平网页操作能力和庞大工作记忆的Sonnet 4.6。
*   **商业扩张**：Anthropic近期以3800亿美元估值完成300亿美元融资，企业客户占其总收入约80%。
*   **五角大楼施压**：军方要求Anthropic放弃军事用途限制，否则可能将其贴上通常用于外国敌对势力的“供应链风险”标签。
*   **冲突导火索**：1月3日美军在委内瑞拉抓捕马杜罗的行动中通过Palantir使用了Claude；Anthropic高管事后询问该技术是否用于此次突袭，引发五角大楼警觉。
*   **军方高层表态**：美国国防部长皮特·海格塞斯（Pete Hegseth）表示已“接近”切断与该公司的关系，并意图让其付出代价。
*   **两条红线**：Anthropic在军事合作中坚持两项原则：禁止对美国人进行大规模监控、禁止开发全自主武器。
*   **机密网络部署**：2024年底，Claude通过Palantir平台获得“机密（Secret）”云安全级别，成为首个在军方机密系统内运行的大语言模型（其他竞品仅同意放宽在非机密系统中的限制）。
*   **军方诉求**：五角大楼要求AI必须可用于“所有合法目的”，并明确表示与公司逐一谈判具体用例是“行不通的”。

**3) 风险与漏洞（基于原文明确提及）**
*   **业务剥离风险**：若被正式认定为“供应链风险”，将迫使五角大楼的承包商在敏感工作中彻底剥离Claude。
*   **“监控”定义的法律漏洞**：现有的法律框架基于“人工审查时代”建立，在AI进行海量数据集查询和模式识别时，难以明确界定“非法监控”与“大规模数据收集”的边界。
*   **目标打击的灰色地带**：AI自动化处理情报并生成目标清单（即使最终由人类批准）与“全自主武器”密切相关，在机密网络中难以准确区分“基础分析工作”与“目标定位”。
*   **技术进步导致界限模糊**：随着Opus 4.6和Sonnet 4.6在多智能体协作、大容量工作记忆和自主导航方面的能力提升，Anthropic试图将“日常繁杂工作”与“军事任务规划”区分开来的防线正变得难以维系。

## 正文

随着Anthropic发布其迄今为止最具自主性的AI智能体，该公司与美国军方之间日益激烈的冲突，揭示了在全球规模化扩张与“安全至上”理念之间一个几乎无法调和的矛盾。

### 强大模型发布与五角大楼的施压

2月5日，Anthropic发布了其最强大的AI模型Claude Opus 4.6。该模型的一项核心新功能是能够协调多个自主智能体团队——即多个AI可以分工合作并并行完成任务。仅仅12天后，该公司又推出了成本更低的Sonnet 4.6模型，其在编程和计算机操作能力上几乎与Opus 4.6不相上下。

在2024年底Anthropic首次推出能控制计算机的模型时，它们还勉强只能操作浏览器。但据Anthropic称，如今的Sonnet 4.6已经能够以人类水平浏览Web应用程序并填写表单。此外，这两个模型都拥有庞大的工作记忆，足以容纳一个小型的图书馆。

目前，企业客户约占Anthropic总收入的80%。就在上周，该公司以3800亿美元的估值完成了一轮300亿美元的融资。无论从哪个指标来看，Anthropic都是历史上扩张最快的科技公司之一。

然而，在盛大的产品发布和惊人的估值背后，Anthropic正面临一个严峻的威胁：五角大楼发出信号，除非Anthropic放弃对军事用途的限制，否则可能会将其列为“供应链风险”——这个标签通常用于外国敌对势力。这一认定可能会迫使五角大楼的承包商在敏感工作中彻底剥离Claude。

### 委内瑞拉突袭行动引发的导火索

双方的紧张局势在1月3日美国特种作战部队突袭委内瑞拉并抓获尼古拉斯·马杜罗（Nicolás Maduro）之后彻底爆发。

据报道，美军在行动中通过Anthropic与国防承包商Palantir的合作使用了Claude。这一事件加剧了双方本已紧张的关于“Claude究竟能用于什么”的谈判。当Anthropic的一名高管联系Palantir，询问该技术是否被用于此次突袭时，这个问题立即引起了五角大楼的警觉（尽管Anthropic否认此举是为了表达对特定军事行动的不满）。

据美国政府高级官员透露，国防部长皮特·海格塞斯（Pete Hegseth）已“接近”切断与该公司的关系，并表示：“我们要确保他们为这样逼迫我们付出代价。”

### “安全至上”与军事机密的伦理困境

这场冲突暴露了一个核心问题：一家以防止AI灾难为初衷而成立的公司，当其最强大的工具（能够处理海量数据集、识别模式并根据结论采取行动的自主智能体）在机密的军事网络中运行时，还能否坚守其伦理底线？一个“安全至上”的AI，是否能与一个需要在军事规模上自主推理、规划和行动的客户相兼容？

Anthropic划定了两条红线：
*   **禁止对美国人进行大规模监控**
*   **禁止开发全自主武器**

首席执行官达里奥·阿莫代（Dario Amodei）曾表示，Anthropic将在“除了那些会让我们变得像独裁对手之外的所有方面”支持国防。虽然OpenAI、Google和xAI等其他主要实验室已经同意放宽在五角大楼非机密系统中的使用限制，但它们的工具尚未进入军方的机密网络。而五角大楼的要求是，AI必须可用于“所有合法目的”。

这种摩擦正在考验Anthropic的核心理念。该公司由前OpenAI高管于2021年创立，他们认为当时的行业对安全问题不够重视，并将Claude定位为合乎伦理的替代方案。2024年底，Anthropic在Palantir平台上提供了Claude，其云安全级别达到了“机密（Secret）”——公开资料显示，这使得Claude成为首个在机密系统内运行的大型语言模型。

### 监控与目标打击的灰色地带

现在的僵局引出了一个问题：一旦技术被嵌入机密的军事行动中，“安全至上”是否还是一个站得住脚的身份？所谓的红线是否真的可行？

乔治城大学安全与新兴技术中心的高级研究员Emelia Probasco指出：“‘非法监控美国人’这几个字看似简单，但实际上，有成群的律师在试图弄清楚该如何解释这个短语。”

以斯诺登事件后的情况为例。当时美国政府为大规模收集电话元数据（谁打给谁、何时打、打多久）辩护，理由是这类数据不具备与通话内容相同的隐私保护级别。当时的隐私辩论主要围绕人类分析师搜索这些记录展开。但现在，想象一下由AI系统查询海量数据集——绘制网络图谱、识别模式、标记可疑人员。我们现有的法律框架是为“人工审查时代”建立的，而非“机器规模分析时代”。

国际机器人武器控制委员会联合创始人Peter Asaro表示：“从某种意义上说，你让AI去查看的任何大规模数据收集，从定义上讲就是大规模监控。”五角大楼官员认为Anthropic的限制存在“相当大的灰色地带”，且要求五角大楼与公司逐一谈判具体用例是“行不通的”。Asaro认为，这要么说明在AI时代确实无法定义监控，要么说明军方确实想将AI用于大规模监控和自主武器，只是用“灰色地带”来掩饰。

关于另一条红线——自主武器（即在没有人类监督的情况下选择和攻击目标的系统），定义相对狭窄且易于管理。但Asaro看到了一个更令人担忧的灰色地带。他提到了以色列军方的Lavender和Gospel系统，据报道，这些系统使用AI生成庞大的目标清单，交由人类操作员批准后再进行打击。

“你实际上已经将目标定位环节自动化了，这与自主武器密切相关，即使它超出了狭义的严格定义，”Asaro说。问题在于，在Palantir机密网络中运行的Claude是否也在做类似的事情——处理情报、识别模式、筛选目标人物——而Anthropic内部却无人能准确说出“分析工作”在哪里结束，“目标定位”从哪里开始。

### 模糊的边界与未来的挑战

马杜罗抓捕行动正是对这种界限的考验。如果AI只是收集数据和情报来识别目标，最终由人类决定轰炸名单，这似乎符合人类监督的要求。但另一方面，军方正变得越来越依赖AI来选择目标，而人类对这些目标的合法性进行审查和挖掘的程度，则是一个完全独立的问题。

Anthropic可能试图将界限划得更窄：将Claude可能协助确定轰炸目标的“任务规划”，与处理文档等“繁杂的日常工作”区分开来。

然而，Anthropic模型自身的能力可能让这种区分难以维系。Opus 4.6的智能体团队可以拆分复杂任务并并行工作，这种自主数据处理的进步可能会彻底改变军事情报工作。Opus和Sonnet都能在极少监督的情况下导航应用程序、填写表单并跨平台工作。正是这些推动Anthropic在商业上占据主导地位的功能，让Claude在机密网络中变得极具吸引力。

一个拥有巨大工作记忆的模型可以容纳整份情报档案；一个能协调自主智能体调试代码库的系统，同样也能协调它们去绘制叛乱分子的供应链。Claude越强大，Anthropic愿意支持的“基础分析工作”与它承诺拒绝的“监控和目标定位”之间的界限就越模糊。

随着Anthropic不断推进自主AI的前沿，军方对这些工具的需求只会越来越强烈。正如Probasco所担忧的，与五角大楼的冲突在安全与国家安全之间制造了一种虚假的二元对立：“为什么我们不能同时拥有安全和国家安全呢？”

## 关联主题

- [[00-元语/AI]]
- [[00-元语/Agent]]
- [[00-元语/Claude]]
- [[00-元语/llm]]
- [[00-元语/alignment]]
- [[00-元语/compliance]]
- [[00-元语/risk]]
- [[00-元语/security]]
