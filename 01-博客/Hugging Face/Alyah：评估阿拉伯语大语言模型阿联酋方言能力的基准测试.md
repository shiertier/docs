---
title: "Alyah：评估阿拉伯语大语言模型阿联酋方言能力的基准测试"

来源: "https://huggingface.co/blog/tiiuae/emirati-benchmarks"
---

## 摘要

### 一句话摘要
Alyah 是一个包含 1,173 个样本的基准测试，专门用于评估大语言模型对阿联酋方言及其背后文化、语用特征的理解能力，以填补传统阿拉伯语评估过度集中于现代标准阿拉伯语（MSA）的空白。

### 核心要点
*   **数据集构建**：包含 1,173 个多项选择题样本（4个选项），由阿联酋母语人士手动收集以确保真实性；干扰选项由大语言模型生成并经人工审查。
*   **内容覆盖**：划分为 7 个类别，包括问候与日常表达、宗教与社会敏感度、意象与比喻义、礼仪与价值观、诗歌与创意表达、历史与文化遗产知识、语言与方言。
*   **评估规模**：共评估了 54 个模型（23 个基础模型，31 个指令微调模型），涵盖原生阿拉伯语模型（如 Jais, Allam）、多语言模型（如 Qwen, LLaMA）及区域适配模型。
*   **评估标准**：侧重于回答的语义正确性及是否符合阿联酋语言习惯，而非与参考答案的字面重合度。
*   **微调优势**：指令微调模型整体表现优于基础模型，在涉及对话规范和文化得体回应（如“礼仪与价值观”）的问题上尤为明显。
*   **能力迁移**：模型在“意象与比喻义”类别表现较好，这主要归因于模型从现代标准阿拉伯语（MSA）中迁移了提取非字面描述模式的能力。
*   **最佳表现模型**：得分最高的大型模型是 Jais-2-70B，小型模型中表现最好的是 jais-2-8B 和 ALLaM-7B-instruct（均为阿拉伯语指令微调模型）。

### 风险与不足
*   **口语语料缺乏导致盲区**：“语言与方言”及“问候与日常表达”是所有模型表现最差的类别，因为阿联酋方言主要用于口语，极少用于书面媒体，导致模型对其较为陌生。
*   **多语言模型的局限性**：即使是强大的通用多语言模型，在最具挑战性的方言问题上也会出现明显的性能下降，难以仅通过通用训练获得特定方言的语义知识。
*   **深层文化理解鸿沟**：表层方言熟悉度与深层文化理解之间仍存在差距，涉及隐式含义和罕见表达的问题对几乎所有受评模型而言仍然十分困难。

## 正文

阿拉伯语是世界上使用最广泛的语言之一，在二十多个国家拥有数亿使用者。尽管具有如此广泛的全球影响力，阿拉伯语却并非一种单一的语言。现代标准阿拉伯语（MSA）与丰富的地区方言并存，这些方言在词汇、句法、音系和文化底蕴上都有着显著差异。这些方言是日常交流、口头讲故事、诗歌和社会互动的主要媒介。然而，现有的大多数阿拉伯语大语言模型基准测试几乎完全集中在现代标准阿拉伯语上，导致方言阿拉伯语在很大程度上缺乏评估和代表性。

随着大语言模型越来越多地在非正式、具有文化背景的对话场景中与用户互动，这一空白显得尤为突出。一个在正式新闻文本上表现良好的模型，可能仍然无法理解当地的问候语、惯用表达或用当地方言讲述的简短轶事。为了解决这一局限性，我们的团队推出了 **Alyah（الياه）**（在阿联酋方言中意为“北极星”⭐️），这是一个以阿联酋为中心的基准测试，旨在评估阿拉伯语大语言模型在捕捉阿联酋方言的语言、文化和语用特征方面的表现。

### 基准测试的动机与范围

阿联酋方言与当地文化、遗产和历史深度交织。它出现在日常问候、口头诗歌、谚语、民间故事以及无法仅通过字面翻译推断其含义的表达中。我们的基准测试旨在深入探究这一层面。它并非仅仅测试表层的词汇知识，而是挑战模型解释蕴含文化意义、语用习惯和方言特定细微差别的能力。

该基准测试涵盖了广泛的内容，包括常见与罕见的本地表达、具有文化背景的问候语、简短轶事、与文化遗产相关的问题以及对阿联酋诗歌的引用。其目标不仅是衡量准确性，还要了解模型在面对真实的阿联酋语言使用时，在哪些方面会系统性地成功或失败。

### 数据集结构

经过进一步的开发和整合，该基准测试被统一为一个名为 **Alyah** 的数据集。最终的基准测试包含 **1,173 个样本**，全部由阿联酋母语人士手动收集，以确保语言的真实性和文化底蕴。这一手动筛选步骤至关重要，因为它能捕捉到极少记录在书面资源中、且难以仅从现代标准阿拉伯语中推断出的表达、含义和用法。

每个样本都被设计为一道多项选择题，包含**四个候选答案**，其中只有一个是正确的。我们使用大语言模型合成生成了干扰选项，随后进行人工审查，以确保其合理性且在语义上接近正确答案。为避免评估时的位置偏差，正确答案的索引在整个数据集中呈随机分布。

Alyah 涵盖了阿联酋方言中广泛的语言和文化现象，从日常表达到具有文化敏感性和比喻性的语言。各类别分布如下：

| 类别 | 样本数量 | 难度 |
| --- | --- | --- |
| 问候与日常表达 | 61 | 简单 |
| 宗教与社会敏感度 | 78 | 中等 |
| 意象与比喻义 | 121 | 中等 |
| 礼仪与价值观 | 173 | 中等 |
| 诗歌与创意表达 | 32 | 困难 |
| 历史与文化遗产知识 | 89 | 困难 |
| 语言与方言 | 619 | 困难 |

这种构成使得 Alyah 能够联合评估表层的对话流畅度以及更深层次的文化、语义和语用理解，特别侧重于当前模型仍难以处理的方言特定语言现象。

### 模型评估设置

我们共评估了 **54 个语言模型**，包括 **23 个基础模型**和 **31 个指令微调模型**，涵盖了多种架构和训练范式。其中包括 Jais 和 Allam 等原生阿拉伯语大语言模型，Qwen 和 LLaMA 等对阿拉伯语有强大支持的多语言模型，以及 Fanar 和 AceGPT 等经过适配或区域专用的模型。对于每个模型系列，我们都评估了基础版本和指令微调版本，以了解对齐和指令微调对方言表现的影响。

所有模型都在一致的提示和评分协议下进行评估。评估标准是回答在语义上的正确性以及是否符合阿联酋的语言习惯，而不是与参考答案的字面重合度。这对于方言评估尤为重要，因为方言中可能存在多种有效的表达方式。

对于每个问题类别，我们根据模型的表现凭经验估算难度。大多数模型难以应对的类别被标记为较难，而不同模型系列都能稳定答对的类别则被视为较易。这种方法使得难度评级源于观察到的实际行为，而非仅仅依赖主观标注。

### Alyah（阿联酋方言）评估结果

我们在 **Alyah** 上评估了广泛的当代阿拉伯语和多语言大语言模型，主要指标是多项选择题的**准确率**。评估共涵盖 **53 个模型**，包括 **22 个基础模型**和 **31 个指令微调模型**，横跨原生阿拉伯语、多语言和区域适配系统。

这些结果旨在作为 Alyah 范围内的**参考测量值**，而非所有阿拉伯语基准测试的绝对排名。

#### 基础模型表现

| 模型 | 准确率 (%) |
| --- | --- |
| google/gemma-3-27b-pt | 74.68 |
| tiiuae/Falcon-H1-34B-Base | 73.66 |
| FreedomIntelligence/AceGPT-v2-32B | 67.35 |
| google/gemma-3-4b-pt | 63.17 |
| QCRI/Fanar-1-9B | 62.75 |
| tiiuae/Falcon-H1-7B-Base | 60.78 |
| meta-llama/Llama-3.1-8B | 58.23 |
| Qwen/Qwen3-14B-Base | 57.29 |
| inceptionai/jais-adapted-13b | 56.01 |
| Qwen/Qwen2.5-32B | 53.03 |
| FreedomIntelligence/AceGPT-13B | 50.81 |
| Qwen/Qwen2.5-72B | 47.91 |
| Qwen/Qwen2.5-14B | 46.80 |
| google/gemma-2-2b | 41.86 |
| tiiuae/Falcon3-7B-Base | 41.43 |
| Qwen/Qwen3-8B-Base | 40.75 |
| tiiuae/Falcon-H1-3B-Base | 40.41 |
| Qwen/Qwen2.5-7B | 36.57 |
| Qwen/Qwen2.5-3B | 35.29 |
| meta-llama/Llama-3.2-3B | 35.12 |
| inceptionai/jais-adapted-7b | 33.50 |
| Qwen/Qwen3-4B-Base | 27.45 |

#### 指令微调模型表现

| 模型 | 准确率 (%) |
| --- | --- |
| falcon-h1-arabic-7b-instruct | 82.18 |
| humain-ai/ALLaM-7B-Instruct-preview | 77.24 |
| google/gemma-3-27b-it | 74.68 |
| falcon-h1-arabic-3b-instruct | 74.51 |
| Qwen/Qwen2.5-72B-Instruct | 74.60 |
| CohereForAI/aya-expanse-32b | 73.66 |
| Navid-AI/Yehia-7B-preview | 73.32 |
| FreedomIntelligence/AceGPT-v2-32B-Chat | 72.80 |
| Qwen/Qwen2.5-32B-Instruct | 71.61 |
| tiiuae/Falcon-H1-34B-Instruct | 71.10 |
| meta-llama/Llama-3.3-70B-Instruct | 69.74 |
| QCRI/Fanar-1-9B-Instruct | 69.22 |
| tiiuae/Falcon-H1-7B-Instruct | 65.13 |
| CohereForAI/c4ai-command-r7b-arabic-02-2025 | 64.54 |
| silma-ai/SILMA-9B-Instruct-v1.0 | 63.94 |
| FreedomIntelligence/AceGPT-v2-8B-Chat | 63.43 |
| CohereLabs/aya-expanse-8b | 61.21 |
| yasserrmd/kallamni-2.6b-v1 | 61.13 |
| yasserrmd/kallamni-4b-v1 | 60.70 |
| microsoft/Phi-4-mini-instruct | 58.57 |
| tiiuae/Falcon-H1-3B-Instruct | 57.12 |
| silma-ai/SILMA-Kashif-2B-Instruct-v1.0 | 48.51 |
| Qwen/Qwen2.5-7B-Instruct | 45.44 |
| google/gemma-3-4b-it | 46.12 |
| meta-llama/Llama-3.1-8B-Instruct | 46.29 |
| meta-llama/Llama-3.2-3B-Instruct | 39.64 |
| yasserrmd/kallamni-1.2b-v1 | 37.77 |
| Qwen/Qwen3-4B | 26.26 |
| google/gemma-2-2b-it | 26.00 |
| Qwen/Qwen3-14B | 26.00 |
| Qwen/Qwen3-8B | 25.66 |

### 分析与观察到的趋势

评估结果呈现出几个明显的趋势：

*   **指令微调的优势**：指令微调模型通常优于其对应的基础模型。在涉及对话规范和文化得体回应（即“礼仪与价值观”类别）的问题上，这一点尤为明显。
*   **意象与比喻义的迁移**：模型在测试意象和比喻义的问题上表现较好。这可以归因于模型最初在理解基于现代标准阿拉伯语（MSA）的意象和比喻语言方面具备强大能力，它们能够提取非字面描述的模式，而与具体方言无关。
*   **最困难的领域**：无论模型大小，“语言与方言”以及“问候与日常表达”始终是最困难的类别。这反映了阿联酋方言在书面媒体中的现状——该方言主要用于口语，极少用于书写，因此对受评模型来说较为陌生。
*   **指令微调在特定类别的突破**：相比基础模型，指令微调模型在理解方言方面具有明显优势，这在中小型模型中尤为突出。在“诗歌与创意表达”类别中，大型指令微调模型的表现略好于小型模型。
*   **多语言模型与原生模型的差异**：即使是强大的多语言模型，在 Alyah 最具挑战性的问题上也出现了明显的性能下降，这表明特定方言的语义知识很难仅通过通用的多语言训练获得。
*   **深层文化理解的鸿沟**：虽然原生阿拉伯语模型在具有文化背景的内容上表现更稳健，但它们在各个类别上的表现并不均衡。涉及隐式含义和罕见表达的问题对几乎所有模型来说仍然很困难。这突显了表层方言熟悉度与深层文化理解之间持续存在的差距。
*   **方言能力的维度**：模型在不同类别间的表现差异很大（例如，一个擅长意象和比喻义的模型可能在诗歌或文化遗产问题上表现挣扎），这表明方言能力是多维的，无法用单一分数来全面衡量。
*   **表现最佳的模型**：得分最高的大型模型是 Jais-2-70B，其次是两个小型模型 jais-2-8B 和 ALLaM-7B-instruct，它们均为阿拉伯语指令微调模型。

### 结论与社区影响

该基准测试代表着向更真实、更具文化底蕴的阿拉伯语语言模型评估迈出了一步。通过关注阿联酋方言，我们旨在支持开发能够更好地服务于阿联酋当地社区、机构和用户的模型。除了模型排名之外，该基准测试还旨在作为一个诊断工具，指导未来的数据收集、训练和适配工作。

我们邀请研究人员、从业者和更广泛的社区使用该基准测试，探索结果并分享反馈。社区的投入对于完善数据集、扩大覆盖范围以及确保方言阿拉伯语在大语言模型评估中获得应有的重视至关重要。

### 引用

```bibtex
@misc{emirati_dialect_benchmark_2026,
title = {Alyah: An Emirati Dialect Benchmark for Evaluating Arabic Large Language Models},
author={Omar Alkaabi and Ahmed Alzubaidi and Hamza Alobeidli and Shaikha Alsuwaidi and Mohammed Alyafeai and Leen AlQadi and Basma El Amel Boussaha and Hakim Hacid},
year = {2026},
month = {january},
}
```

## 相关文档

- [[01-博客/Hugging Face/社区评估：打破黑盒排行榜，将评估权交还社区.md|社区评估：打破黑盒排行榜，将评估权交还社区]]；关联理由：观点一致；说明：两文都指出单一榜单分数不足以反映真实能力，强调评测需要更可解释、可复核。
- [[01-博客/Hugging Face/RTEB：检索评测新标准.md|RTEB：检索评测新标准]]；关联理由：延伸思考；说明：两文都通过新基准弥补既有评测盲区，分别聚焦阿联酋方言理解与检索泛化能力。

## 关联主题

- [[00-元语/benchmark]]
- [[00-元语/evals]]
- [[00-元语/llm]]
