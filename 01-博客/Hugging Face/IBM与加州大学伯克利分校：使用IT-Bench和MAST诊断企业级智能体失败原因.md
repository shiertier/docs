# IBM与加州大学伯克利分校：使用IT-Bench和MAST诊断企业级智能体失败原因

## 文档信息
- 来源：https://huggingface.co/blog/ibm-research/itbenchandmast

## 摘要
### 1) 一句话总结
IBM与加州大学伯克利分校利用MAST故障分类法分析了ITBench基准测试，揭示了不同大语言模型在企业IT自动化智能体中失败的具体原因（如错误验证、终止失败等），并提出了从架构层面解决这些致命缺陷的工程策略。

### 2) 核心要点
*   **打破“黑盒”评估：** 传统的基准测试仅提供成功率指标，而MAST（多智能体系统故障分类法）将非结构化的执行日志转化为14种结构化的故障模式，明确指出智能体“哪里坏了”以及“为什么坏了”。
*   **实验数据与模型对比：** 研究标注了310个ITBench SRE真实轨迹，对比了三种模型：Gemini-3-Flash（平均召回率75.5%）、Kimi-K2（28.6%）和GPT-OSS-120B（12.4%）。
*   **前沿模型（Gemini-3-Flash）表现为孤立故障：** 平均每个失败轨迹仅有2.6种故障模式，主要瓶颈是过度自信，常在没有核实真实情况的前提下“宣布胜利”。
*   **开源大模型（GPT-OSS-120B）表现为级联故障：** 平均每个失败轨迹高达5.3种故障模式，24%的轨迹会丢失对话历史，94%的轨迹出现推理与行动脱节，极易因早期错误导致彻底脱轨。
*   **Kimi-K2 面临“终止危机”与“执行鸿沟”：** 经常在解决问题前夕退出或陷入无限循环（过早终止增加46%），且92%的失败案例中出现了行动与推理不匹配（想对了但做错了）。
*   **区分致命与非致命故障：** 步骤重复（FM-1.3）等属于系统可容忍的良性缺陷；而错误验证（FM-3.3）、未意识到终止条件（FM-1.5）和丢失对话历史（FM-1.4）则是导致任务失败的致命缺陷。
*   **针对前沿模型的修复策略：** 必须将验证过程外部化，绝不能让LLM“自己批改作业”，退出前需强制要求提供确凿的工具证据（如警报清除状态）。
*   **针对终止与循环的修复策略：** 应将终止和循环控制置于模型之外，通过实现有限状态机（FSM）或明确的停止条件来防止智能体陷入死循环。
*   **架构干预优于提示词工程：** 实验表明，针对内存等故障单纯调整提示词最多仅提升15.6%的性能，而引入新智能体（如总结智能体）或状态机等架构级干预可带来高达53%的性能提升。

### 3) 风险/不足
*   **智能体自我验证风险：** 允许智能体自行验证结果会导致极高的“错误验证”（FM-3.3）发生率，这是所有模型中最强的失败预测指标。
*   **提示词工程的局限性：** 盲目调整提示词通常是“解决一个问题又制造另一个问题”，无法从根本上修复复杂的系统性故障。
*   **上下文污染风险：** 在较弱或开源模型中，运行早期出现的微小推理偏差极易污染上下文，引发不断复合的幻觉，最终导致任务完全脱轨。

## 正文
IBM Research 与加州大学伯克利分校合作，研究了在真实的 IT 自动化场景中（如事件排查、日志/指标查询以及长周期工具循环中的 Kubernetes 操作），智能体大语言模型（LLM）系统是如何失效的。

通常，基准测试会将性能简化为一个单一的数字，只告诉你智能体是否失败，却从不说明原因。为了解决这个“黑盒”问题，我们应用了 MAST（多智能体系统故障分类法），这是一种用于诊断智能体可靠性的新兴方法。通过利用 MAST 分析 ITBench（针对 SRE、安全和 FinOps 自动化的行业基准），我们将原始执行轨迹转化为结构化的故障特征，揭示了究竟是什么出了问题以及如何修复。我们标注了 310 个 ITBench SRE 轨迹，涵盖三种不同的模型类别：Gemini-3-Flash、Kimi-K2 和 GPT-OSS-120B。

**核心发现：**
*   **前沿模型（如 Gemini-3-Flash）的失败往往是“干净利落”的**（每个轨迹 2.6 种故障模式），通常遇到的是孤立的瓶颈（如验证环节）。而大型开源模型（如 GPT-OSS-120B）则会遭遇级联故障模式（每个轨迹 5.3 种故障模式）。在运行早期出现的一次推理偏差会污染上下文，导致不断复合的幻觉。
*   在所有模型中，**最强的失败预测指标是 FM-3.3（错误验证）**。智能体总是习惯在没有核实真实情况的前提下“宣布胜利”。
*   **Kimi-K2 难以识别任务何时完成**。它在“过早终止”（+46%）和“未意识到终止条件”（+43%）方面出现了巨大的峰值，经常在解决问题前夕退出或陷入无限循环。

**构建智能体时的核心启示：**
*   **对于 Gemini 等前沿模型：将验证过程外部化。** 绝不要让 LLM 自己批改自己的作业。在退出前必须要求提供确凿的工具证据。
*   **将终止和循环控制置于模型之外：** 终止问题是常见的致命因素（FM-1.5）。应为重复的工具调用/操作添加明确的停止条件和循环检测器，或实现有限状态机（FSM）。
*   **当输入模糊时，强制要求澄清或保持只读：** 澄清失败（FM-2.2）是较小模型失败的主要驱动因素。在你的智能体图（Agent Graph）中，应将“处理模糊性”作为一个一等分支。

如果你正在为企业 IT 工作流构建智能体，这正是你所需要的评估方式：不仅仅是问“它通过了吗？”，而是问“哪里坏了？为什么坏了？哪种干预措施最有效？”

### 智能体基准测试的“黑盒”问题

像 ITBench 这样的基准测试正在成为衡量高风险 IT 自动化任务中智能体性能的标准。在 ITBench 中，智能体扮演站点可靠性工程师（SRE）或安全分析师的角色，负责诊断 Kubernetes 故障、修补漏洞或管理生产环境中的云成本。

这些基准测试主要使用成功率作为评估指标。然而，这个指标不足以用来构建健壮的系统。知道一个智能体系统在 ITBench 上取得了 14% 的成功率，只告诉我们它失败了，但没有说明原因：**是因为它忘记了上下文？是因为它幻觉出了一条命令？还是因为它根本没有终止运行？**

如果没有全面的方法来诊断这些故障，开发者只能靠猜测，通常会盲目地调整提示词，结果解决了一个问题又制造了另一个问题。

为了分析复杂智能体系统的故障模式，我们开发了 **MAST（多智能体系统故障分类法）** 作为新标准。MAST 基于对七种不同框架下 1600 多个轨迹的严格分析，为智能体故障提供了标准化的分类，从而打破了基准测试的不透明性。

MAST 将非结构化的执行日志转化为结构化的“故障向量”，涵盖三大核心类别下的 14 种不同模式：

*   **FC1：系统设计问题（“骨架”）**
    *   此类故障源于智能体的架构和角色定义。
    *   *示例：* **FM-1.3 步骤重复**（陷入循环）、**FM-1.4 丢失对话历史**（内存泄漏）、**FM-1.5 未意识到终止**（未能停止）。
*   **FC2：智能体间对齐问题（“通信”）**
    *   此类故障发生在运行时，源于智能体之间或智能体与环境之间的交互方式。
    *   *示例：* **FM-2.2 未能要求澄清**（靠假设而非询问）、**FM-2.3 任务脱轨**（偏离主题）。
*   **FC3：任务验证问题（“质量控制”）**
    *   智能体输出质量保证方面的故障。
    *   *示例：* **FM-3.1 过早终止**（过早放弃）、**FM-3.3 错误验证**（幻觉出成功的结论）。

### 实验：诊断 ITBench 智能体

我们将 MAST 应用于 ITBench（一个涵盖 SRE、安全/合规和 FinOps 的流行 IT 自动化评估套件），以压力测试其在智能体评估中的实用性，并获取有关故障模式的洞察。

我们标注了 310 个由基于 Codex 构建的 SRE 智能体在真实环境中生成的 ITBench SRE 执行轨迹。这些轨迹捕捉了智能体与其工具之间在三种不同能力层级的模型（Gemini-3-Flash、Kimi-K2 和 GPT-OSS-120B）下的自然语言交互。这使我们能够超越简单的成功指标，深入调查导致这些结果的特定故障特征。我们使用召回率（Recall）作为指标，因为模型设计上最多只输出 3-5 个结果，且 SRE 更看重召回率而非 F-1 分数。

*   **Gemini-3-Flash：** 100 个轨迹（平均召回率 75.5%）
*   **Kimi-K2：** 105 个轨迹（平均召回率 28.6%）
*   **GPT-OSS-120B：** 105 个轨迹（平均召回率 12.4%）

### 发现一：前沿模型表现为孤立故障，开源模型表现为复合故障

当我们检查失败的轨迹时，三种模型之间呈现出明显的复杂性层级。这可以通过每次失败运行中观察到的不同故障模式的数量来衡量：

*   **Gemini-3-Flash：** 每个失败轨迹 2.6 种故障模式
*   **Kimi-K2：** 每个失败轨迹 4.7 种故障模式
*   **GPT-OSS-120B：** 每个失败轨迹 5.3 种故障模式

故障模式密度的差异揭示了这些系统崩溃方式的根本不同。Gemini-3-Flash 表现出“外科手术式”的故障特征。即使在不成功的运行中，它也保持着高度的内部连贯性，通常由于单一的孤立故障（如错误的验证步骤）而失败。这些故障非常精确，诊断起来要容易得多。

在光谱的另一端，GPT-OSS-120B 遭受的是级联崩溃。在这些轨迹中，错误往往会随着时间的推移而复合。早期过程中的微小推理偏差通常会导致偏离任务规范，进而引发智能体的彻底脱轨。Kimi-K2 处于中间地带，其故障比前沿模型更频繁、更复杂，但尚未达到 120B 开源权重模型那种系统性的不稳定性。

这一发现的意义在于，较高的成功率通常伴随着孤立的故障。同时出现较少问题的系统更具可预测性，也更容易通过有针对性的工程干预来改进。

### 发现二：“非致命”与“致命”故障

MAST 带来的最关键洞察或许是区分了系统可以*容忍*的故障与对下游任务成功*致命*的故障。通过比较**成功轨迹**和**失败轨迹**中故障模式的分布，我们可以将它们分为以下几类：

#### “非致命”（良性）缺陷
在所有三种模型中，某些故障模式即使在最终成功的运行中也频繁出现。这些通常是结构性的摩擦，而不是终端错误。

*   **FM-1.3 步骤重复：** 这种模式出现在超过 90% 的 Kimi-K2 成功运行中。在 SRE 领域，迭代通常是必要的。智能体可能会多次查询同一个指标，以验证服务是否稳定或修复是否生效。Gemini-3-Flash 在其失败轨迹中反而表现出较少的重复，这表明它有时失败是因为迭代不够。
*   **FM-1.1 不遵守任务规范：** 智能体经常偏离严格的工具格式或顺序指令，但仍能设法找出正确的根本原因。

这正是 MAST 彰显价值的地方。它允许我们忽略故障排查中经常出现的良性故障（如重复），而将注意力集中在导致运行终止的致命故障上。

#### “致命”缺陷
某些行为强烈地将成功与失败区分开来。当这些模式出现时，成功结果的概率会急剧下降。最突出的例子是 **FM-3.3（错误验证）**。与成功轨迹相比，这种模式在 Gemini-3-Flash 的失败轨迹中增加了 52%。其他突出的故障模式包括 1.5（未意识到终止条件）和 2.6（推理与行动不匹配）。

如果发生这些情况，运行很可能已经失败；这指导从业者在系统中的智能体之间以及多轮交互中开发健壮的上下文管理策略。

### 案例分析

#### Gemini-3-Flash（果断但过度自信）
Gemini-3-Flash 非常高效，但其主要瓶颈在于倾向于在没有严格证据的情况下假设成功。它的故障特征主要表现为验证错误的大幅增加。它经常识别出正确的信号，但在将其与真实情况交叉验证之前就终止了。为了解决这个问题，开发者应该实现一个外部验证网关。通过要求提供基于工具的证据（如清除的警报或健康的指标阈值）才允许智能体退出，我们可以缓解该模型固有的过度自信。

*   **修复方案：** 要在 ITBench 上改进 Gemini-3-Flash，提示词工程的作用不大。我们在 NeurIPS 2025 论文中的实验表明，通过针对内存相关故障进行提示词工程等手动干预，最多只能获得约 15.6% 的性能提升。而在之前关于 MAST 的研究中，我们展示了通过引入新的智能体（如**总结智能体**来提醒其他智能体当前情况并持续增强其状态，以修复 FM-1.4），或引入上下文管理机制（如更严格的**状态机**来强制终止以修复 FM-1.5），我们可以获得高达 53% 的性能提升，因为这些方法解决了系统更根本的问题。

#### Kimi-K2（终止危机）
虽然终止混乱（FM-3.1 和 FM-1.5）是 Kimi-K2 普遍存在的故障模式，但其失败轨迹的典型特征是普遍存在的**行动与推理不匹配（FM-2.6）**，这一模式出现在惊人的 **92% 的失败案例**中。

*   **执行鸿沟：** 虽然其内部推理的部分通常是准确的，但它遭受了高达 92% 的 **FM-2.6（行动与推理不匹配）** 故障率。它经常识别出正确的下一步，但随后却执行了一个多余或不相关的命令。
*   **元循环陷阱：** 大约 25% 的失败轨迹涉及 **FM-2.3（任务脱轨）**。当工具调用返回一个轻微错误时，智能体通常会放弃主要事件，进入一个调试其自身调查脚本的循环。

Kimi-K2 是一个“过度思考”模型的典型例子，它的推理链通常太长，却在执行环节失败。

#### GPT-OSS-120B
GPT-OSS-120B 表现出该队列中最不稳定的故障特征。该模型在每个失败轨迹中平均表现出 5.3 种不同的故障模式，表明其根本无法维持内部状态。

*   **丢失对话历史（FM-1.4）：** 这是 120B 模型独有的致命缺陷。它在 **24%** 的轨迹中丢失了对话历史，而 Gemini-3-Flash 的内存丢失率为零，Kimi-K2 仅为 7%。随着 SRE 轨迹长度的增加，GPT-OSS-120B 实际上“忘记”了它最初正在排查的警报，导致任务彻底脱轨。
*   **推理脱节（FM-2.6）：** 惊人的 **94%** 的轨迹显示出推理与行动的脱钩。它描述了一个正确的计划但随后执行了完全不相关或多余的工具调用的可能性，几乎是 Gemini（31%）的 3 倍。

### 另一种（更有用的）视角：致命与非致命故障

总而言之，MAST 允许你将故障模式分为两类：

**可恢复/结构性故障（即使在成功轨迹中也会出现）**
这些是非致命的故障，系统可以从中恢复并成功完成任务。
*   **FM-1.3 步骤重复**
*   **FM-3.3 错误验证**（重要细节：系统*确实*进行了验证；只是验证得很糟糕）
*   **FM-2.6 推理与行动不匹配**（经常出现，但不总是决定性的）

**致命/决定性故障（与失败轨迹强烈相关）**
这些是系统通常无法从中恢复的故障。
*   **FM-1.5 未意识到终止条件**
*   **FM-3.1 过早终止**
*   **FM-1.4 丢失对话历史**
*   **FM-2.3 任务脱轨**（罕见，但一旦出现就极具诊断意义）
*   **FM-2.2 未能要求澄清**（特别是在 Granite/Llama 模型中）

这就是“更深层理解”的意义所在：**两个模型在小样本上可能具有相同的成功率，但失败的原因却截然不同——这需要完全不同的修复方法。**

### 结论

MAST 是一种检查智能体系统轨迹以识别细粒度故障类型的工具，能够为系统开发和调试提供支持。在这篇博客中，我们展示了通过将 MAST 应用于 ITBench，我们从一般性的观察（“开源模型表现挣扎”）转向了具体的工程路线图，帮助提高依赖这些模型的智能体系统的性能，例如：

1.  **对于 Gemini-3-Flash：** 验证失败（**FM-3.3**）是这类“外科手术式”模型最常见的致命故障。绝不允许智能体自行终止；在认为运行成功之前，必须要求提供硬性的、由工具介导的证据（例如 AlertManager 警报清除或 K8s 状态改变）。
2.  **对于 Kimi-K2：** 使用确定性的状态机来修复该模型在识别任务完成方面的频繁挣扎。该模型的推理链可能过长且难以终止，因此对何时结束进行更严格的控制将带来显著收益。
3.  **对于 GPT-OSS-120B：** 当微小的推理不匹配（**FM-2.6**）污染任务历史时，就会发生系统性崩溃。应实施激进的上下文清理和早期错误检测，以确保微小的不对齐不会复合演变成彻底的脱轨。

**相关资源：**
*   **IT-Bench 论文：** https://arxiv.org/pdf/2502.05352
*   **IT-Bench 代码：** https://github.com/itbench-hub/ITBench
*   **MAST 论文：** https://arxiv.org/abs/2503.13657
*   **MAST 代码：** https://github.com/multi-agent-systems-failure-taxonomy/MAST
*   **MAST 数据集：** https://huggingface.co/datasets/mcemri/MAST-Data

## 关联主题
- [[00-元语/Agent]]
- [[00-元语/benchmark]]
- [[00-元语/evals]]
- [[00-元语/llm]]
- [[00-元语/memory]]
- [[00-元语/observability]]
