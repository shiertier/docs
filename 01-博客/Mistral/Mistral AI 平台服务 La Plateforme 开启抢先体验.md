# Mistral AI 平台服务 La Plateforme 开启抢先体验

## 文档信息
- 来源：https://mistral.ai/news/la-plateforme

## 摘要
**一句话总结**
Mistral AI 正式开放其平台服务 La Plateforme 的 Beta 测试权限，首批提供三个具备不同性能与价格优势的文本生成端点以及一个嵌入端点。

**关键要点**
*   **平台服务概览**：La Plateforme 首批开放 3 个文本生成聊天端点（tiny, small, medium）和 1 个嵌入端点（embed）。
*   **Mistral-tiny**：最具性价比的端点，基于 Mistral 7B Instruct v0.2 模型，仅支持英语，MT-Bench 得分为 7.6（该模型已开放下载）。
*   **Mistral-small**：基于最新的 Mixtral 8x7B 模型，精通英、法、意、德、西五种语言及代码，MT-Bench 得分为 8.3。
*   **Mistral-medium**：质量最高的原型模型端点，同样支持上述五种语言及代码，MT-Bench 得分为 8.6。
*   **Mistral-embed**：专为检索设计的嵌入端点，提供 1024 嵌入维度，MTEB 检索得分为 55.26。
*   **模型训练**：模型在开放网络数据上预训练，并使用高效微调和直接偏好优化（DPO）等技术在标注数据上进行指令微调与对齐。
*   **API 与接入**：API 遵循主流聊天接口规范，提供 Python 和 Javascript 客户端库；支持通过系统提示词（system prompt）进行高级别的输出控制。
*   **技术合作**：与 NVIDIA 合作整合了 TensorRT-LLM 和 Triton，使稀疏混合专家模型能够兼容 TRT-LLM。

**风险与不足**
*   平台目前正处于稳定期并向完全自助服务过渡，官方明确表示在此过程中可能会遇到一些不完善之处。

## 正文
我们的首批 AI 端点现已开放抢先体验。Mistral AI 致力于为开发者提供最强大的开源生成式模型，以及在生产环境中高效部署和定制这些模型的方法。

今天，我们正式开放首批平台服务的 Beta 测试权限。我们从最基础的服务开始：La Plateforme 提供了三个用于根据文本指令生成文本的聊天端点，以及一个嵌入（embedding）端点。每个端点都提供了不同的性能与价格权衡方案。

### 模型训练与对齐

我们提供的是经过指令微调（instructed）的模型版本。我们致力于整合最有效的对齐技术（如高效微调、直接偏好优化），以打造易于控制且使用体验良好的模型。我们在从开放网络提取的数据上对模型进行预训练，并根据标注数据进行指令微调。

### 提供的端点服务

前两个端点（mistral-tiny 和 mistral-small）目前使用的是我们已发布的两个开源模型；第三个端点（mistral-medium）则使用了一个性能更高的原型模型，我们正在部署环境中对其进行测试。

*   **Mistral-tiny**：这是我们最具性价比的端点，目前提供 Mistral 7B Instruct v0.2（Mistral 7B Instruct 的一个全新次要版本）。该端点仅支持英语，在 MT-Bench 上获得了 7.6 分。该指令模型目前已开放下载。
*   **Mistral-small**：该端点目前提供我们最新的模型 Mixtral 8x7B。它精通英语、法语、意大利语、德语、西班牙语以及代码，在 MT-Bench 上获得了 8.3 分。
*   **Mistral-medium**：这是我们质量最高的端点，目前提供一个原型模型。根据标准基准测试，该模型是目前可用的顶级服务模型之一。它同样精通英语、法语、意大利语、德语、西班牙语以及代码，在 MT-Bench 上获得了 8.6 分。我们已将该基础模型与 Mistral-small 及竞争对手的端点进行了性能对比。
*   **Mistral-embed**：这是我们的嵌入（embedding）端点，提供一个具有 1024 嵌入维度的模型。我们的嵌入模型在设计时充分考虑了检索功能，在 MTEB 上获得了 55.26 的检索分数。

### API 特性与接入方式

我们的 API 遵循了目前流行的聊天接口规范。我们提供 Python 和 Javascript 客户端库以便开发者查询我们的端点。对于有严格审核要求的应用程序，我们的端点允许用户提供系统提示词（system prompt），以便对模型输出设置更高级别的控制。

随着我们逐步提升服务容量，从今天起，任何人都可以注册使用我们的 API。我们的业务团队可以帮助评估您的需求并加速接入。在我们稳定平台并迈向完全自助服务的过程中，可能会遇到一些不完善之处，敬请谅解。

### 特别鸣谢

我们非常感谢 NVIDIA 在整合 TensorRT-LLM 和 Triton 方面给予的支持，并感谢他们与我们并肩合作，使稀疏混合专家模型（sparse mixture of experts）能够兼容 TRT-LLM。

AI 的下一篇章属于你。

## 关联主题
- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/sdk]]
