---
title: "推出 EVMbench：评估 AI 智能体在区块链安全中的能力"

来源: "https://openai.com/index/introducing-evmbench"
发布日期: "2026-02-18"
---

## 摘要

### 1) 一句话总结
EVMbench 是一个包含 120 个真实漏洞的基准测试，旨在评估 AI 智能体在区块链环境中检测、修复和利用智能合约漏洞的能力。

### 2) 关键要点
*   **项目背景与数据**：与 Paradigm 合作推出，包含从 40 次审计中挑选的 120 个高危漏洞，涵盖公开审计竞赛及 Tempo 区块链的支付场景。
*   **三大评估模式**：
    *   **检测（Detect）**：审计代码库，根据真实漏洞召回率评分。
    *   **修复（Patch）**：修改合约，要求在消除漏洞的同时保留预期功能。
    *   **利用（Exploit）**：在沙盒环境中执行端到端资金窃取，通过交易重放和链上验证评分。
*   **测试基础设施**：开发了基于 Rust 的测试工具，在隔离的本地 Anvil 环境中运行（不涉及真实网络），所有测试漏洞均为历史公开记录。
*   **模型表现数据**：在“利用”模式下，GPT-5.3-Codex 获得 72.2% 的分数，较半年前发布的 GPT-5（31.9%）有显著提升。
*   **模型行为差异**：智能体在目标明确的“利用”任务中表现最佳；在“检测”任务中容易在发现单一问题后停止；在“修复”任务中难以兼顾消除漏洞与保持功能完整性。
*   **安全防御投资**：扩大安全研究智能体 Aardvark 的内测范围，并承诺提供 1000 万美元的 API 额度，用于加速开源软件和关键基础设施的网络防御。
*   **开源决定**：将公开发布 EVMbench 的任务、工具和评估框架，以支持持续的研究。

### 3) 风险与不足
*   **难度代表性不足**：基准测试的难度不能完全代表现实世界，广泛部署的加密合约通常经过更严格的审查，更难被利用。
*   **检测评分系统不完善**：当智能体在“检测”模式下发现人类审计员未标记的额外问题时，目前缺乏可靠的方法来判定其为真实漏洞还是误报。
*   **利用模式的结构性限制**：交易为顺序重放，无法测试依赖精确时间机制的行为；测试环境为干净的本地 Anvil 实例而非主网分叉；目前仅支持单链环境。

## 正文

智能合约日常保护着超过 1000 亿美元的开源加密资产。随着 AI 智能体在阅读、编写和执行代码方面的能力不断提升，在具有经济意义的环境中衡量它们的能力，并鼓励防御性地使用 AI 系统来审计和加固已部署的合约，变得越来越重要。

为此，我们推出了 EVMbench，旨在通过评估 AI 智能体在区块链环境中检测、修复和利用漏洞的能力，让智能合约变得更加安全。

### 什么是 EVMbench？

我们与 Paradigm 合作推出了 EVMbench 基准测试，用于评估 AI 智能体检测、修复和利用高危智能合约漏洞的能力。

EVMbench 包含了从 40 次审计中精心挑选的 120 个漏洞，其中大部分来自公开的代码审计竞赛。此外，基准测试还包含了来自 Tempo 区块链（一个专为通过稳定币实现高吞吐量、低成本支付而设计的 L1 网络）安全审计过程中的几个漏洞场景。这些场景将基准测试扩展到了面向支付的智能合约代码领域，帮助其扎根于具有新兴实用重要性的领域。

### 任务环境与构建方法

为了创建任务环境，我们调整了现有的概念验证（PoC）漏洞利用测试和部署脚本；在没有现有脚本的情况下，我们进行了手动编写。

*   **修复模式构建**：我们确保漏洞可被利用，且可以在不引入破坏编译的更改的情况下得到缓解，以免破坏测试设置。
*   **利用模式构建**：我们编写了自定义评分器，并对环境进行了红队测试，以发现并修补智能体可能用来欺骗评分器的方法。

除了借助 Paradigm 的领域专业知识进行质量控制外，我们还使用了自动化的任务审计智能体来提高环境的可靠性。

### 三大能力评估模式

EVMbench 评估以下三种能力模式：

*   **检测（Detect）**：智能体审计智能合约代码库，系统根据其对真实漏洞的召回率及相关的审计奖励进行评分。
*   **修复（Patch）**：智能体修改存在漏洞的合约，必须在消除漏洞利用可能性的同时保留预期功能，这通过自动化测试和漏洞利用检查来验证。
*   **利用（Exploit）**：智能体在沙盒区块链环境中对已部署的合约执行端到端的资金窃取攻击，系统通过交易重放和链上验证进行程序化评分。

为了支持客观且可重复的评估，我们开发了一个基于 Rust 的测试工具（harness），用于部署合约、确定性地重放智能体交易，并限制不安全的 RPC 方法。漏洞利用任务在隔离的本地 Anvil 环境中运行，而非真实网络，且所有漏洞均为历史遗留且公开记录的。

### 评估结果与模型行为差异

我们在所有三种模式下对前沿智能体进行了评估。在**“利用”**模式下，通过 Codex CLI 运行的 GPT-5.3-Codex 获得了 72.2% 的分数。与仅在六个月前发布的 GPT-5（得分为 31.9%）相比，这代表了显著的提升。然而，检测的召回率和修复的成功率仍未达到全面覆盖，很大一部分漏洞对智能体来说仍然难以发现和修复。

EVMbench 还揭示了模型在不同任务中行为的有趣差异：
*   **利用任务表现最佳**：目标非常明确，即不断迭代直到资金被抽干。
*   **检测任务表现较弱**：智能体有时在发现一个问题后就会停止，而不是对代码库进行详尽的审计。
*   **修复任务面临挑战**：在消除微妙漏洞的同时保持完整功能仍然是一项挑战。

### 局限性

*   **难度代表性不足**：EVMbench 并不能代表现实世界智能合约安全的全部难度。虽然包含的漏洞真实且严重，但许多被广泛部署和使用的加密合约经历了更严格的审查，可能更难被利用。
*   **评分系统不完美**：在“检测”模式下，我们检查智能体是否发现了人类审计员识别出的相同漏洞。如果智能体发现了额外的问题，我们目前没有可靠的方法来确定它们是人类遗漏的真实漏洞还是误报。
*   **“利用”模式的结构性限制**：交易在评分容器中是顺序重放的，因此依赖精确时间机制的行为不在测试范围内。链状态是一个干净的本地 Anvil 实例，而不是主网的分叉，且目前仅支持单链环境（有时需要使用模拟合约代替主网部署）。

### 意义与未来展望

智能合约保护着数十亿美元的资产，AI 智能体可能会对攻击者和防御者产生变革性影响。在这一领域衡量模型能力有助于追踪新兴的网络风险，并凸显了防御性使用 AI 系统来审计和加固合约的重要性。EVMbench 既是一个衡量工具，也是行动的号召：随着智能体的进步，开发者和安全研究人员将 AI 辅助审计纳入其工作流程变得越来越重要。

近几个月来，模型在网络安全任务上的表现取得了显著进步。与此同时，我们正在准备加强网络安全防护措施，以支持防御性使用和更广泛的生态系统弹性。因为网络安全本质上具有双重用途，我们正在采取基于证据的迭代方法，在加速防御者发现和修复漏洞能力的同时，减缓滥用风险。我们的缓解措施包括安全培训、自动监控、高级功能的可信访问，以及包含威胁情报的执行管道。

我们正在投资生态系统安全保障，例如扩大我们的安全研究智能体 Aardvark 的内测范围，并与开源维护者合作，为广泛使用的项目提供免费的代码库扫描。

基于 2023 年启动的网络安全资助计划，我们还将承诺提供 1000 万美元的 API 额度，利用我们最强大的模型加速网络防御，特别是针对开源软件和关键基础设施系统。从事善意安全研究的组织可以申请 API 额度及支持。

最后，我们将发布 EVMbench 的任务、工具和评估框架，以支持对衡量和管理新兴 AI 网络能力的持续研究。

## 关联主题

- [[00-元语/OpenAI]]
- [[00-元语/AI]]
- [[00-元语/Agent]]
- [[00-元语/blockchain]]
- [[00-元语/security]]
- [[00-元语/evals]]
- [[00-元语/benchmark]]
