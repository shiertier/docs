# 让 AI 惠及全球每一个人：我们的本地化方法

## 文档信息
- 来源：https://openai.com/index/our-approach-to-localization
- 发布日期：2025-09-12

## 摘要
**1) 一句话总结**
OpenAI 推出“OpenAI 助力国家”倡议，旨在遵守《模型规范》与安全红线的前提下，协助各国打造符合当地语言、法律与文化的本地化“主权 AI”。

**2) 核心要点**
*   **主权 AI 需求**：AI 正成为关键国家基础设施，各国政府希望基于现有前沿模型构建适应本地环境的“主权 AI”，而非仅仅获取翻译版本的系统。
*   **“OpenAI 助力国家”倡议**：致力于打造本地化 AI 系统，使其既符合当地需求，又能受益于全球领先的前沿模型。
*   **爱沙尼亚试点项目**：作为 ChatGPT Edu 项目的一部分，目前正在爱沙尼亚试点融入当地课程体系与教学方法的本地化版本 ChatGPT。
*   **《模型规范》约束**：通过公开的《模型规范》界定模型行为准则，明确规定在所有部署地区中哪些内容可更改、哪些不可更改。
*   **坚守安全红线**：严禁模型被用于暴力、大规模杀伤性武器、恐怖主义、迫害、大规模监控、操纵公众或破坏公民进程，并严格保护用户隐私。
*   **坚持客观视角**：本地化和定制化不能凌驾于《模型规范》之上；本地化可调整语言或语气，但绝不能改变事实的实质内容或平衡性。
*   **内容审查透明度**：因法律要求而省略的内容或新增的信息，将在每次回复中向用户透明标示（说明移除类型及原因，但不披露被屏蔽内容本身）。

**3) 风险与不足**
*   **技术能力差距**：目前全球仅有少数国家具备自主开发前沿 AI 模型的能力。
*   **本地化适配挑战**：对于大多数国家而言，面临的主要挑战并非如何从零开始构建模型，而是如何调整现有的最佳 AI 以适应其特定的本地环境。

## 正文
OpenAI 的使命是确保通用人工智能（AGI）造福全人类。为了实现这一目标，我们需要深入世界各地，满足人们的实际需求。

如今，人工智能越来越被视为与电力同等重要的关键国家基础设施。全球各地的政府和机构都希望通过获取最强大的系统，确保其公民和经济能够从 AI 时代中获益。

### 本地化与主权 AI 的需求

要让 AI 兑现其承诺，它必须具备本地相关性。这意味着 AI 需要使用当地语言和口音进行交流，遵守当地法律，并反映当地的文化规范与价值观。

然而，目前只有少数国家有能力自主开发前沿 AI 模型。对于大多数国家而言，面临的挑战并非如何从零开始构建模型，而是如何调整现有的最佳 AI，使其适应特定的环境。这也是我们不断从各国政府那里听到的诉求：他们希望与我们共同构建“主权 AI”，而不仅仅是获得一个翻译成当地语言的系统。

### “OpenAI 助力国家”倡议与试点

通过“OpenAI 助力国家（OpenAI for Countries）”倡议，我们一直在探索本地化在实践中的运作方式。我们的目标是打造本地化的 AI 系统，同时让其继续受益于全球领先的前沿模型。

目前，作为 ChatGPT Edu 项目的一部分，我们正在爱沙尼亚为学生试点本地化版本的 ChatGPT，该版本融入了当地的课程体系和教学方法。此外，我们也在与其他国家探索本地化的试点工作。作为我们对 AI 研发和部署透明度承诺的一部分，我们将分享更多关于本地化运作方式的细节。

### 模型规范与红线原则

我们的《模型规范》（Model Spec）是一份公开文档，规定了我们期望模型表现出的行为准则。我们训练模型遵循该规范，并通过整合全球各地团队的反馈，以全公司协作的方式不断对其进行完善。该规范涵盖了模型使用的方方面面，从 ChatGPT 到开发者在我们的平台上构建的体验，再到其他应用场景。这些规则适用于我们模型部署的任何地方，明确界定了哪些可以更改、哪些不能更改，并体现了我们对更改保持透明的承诺。

《模型规范》包含了适用于所有部署（包括“OpenAI 助力国家”项目）的“红线原则”。在这些原则中，我们强调“人类安全和人权对 OpenAI 的使命至关重要”，并明确指出：

*   我们绝不允许我们的模型被用于促成严重的伤害行为，如暴力、大规模杀伤性武器、恐怖主义、迫害或大规模监控。
*   我们绝不允许我们的模型被用于针对性或规模化的排斥、操纵、破坏人类自主性或削弱公众对公民进程的参与。
*   我们致力于在个人与 AI 的互动中保护其隐私。

### 第一方体验的约束与透明度

当 OpenAI 直接向消费者提供如 ChatGPT 这样的第一方体验时，我们还承诺做到以下几点：

*   人们应该能够轻松地从我们的模型中获取值得信赖的、涉及安全关键信息的解答。
*   定制化、个性化和本地化绝不能凌驾于《模型规范》中的约束性规则之上。这包括“客观视角”原则，即本地化可能会影响语言或语气，但绝不能改变所呈现事实的实质内容或平衡性。
*   人们应该对我们模型行为背后的重要规则和原因享有透明度。例如，任何因法律要求而省略的内容，都将在每次模型回复中向用户透明地标示出来，说明被移除信息的类型及其移除原因，但不会披露被屏蔽的内容本身。同样，任何新增的信息也会被透明地标识出来。

随着我们通过“OpenAI 助力国家”倡议不断探索本地化和主权 AI，我们承诺将继续分享我们的经验与发现，并以透明的方式不断改进我们的方法。

## 关联主题
- [[00-元语/OpenAI]]
- [[00-元语/AI]]
- [[00-元语/ChatGPT]]
- [[00-元语/alignment]]
- [[00-元语/compliance]]
