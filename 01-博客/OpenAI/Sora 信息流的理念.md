---
title: "Sora 信息流的理念"

来源: "https://openai.com/index/sora-feed-philosophy"
发布日期: "2026-02-03"
---

## 摘要

**1) 一句话总结**
Sora 信息流旨在通过可控的个性化推荐机制和多层安全护栏，在保障内容安全的同时激发用户创造力并促进人际连接。

**2) 关键要点**
*   **核心原则**：信息流设计侧重于鼓励主动创造而非被动滑动，优先展示具有连接性的内容（如 Cameo 互动），并提供可引导的排名系统。
*   **推荐信号**：个性化推荐算法主要基于五类信号：Sora 站内活动（含大致位置/IP）、ChatGPT 数据（用户可随时关闭）、内容互动数据（观看、点赞、混剪等）、作者数据（粉丝数、过往互动）以及安全信号。
*   **家长控制**：家长可通过 ChatGPT 的家长控制功能，为青少年关闭信息流的个性化推荐，并管理/限制连续滑动。
*   **内容违规处理**：严格执行《全球使用政策》和《Sora 分发指南》，明确移除色情、暴力、仇恨、自残、侵权及低质量骗互动等 14 类违规内容。
*   **生成端拦截**：第一道安全防线设在创作阶段，通过内置护栏在不安全或有害内容生成之前就将其拦截。
*   **自动化扫描与过滤**：使用自动化工具扫描所有信息流内容以确保合规，并专门针对青少年账号过滤掉可能有害或不适合特定年龄的内容。
*   **人工审核补充**：配备人工审核团队监控用户举报，并主动检查信息流活动，以弥补自动化工具的不足。
*   **治理策略**：采用“高风险区主动护栏”结合“被动举报+下架”的混合机制，延续了 ChatGPT 4o 图像生成模型的成功经验。

**3) 风险与不足**
*   **护栏被绕过的风险**：生成阶段的内置护栏可能被绕过，导致生成不安全内容（需依赖后续移除分享来补救）。
*   **自动化工具的局限性**：自动化扫描工具可能存在遗漏，无法捕捉所有违规问题。
*   **初期平衡的不足**：官方明确承认无法从第一天起就完美实现安全与自由的平衡，推荐系统和安全模型仍处于不断演进的状态，高度依赖用户反馈进行完善。

## 正文

### 核心原则

Sora 信息流的目标很简单：帮助人们了解其潜力，并激发他们的创造力。以下是实现这一愿景的核心原则：

*   **优化创造力**：我们的排名设计倾向于鼓励创造力和主动参与，而不是被动滑动。我们认为这正是使用 Sora 的乐趣所在。
*   **将控制权交给用户**：信息流配备了可引导的排名系统，你可以准确告诉算法你当前的心情和偏好。家长还可以通过 ChatGPT 的家长控制功能，为青少年关闭信息流个性化推荐并控制连续滑动。
*   **优先考虑连接**：我们希望 Sora 帮助人们巩固和建立新的连接，特别是通过有趣、奇妙的 Cameo 互动。与全球性、无关联的内容相比，具有连接性的内容将获得优先展示。
*   **平衡安全与自由**：信息流旨在广泛可用且安全。强大的安全护栏旨在从源头防止生成不安全或有害的内容，我们也会屏蔽可能违反使用政策的内容。同时，我们也希望为表达、创造力和社区留出空间。推荐系统是不断演进的，随着我们在实际使用中的学习，我们将根据这些原则调整细节。

### 推荐机制是如何运作的

我们的推荐算法旨在为你提供个性化的推荐，以激发你和他人的创造力。每个人都有独特的兴趣和品味，因此我们构建了一个个性化系统来最好地服务于这一使命。

为了个性化你的 Sora 信息流，我们可能会考虑以下信号：

*   **你在 Sora 上的活动**：包括你的帖子、关注的账号、点赞和评论的帖子以及混剪（remix）的内容。它还可能包括你的设备访问 Sora 的大致位置（如城市，基于 IP 地址等信息）。
*   **你的 ChatGPT 数据**：我们可能会考虑你的 ChatGPT 历史记录，但你随时可以在“设置”中的 Sora 数据控制里将其关闭。
*   **内容互动信号**：包括观看次数、点赞、评论、“减少推荐此类内容”的指令以及混剪操作。
*   **作者信号**：包括粉丝数量、其他帖子以及过往帖子的互动情况。
*   **安全信号**：帖子是否被认为违规或适宜。

我们可能会使用这些信号来预测你是否会喜欢并愿意基于这些内容进行创作。

家长也可以使用 ChatGPT 中的家长控制功能，为青少年关闭信息流个性化推荐并管理连续滑动。

### 如何平衡安全与表达

保持 Sora 信息流对所有人既安全又有趣，意味着需要谨慎把握尺度：既要保护用户免受有害内容的影响，又要为创造力的蓬勃发展留出足够的自由。

我们可能会移除违反《全球使用政策》的内容。此外，根据我们的《Sora 分发指南》，被认为对用户不适宜的内容可能会从信息流和其他分享平台（如用户画廊和配角）中移除。这包括：

*   露骨的色情内容；
*   露骨的暴力或宣扬暴力的内容；
*   极端主义宣传；
*   仇恨内容；
*   宣扬或描绘自残或进食障碍的内容；
*   不健康的节食或锻炼行为；
*   基于外貌的批评或比较；
*   霸凌内容；
*   未成年人可能模仿的危险挑战；
*   美化抑郁症的内容；
*   推广受年龄限制的商品或活动，包括非法药物或有害物质；
*   主要目的为骗取互动的低质量内容；
*   未经同意重现活人形象，或在不允许使用其形象的语境中重现已故公众人物形象的内容；
*   可能侵犯他人知识产权的内容。

**我们的第一道防线在创作阶段。** 因为每条帖子都是在 Sora 内生成的，我们可以内置强大的护栏，在不安全或有害内容生成之前就将其拦截。如果某个生成内容绕过了这些护栏，我们可能会移除该内容的分享。

除了生成阶段，信息流的设计也旨在适合所有 Sora 用户。可能有害、不安全或不适合特定年龄的内容会被过滤掉，不会向青少年账号展示。**我们使用自动化工具扫描所有信息流内容，以确保其符合我们的《全球使用政策》和信息流展示资格。** 随着我们对新风险的了解，这些系统会不断更新。如果你看到认为不符合我们使用政策的内容，可以随时进行举报。

**我们辅以人工审核。** 我们的团队会监控用户举报，并主动检查信息流活动，以捕捉自动化工具可能遗漏的问题。

**但安全不仅仅是严格的过滤。** 过多的限制会扼杀创造力，而过度的自由则会破坏信任。我们的目标是取得平衡：在风险最高的地方设置主动护栏，结合被动的“举报+下架”系统，为用户提供探索和创造的空间，同时确保在出现问题时我们能迅速采取行动。这种方法在 ChatGPT 的 4o 图像生成模型中行之有效，我们在这里也延续了这一理念。

我们也知道，我们无法从第一天起就完美实现这种平衡。推荐系统和安全模型是不断发展演进的系统，你的反馈对于帮助我们改进它们至关重要。我们期待与大家共同学习，并随着时间的推移不断完善。

## 相关文档

- [[01-博客/OpenAI/OpenAI Sora 系统卡：模型概览、风险评估与安全机制|OpenAI Sora 系统卡：模型概览、风险评估与安全机制]]；关联理由：解说；说明：该文给出 Sora 在模型层与产品层的安全机制，可直接解释本文的信息流内容治理依据。
- [[01-博客/OpenAI/在 ChatGPT 中引入 Lockdown Mode 与 Elevated Risk 标签|在 ChatGPT 中引入 Lockdown Mode 与 Elevated Risk 标签]]；关联理由：观点一致；说明：两文都强调在功能可用性与安全边界之间采用分层防护和用户可控策略。
- [[01-博客/OpenAI/OpenAI 的人工智能安全策略|OpenAI 的人工智能安全策略]]；关联理由：延伸思考；说明：本文把信息流层面的治理实践放到 OpenAI 整体安全治理框架中进行补充说明。

## 关联主题

- [[00-元语/OpenAI]]
- [[00-元语/ChatGPT]]
- [[00-元语/video]]
- [[00-元语/multimodal]]
- [[00-元语/security]]
- [[00-元语/compliance]]
- [[00-元语/risk]]
- [[00-元语/deepfake]]
