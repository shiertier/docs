# 我们的 First Proof 提交

## 文档信息

- 来源：https://openai.com/index/first-proof-submissions
- 发布日期：2026-02-20
- 译注：未找到官方中文版本，本文基于英文原文翻译整理。

## 摘要

### 1) 一句话总结
OpenAI 使用其内部正在训练的推理模型提交了“First Proof”研究级数学挑战的全部10个问题的证明尝试，其中至少5个问题经专家评估具有很高的正确概率。

### 2) 关键要点
*   **挑战背景**：First Proof 是一个测试 AI 能否生成可验证证明的研究级数学挑战，包含部分悬而未决多年的专家级难题。
*   **提交详情**：OpenAI 于2026年2月14日提交了全部10个问题的证明尝试，并发布了包含提示词模式和人工交互示例的完整预印本。
*   **评估结果**：根据专家反馈，模型在问题 4、5、6、9 和 10 上的证明尝试有很高的正确概率。
*   **模型进展**：该内部新模型专注于提高思维严谨性，目标是能连续思考数小时；随着训练推进，其解题能力显著提升（从最初解决2题增加到至少5题）。
*   **人工干预**：证明过程包含有限的人类监督，包括建议重试策略、根据专家反馈要求模型扩展或澄清证明，以及由人工挑选出最佳尝试。
*   **工具协同**：过程中促成了该内部模型与 ChatGPT 之间的反复交互，以完成验证、格式化和风格调整。
*   **历史延续**：此项工作建立在 OpenAI 此前的推理成果之上，包括2025年7月 IMO 金牌水平（35/42分）、2025年11月 GPT-5 加速科学研究实验，以及近期 GPT-5.2 在物理学胶子振幅公式上的合作。
*   **未来计划**：OpenAI 计划与 First Proof 组织者讨论制定更严谨的实验和评估框架，并期待在未来的公开模型中提供这些新能力。

### 3) 风险与不足
*   **实验过程缺乏严格控制**：本次提交是一次快速冲刺，包含人工干预，过程不如在严格控制的评估中所希望的那样干净利落。
*   **模型存在错误证明**：对问题 2 的证明尝试最初被内部认为很可能是正确的，但经官方评论和社区分析后确认为不正确。
*   **现有基准测试的盲区**：传统基准测试可能会遗漏研究中最困难的部分，如维持长推理链、选择正确的抽象概念、处理问题陈述中的歧义，以及生成经得起专家推敲的论证。

## 正文

我们的 First Proof 提交 | OpenAI

我们将分享针对 First Proof 的证明尝试，这是一个旨在测试 AI 能否在特定领域问题上生成可验证证明的数学挑战。

收听文章

我们使用一个内部模型运行了所有 10 个 [First Proof⁠(在新窗口中打开)](https://1stproof.org/) 问题，这是一个研究级别的数学挑战，旨在测试 AI 系统能否生成正确且可验证的证明尝试。与简答题或竞赛类数学题不同，这些问题需要在专业领域内构建端到端的论证，且如果没有专家的审查，很难确定其正确性。First Proof 问题的作者都是各自领域的顶尖专家，其中至少有几个问题在作者找到解决方案之前已经悬而未决多年。一个与这些学科领域有大量重叠的学术部门，可以想象能够在一周内解决其中的许多问题。

我们在太平洋时间 2026 年 2 月 14 日星期六凌晨 12:00 [分享了⁠(在新窗口中打开)](https://x.com/merettm/status/2022517085193277874?s=20)我们的证明尝试。根据专家的反馈，我们认为该模型至少有五个证明尝试（问题 4、5、6、9 和 10）有很高的正确概率，其他几个仍在审查中。我们最初认为我们对问题 2 的尝试很可能是正确的。根据 First Proof 的官方评论和社区的进一步分析，我们现在认为它是不正确的。我们对大家的参与表示感谢，并期待后续的持续审查。我们完整的证明尝试可以在[这里⁠(在新窗口中打开)](https://cdn.openai.com/pdf/26177a73-3b75-4828-8c91-e8f1cf27aaa0/oai_first_proof.pdf)找到。该预印本包含了所有十个证明尝试，外加一个新增的附录，其中包含提示词模式和示例，旨在模拟我们在该过程中与模型进行的手动交互。

我们认为，新颖的前沿研究可能是评估下一代 AI 模型能力的最重要方式。基准测试很有用，但它们可能会遗漏研究中最困难的一些部分：维持长推理链、选择正确的抽象概念、处理问题陈述中的歧义，以及生成经得起专家推敲的论证。像 First Proof 这样的前沿挑战帮助我们在正确性难以验证且失败模式具有启发意义的环境中，对这些能力进行压力测试。

_“我们目前正在训练一个新模型，其主要重点是提高其思维的严谨性，目标是让该模型能够连续思考数小时，并对其结论保持高度自信。当 First Proof 问题公布时，它似乎是一个完美的测试平台，所以我在周末尝试了一下。它当时已经能够解决其中的两个问题（#9 和 #10）。随着训练的进行，它的能力越来越强，最终——据我们估计——至少又解决了三个问题。当它解决 #6，并在两天后解决 #4 时，我们感到特别高兴，因为这些问题来自我们许多人熟悉的领域。看着一个模型一天天变得明显更聪明，这真是令人难以置信。”_

—— James R. Lee（OpenAI 研究员，推理方向）

我们在有限的人类监督下运行了该模型。在训练过程中向不同版本的模型提供提示时，我们有时会建议重试在早期尝试中看似有效的策略。对于某些尝试，我们在收到专家反馈后，要求模型扩展或澄清证明的某些部分，以使推理更容易验证。我们还促成了该模型与 ChatGPT 之间的反复交互，以进行验证、格式化和风格调整。对于某些问题，我们展示了由人类判断选出的几次尝试中最好的一次。这是一次快速冲刺，我们的过程并不像我们在严格控制的评估中所希望的那样干净利落。我们期待与 First Proof 组织者讨论，为未来的迭代制定更严谨的实验和评估框架。

这项工作建立在前沿推理模型在数学和科学领域的早期成果之上。2025 年 7 月，我们使用通用推理模型在国际数学奥林匹克竞赛中达到了[金牌水平的表现⁠(在新窗口中打开)](https://x.com/OpenAI/status/1946594928945148246?utm_source=chatgpt.com)（35/42 分）。2025 年 11 月，我们分享了“[使用 GPT-5 加速科学研究的早期实验](https://openai.com/index/accelerating-science-gpt-5/)”，这是一组案例研究，展示了 GPT-5 如何帮助研究人员在数学、物理、生物等领域取得具体进展，以及我们观察到的局限性。最近，我们报告了一项[物理学合作](https://openai.com/index/new-result-theoretical-physics/)，其中 GPT-5.2 提出了一个胶子振幅公式的候选表达式，随后由一个内部模型进行了形式化证明，并由作者进行了验证。

我们期待与社区就如何评估研究级推理进行更深入的交流，包括对这些尝试的专家反馈，并且我们非常高兴能在未来的公开模型中提供这些新能力。

## 关联主题

- [[00-元语/OpenAI]]
- [[00-元语/AI]]
