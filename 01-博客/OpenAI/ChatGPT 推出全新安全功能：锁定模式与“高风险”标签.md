# ChatGPT 推出全新安全功能：锁定模式与“高风险”标签

## 文档信息
- 来源：https://openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt

## 摘要
**1) 一句话总结**
OpenAI 为 ChatGPT 推出了“锁定模式”和“高风险”标签两项全新安全功能，旨在帮助组织和用户防范提示词注入攻击，并提供更清晰的风险可见性与控制力。

**2) 关键要点**
*   **核心目标**：应对日益凸显的提示词注入（Prompt Injection）攻击，防止第三方误导 AI 执行恶意指令或泄露敏感信息。
*   **锁定模式定位**：一项可选的高级安全设置，专为高管或安全团队等面临高级威胁的少数高风险用户设计，普通用户非必需。
*   **锁定模式机制**：严格限制 ChatGPT 与外部系统的交互（如将网络浏览限制为仅访问缓存内容），并完全禁用无法提供强有力数据安全保证的功能，以防止数据外泄。
*   **适用版本与管理**：锁定模式目前适用于 ChatGPT Enterprise、Edu、Healthcare 和 Teachers；管理员可通过创建新角色启用，并保留对特定应用和操作的细粒度控制权。
*   **监控与审计**：独立的合规 API 日志平台（Compliance API Logs Platform）提供对应用使用情况、共享数据和连接源的详细可见性。
*   **消费者计划**：计划在未来几个月内向普通消费者用户推出锁定模式。
*   **“高风险”标签**：在 ChatGPT、ChatGPT Atlas 和 Codex 中，对可能引入额外风险的特定联网或应用连接功能进行标准化标识。
*   **标签作用**：在产品内提供明确指导，解释功能变化及潜在风险，帮助用户在处理私人数据时做出知情决策。
*   **未来规划**：随着安全技术的进步，若某项功能的常规使用风险被充分降低，将移除其“高风险”标签，并持续动态更新标签列表。

**3) 风险/缺口（原文明确提及）**
*   **提示词注入风险**：攻击者可能通过提示词注入，利用 AI 系统的工具和互联应用窃取敏感数据或执行恶意指令。
*   **数据外泄风险**：实时网络请求等功能可能成为敏感数据外泄给攻击者的渠道。
*   **现有安全措施的局限性**：AI 产品连接到应用程序和网络时，会引入行业现有安全缓解措施尚未完全解决的新风险。

## 正文
随着人工智能系统承担越来越复杂的任务（尤其是涉及网络和互联应用程序的任务），安全风险也在发生变化。

其中一个日益凸显的风险是**提示词注入（Prompt Injection）**。在这种攻击中，第三方试图误导对话式 AI 系统执行恶意指令或泄露敏感信息。

为了帮助用户和组织缓解提示词注入攻击，并提供更清晰的风险可见性和更强的控制力，我们今天推出了两项全新的安全保护措施：

*   **锁定模式（Lockdown Mode）**：在 ChatGPT 中为高风险用户提供的高级、可选安全设置。
*   **“高风险（Elevated Risk）”标签**：针对 ChatGPT、ChatGPT Atlas 和 Codex 中可能引入额外风险的特定功能。

### 帮助组织保护最易受网络攻击的员工

锁定模式是一项可选的高级安全设置，专为少数具有高度安全意识的用户（如知名企业的高管或安全团队）设计，以满足他们抵御高级威胁的需求。对于大多数普通用户而言，该模式并非必需。

锁定模式通过严格限制 ChatGPT 与外部系统的交互方式，来降低基于提示词注入的数据外泄风险。它会确定性地禁用 ChatGPT 中的某些工具和功能，防止攻击者利用这些功能通过提示词注入等手段，从用户的对话或互联应用中窃取敏感数据。

例如，在锁定模式下，网络浏览功能仅限于访问缓存内容，因此不会有任何实时网络请求离开 OpenAI 的受控网络。这一限制旨在防止敏感数据通过浏览功能外泄给攻击者。对于那些我们无法提供强有力的数据安全确定性保证的功能，将会被完全禁用。

ChatGPT 的商业计划已经提供了企业级的数据安全保障。锁定模式在这些现有保护的基础上进一步增强，目前适用于 ChatGPT Enterprise、ChatGPT Edu、ChatGPT for Healthcare 以及 ChatGPT for Teachers。管理员可以通过在工作区设置中创建新角色来启用该模式。启用后，锁定模式会在现有的管理员设置之上叠加额外的限制。

由于某些关键工作流依赖于应用程序，工作区管理员保留了更细粒度的控制权。他们可以精确选择在锁定模式下，用户可以使用哪些应用程序以及这些程序中的哪些具体操作。此外，独立于锁定模式的合规 API 日志平台（Compliance API Logs Platform）提供了对应用使用情况、共享数据和连接源的详细可见性，帮助管理员保持监督。

我们计划在未来几个月内向消费者用户推出锁定模式。

### 帮助用户在了解风险的前提下做出选择

当 AI 产品连接到您的应用程序和网络时，它们会变得更加实用。尽管我们在保障连接数据安全方面投入了大量资源，但某些与网络相关的功能仍会带来行业现有安全缓解措施尚未完全解决的新风险。部分用户可能愿意承担这些风险，我们认为，让用户有能力决定是否以及如何使用这些功能（尤其是在处理私人数据时）至关重要。

我们的策略是为可能引入额外风险的功能提供产品内指导。为了使这一点更加清晰和一致，我们正在对少数现有功能的标签方式进行标准化。这些功能现在将在 ChatGPT、ChatGPT Atlas 和 Codex 中统一使用“高风险（Elevated Risk）”标签，确保用户无论在哪里遇到这些功能，都能获得一致的指导。

例如，在我们的编程助手 Codex 中，开发人员可以授予 Codex 网络访问权限，以便其在网络上执行查找文档等操作。相关的设置界面会显示“高风险”标签，并清晰地解释发生了什么变化、可能引入哪些风险，以及何时适合开放此类访问权限。

### 下一步计划

我们将继续投资于加强我们的安全防护措施，特别是针对新型、新兴或不断增长的风险。随着我们对这些功能安全防护的不断加强，一旦我们确定安全技术的进步已经充分降低了这些功能在常规使用中的风险，我们就会移除“高风险”标签。同时，我们也会随着时间的推移持续更新带有此标签的功能列表，以便向用户最准确地传达风险信息。

## 关联主题
- [[00-元语/ChatGPT]]
- [[00-元语/OpenAI]]
- [[00-元语/security]]
- [[00-元语/risk]]
- [[00-元语/Codex]]
- [[00-元语/compliance]]
- [[00-元语/prompt]]
