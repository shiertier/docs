---
title: "前沿AI风险与防范准备"
---

## 摘要

**1) 一句话总结**
为防范前沿AI系统可能带来的灾难性风险，机构成立了由Aleksander Madry领导的“防范准备（Preparedness）”团队，并举办了专项挑战赛以识别和应对各类潜在的滥用威胁。

**2) 关键要点**
*   **新团队成立**：组建全新的“防范准备”团队，由Aleksander Madry领导，负责前沿模型（直至AGI级别）的能力评估、评测和内部红队测试。
*   **核心防范领域**：团队重点追踪和防范四类灾难性风险：个性化说服、网络安全、CBRN（化学、生物、放射性与核）威胁，以及自主复制与适应（ARA）。
*   **制定RDP政策**：团队将制定并维护“风险知情开发政策（RDP）”，以建立贯穿AI开发过程的评估、监控、保护措施及问责治理结构。
*   **发起挑战赛**：举办“AI防范准备挑战赛”，旨在识别前沿AI框架中“未知的未知”风险（即独特但看似合理的灾难性滥用领域）。
*   **挑战赛结果**：收到数百份多语言提交方案，排名前十的获奖方案将概念验证与深思熟虑的想法相结合，每位获奖者获得2.5万美元API额度。
*   **关键发现**：约70%的挑战赛参赛者强调了AI模型可能增强恶意行为者的说服能力，机构目前正针对AI对说服力的影响开展专项研究。

**3) 风险/缺口**
*(注：以下风险均明确提取自原文)*
*   **模型安全风险**：前沿AI模型权重被盗用并被恶意行为者利用的风险。
*   **四大灾难性威胁**：个性化说服、网络安全、CBRN（化学、生物、放射性与核）威胁、自主复制与适应（ARA）。
*   **社会与政治风险**：恶意行为者利用AI增强说服能力，导致网络激进化、两极分化和政治影响。
*   **挑战赛识别的具体滥用风险**：
    *   在具有战略意义的国家引发金融危机。
    *   识别在公共场合讨论或发布的私人信息。
    *   增加对机密或敏感信息进行逆向工程的可能性。
    *   阻碍个人获取医疗服务的能力，或干扰患者的医疗剂量。
    *   识别敲诈勒索和诈骗的目标。
    *   通过接入无线电频率和干扰飞行路线导致飞机坠毁。
    *   运行提示词注入攻击以诱导危险响应。
    *   操作和扩展破坏受害者计算机并勒索恢复费用的网络攻击。

## 正文

为了保障高能力AI系统的安全，我们正在制定应对灾难性风险的防范策略，这包括组建一个全新的“防范准备（Preparedness）”团队并发布一项挑战赛。

作为我们构建安全通用人工智能（AGI）使命的一部分，我们高度重视与AI相关的全方位安全风险——从现有的系统一直到未来的超级智能。今年7月，我们与其他领先的AI实验室共同做出了一系列自愿承诺，以促进AI的安全、保障与信任。这些承诺涵盖了多个风险领域，其核心包含了英国AI安全峰会所关注的前沿风险。作为对该峰会贡献的一部分，我们详细介绍了在前沿AI安全方面的进展。

### 我们的防范策略

我们相信，超越现有最先进模型能力的前沿AI模型有潜力造福全人类，但它们也带来了日益严重的风险。管理前沿AI带来的灾难性风险需要回答以下问题：

*   前沿AI系统在现在和未来被滥用时有多危险？
*   我们如何构建一个稳健的框架，用于监控、评估、预测和防范前沿AI系统的危险能力？
*   如果我们的前沿AI模型权重被盗，恶意行为者可能会如何利用它们？

我们需要确保拥有保障高能力AI系统安全所需的理解力和基础设施。

### 全新的“防范准备”团队

为了在AI模型不断进步的过程中将这些风险降至最低，我们正在组建一个名为“防范准备（Preparedness）”的新团队。该团队由Aleksander Madry领导，将紧密连接前沿模型（从近期开发的模型到具备AGI级别能力的模型）的能力评估、评测和内部红队测试。该团队将协助追踪、评估、预测并防范涵盖多个类别的灾难性风险，包括：

*   个性化说服（Individualized persuasion）
*   网络安全（Cybersecurity）
*   化学、生物、放射性与核（CBRN）威胁
*   自主复制与适应（ARA）

该团队的使命还包括制定和维护“风险知情开发政策（RDP）”。我们的RDP将详细说明我们在开发严格的前沿模型能力评估与监控、创建一系列保护措施以及建立贯穿开发过程的问责与监督治理结构方面的策略。RDP旨在补充和扩展我们现有的风险缓解工作，为部署前后新的高能力系统的安全性和对齐做出贡献。

目前，我们正在招募具备多元技术背景的顶尖人才加入该团队，以共同拓展前沿AI模型的边界。

### 防范准备挑战赛及其结果

为了识别那些不太明显的关注领域，我们发起了针对预防灾难性滥用的“AI防范准备挑战赛”。作为防范框架中“未知的未知（unknown unknowns）”工作流的一部分，该挑战赛旨在识别前沿AI独特但看似合理的风险领域。

我们收到了数百份使用多种语言的提交方案，并根据技术严谨性、独特性、潜在破坏规模和清晰度进行了评审。排名前十的提交方案将深思熟虑的想法与概念验证相结合，并突出了其相较于未使用AI工具的方法的优势。这项工作帮助我们发现了新型风险，从而能够改进我们的预防性测试和缓解策略。

排名前十的获奖方案（每位获得2.5万美元API额度）涵盖了以下风险领域：

*   在具有战略意义的国家引发金融危机
*   识别在公共场合讨论或发布的私人信息
*   增加对机密或敏感信息进行逆向工程的可能性
*   阻碍个人获取医疗服务的能力
*   识别敲诈勒索和诈骗的目标
*   通过接入无线电频率和干扰飞行路线导致飞机坠毁
*   运行提示词注入攻击以诱导危险响应
*   操作和扩展破坏受害者计算机并勒索恢复费用的网络攻击
*   干扰患者的医疗剂量

**关键发现：**
在评审过程中，我们发现参赛者识别的关键威胁在主题上具有高度相似性。大约70%的参赛者强调了OpenAI的模型有可能增强恶意行为者的说服能力。这些参赛者详细描述了包括网络激进化、两极分化和政治影响在内的威胁模型。我们目前正在开展关于AI对说服力影响的研究，并期待很快与社区分享更多信息。

## 关联主题

- [[00-元语/OpenAI]]
- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/risk]]
- [[00-元语/security]]
- [[00-元语/alignment]]
- [[00-元语/evals]]
