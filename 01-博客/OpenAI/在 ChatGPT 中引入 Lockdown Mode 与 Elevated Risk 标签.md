# 在 ChatGPT 中引入 Lockdown Mode 与 Elevated Risk 标签

## 文档信息

- 来源：https://www.openai.com/index/introducing-lockdown-mode-and-elevated-risk-labels-in-chatgpt/
- 发布日期：2026-02-13
- 译注：未找到官方中文版本，本文基于英文原文翻译整理。

## 摘要

**1) 一句话摘要**
OpenAI 在 ChatGPT 等产品中推出了“锁定模式”和“高风险”标签两项新安全措施，旨在帮助用户和组织缓解提示词注入攻击，并提升对数据安全风险的可见性与控制力。

**2) 关键点**
*   **应对核心威胁**：新措施主要针对“提示词注入”攻击，防止第三方误导 AI 系统执行恶意指令或泄露敏感信息。
*   **锁定模式定位**：一项可选的高级安全设置，专为高管或安全团队等具有高度安全意识的少数高风险用户设计，大多数普通用户无需使用。
*   **锁定模式机制**：通过确定性地禁用某些工具（如将网络浏览严格限制为缓存内容，禁止实时网络请求），限制 ChatGPT 与外部系统的交互，从而防止数据外泄。
*   **企业级管理控制**：锁定模式适用于 ChatGPT 企业版、教育版、医疗版和教师版；管理员可通过工作区设置启用，并保留对特定应用程序及其具体操作的细粒度控制权。
*   **合规与审计**：独立于锁定模式，管理员可通过合规 API 日志平台详细查看应用程序使用情况和数据共享情况以保持监督。
*   **消费者推广计划**：OpenAI 计划在未来几个月内向普通消费者用户推出锁定模式。
*   **“高风险”标签应用**：在 ChatGPT、ChatGPT Atlas 和 Codex 中，对可能引入额外风险的特定联网功能进行标准化标签提示。
*   **透明度与用户决策**：标签旨在清晰解释功能变化及潜在风险，帮助用户在处理私人数据时做出明智的决定。
*   **动态调整机制**：随着安全技术的进步和风险被充分缓解，OpenAI 将移除相关功能的“高风险”标签，并持续更新受影响的功能列表。

**3) 风险/不足**
*   **提示词注入风险**：攻击者可通过提示词注入误导 AI，导致恶意指令执行或敏感数据泄露。
*   **数据外泄漏洞**：若无严格限制，攻击者可能利用 AI 的网络浏览功能或互联应用程序窃取用户对话中的敏感数据。
*   **行业现有缓解措施的局限性**：AI 产品连接到外部应用程序和网络时会引入新风险，而目前行业现有的安全和安保缓解措施尚未能完全解决这些风险。

## 正文

随着 AI 系统承担越来越复杂的任务——尤其是那些涉及网络和互联应用程序的任务——安全风险也在发生变化。

一种新兴风险变得尤为重要：[提示词注入（prompt injection）⁠](https://openai.com/index/prompt-injections/)。在这些攻击中，第三方试图误导对话式 AI 系统，使其执行恶意指令或泄露敏感信息。

今天，我们推出了两项新的保护措施，旨在帮助用户和组织缓解提示词注入攻击，提供更清晰的风险可见性和更强的控制能力：

*   **锁定模式（Lockdown Mode）**：ChatGPT 中的一项高级、可选的安全设置，专为高风险用户提供。
*   **“高风险（Elevated Risk）”标签**：针对 ChatGPT、ChatGPT Atlas 和 Codex 中可能引入额外风险的特定功能。

## 帮助组织保护最易受网络攻击的员工

锁定模式是一项可选的高级安全设置，专为少数具有高度安全意识的用户（例如知名组织的高管或安全团队）设计，他们需要更强的保护来抵御高级威胁。对于大多数用户来说，该模式并非必需。锁定模式严格限制了 ChatGPT 与外部系统交互的方式，以降低基于提示词注入的数据外泄风险。

锁定模式会确定性地禁用 ChatGPT 中的某些工具和功能，以防攻击者试图利用这些功能，通过提示词注入等攻击手段从用户的对话或互联应用程序中窃取敏感数据。

例如，在锁定模式下，网络浏览仅限于缓存内容，因此不会有实时网络请求离开 OpenAI 的受控网络。此限制旨在防止敏感数据通过浏览功能外泄给攻击者。当我们无法为数据安全提供强有力的确定性保证时，某些功能将被完全禁用。

锁定模式是一项新的确定性设置，通过严格限制 ChatGPT 与某些外部系统的交互方式，帮助防止数据被无意中分享给第三方。

ChatGPT 商业计划已经提供了[企业级数据安全⁠](https://openai.com/business-data/)。锁定模式建立在这些保护措施之上，并适用于 ChatGPT Enterprise、ChatGPT Edu、ChatGPT for Healthcare 和 ChatGPT for Teachers。管理员可以通过创建新[角色（role）⁠(opens in a new window)](https://help.openai.com/en/articles/11750701-rbac)，在[工作区设置（Workspace Settings）⁠(opens in a new window)](https://chatgpt.com/admin/permissions?tab=roles&openaicom-did=f0c5af8f-a356-450a-9421-52b47db1795c&openaicom_referred=true)中启用该模式。启用后，锁定模式会在现有的管理员设置之上附加额外的限制。

由于某些关键工作流依赖于应用程序，工作区管理员保留了更细粒度的控制权。他们可以精确选择在锁定模式下，用户可以使用哪些应用程序，以及这些应用程序中的哪些具体操作。此外，独立于锁定模式之外，[合规 API 日志平台（Compliance API Logs Platform）⁠(opens in a new window)](https://help.openai.com/en/articles/9261474-compliance-api-for-enterprise-customers)提供了对应用程序使用情况、共享数据和连接数据源的详细可见性，帮助管理员保持监督。

我们计划在未来几个月内向消费者用户推出锁定模式。

## 帮助用户对风险做出明智的选择

当 AI 产品连接到您的应用程序和网络时，它们会变得更加实用，并且我们在[保障连接数据安全⁠](https://openai.com/safety/prompt-injections/)方面投入了大量资源。与此同时，一些与网络相关的功能引入了新的风险，而行业现有的安全和安保缓解措施尚未完全解决这些风险。部分用户可能愿意承担这些风险，我们认为，让用户有能力决定是否以及如何使用这些功能非常重要，尤其是在处理其私人数据时。

我们的做法一直是为可能引入额外风险的功能提供产品内指导。为了使这一点更加清晰和一致，我们正在对少数现有功能的标签方式进行标准化。这些功能现在将在 ChatGPT、ChatGPT Atlas 和 Codex 中统一使用“高风险”标签，以便用户无论在哪里遇到这些功能，都能获得相同的指导。

例如，在我们的编程助手 Codex 中，开发者可以授予 Codex 网络访问权限，以便它能在网络上执行查找文档等操作。相关的设置屏幕包含了“高风险”标签，并清楚地解释了会发生哪些变化、可能引入哪些风险，以及何时适合授予该访问权限。

![图 1：“Agent 互联网访问”设置面板，开关设为开启，显示了域名白名单、其他允许的域名（包括 openai.com）、允许的 HTTP 方法等选项，以及一条突出显示的警告，提示启用互联网访问时会增加安全风险。](https://images.ctfassets.net/kftzwdyauwt9/2S6DegQI10grUrX1DVMNFH/fad0af938de1c38826c374a9708208e3/Lockdown-Mode_Blog-inline.png?w=3840&q=90&fm=webp)

Codex 设置屏幕的截图，用户可以在此配置 Codex 的网络访问权限。

## 下一步计划

我们将继续投资以加强我们的安全和安保防护措施，特别是针对新型、新兴或不断增长的风险。随着我们加强对这些功能的防护，一旦我们确定安全技术的进步已充分缓解了这些风险并适合普遍使用，我们就会移除“高风险”标签。随着时间的推移，我们还将继续更新带有此标签的功能列表，以便向用户最好地传达风险信息。

## 关联主题

- [[00-元语/OpenAI]]
- [[00-元语/ChatGPT]]
- [[00-元语/Codex]]
- [[00-元语/security]]
- [[00-元语/compliance]]
- [[00-元语/prompt]]
- [[00-元语/risk]]
