---
title: "看好了，这才是7家大模型做高考数学题的真实分数。"
发布日期: 2025-06-09
作者: "数字生命卡兹克"
来源: "微信公众号"
原文链接: "https://mp.weixin.qq.com/s?__biz=MzIyMzA5NjEyMA==&mid=2647671757&idx=1&sn=9fd4e8d5743c730cb4ae299e1a837ef5&chksm=f13572f29037eac6343ead7799d1e239c0513a1b575b13dc939f80773589cfd70ea2bd5e8eb6"
---

## 摘要

**1) 一句话总结**
作者通过将2025年高考数学全国一卷客观题转化为LaTeX文本，对7款主流推理大模型进行了严格控制变量的纯数学能力测试，结果显示各模型表现优异且差距极小，其中Gemini 2.5 Pro获得满分。

**2) 核心要点**
*   **测试范围**：2025年高考数学全国一卷，剔除解答题及带图表的第6题，保留7道单选、3道多选、3道填空，满分68分。
*   **参测模型**：OpenAI o3、Gemini 2.5 pro、DeepSeek R1、豆包（1.5-thinking-pro）、元宝（混元T1）、千问3（235B）、讯飞星火X1。
*   **控制变量**：题目全部转为LaTeX文本格式输入；关闭联网、代码沙盒及Prompt引导，仅测试纯推理能力。
*   **计分规则**：严格遵循高考判分标准（多选漏选按比例给分），每题测试3次并按正确比例计算平均分，以减少幻觉干扰。
*   **得分排名**：
    *   第一名：Gemini 2.5 Pro（68分，满分）。
    *   第二名：豆包、元宝、星火（67分，均在第9题漏选）。
    *   第五名：DeepSeek R1（66.3分，因第11题输出格式问题丢0.7分）。
    *   垫底：Qwen3、OpenAI o3（65.3分，均在填空题错1次）。
*   **核心结论**：当前主流推理大模型应对高考数学客观题已无明显难度，彼此间能力差距极小，错误多为轻微幻觉。

**3) 风险与不足**
*   **多模态识图风险**：直接使用截图让大模型做数学题存在极高的OCR识别错误风险（如将数学符号“\complement_{U} A”错误识别为“CuA”），会导致评测结果严重失真。
*   **输出格式风险**：部分模型（如DeepSeek R1）在逻辑计算正确的情况下，可能因输出回答时的“抽象”表达或格式不规范导致意外失分。

## 正文

这两天，很多媒体都在写用AI考高考题的内容。

我本来真的没打算卷这个选题，因为知道大家肯定都会写，都会卷，我也想休息休息，真的就不打算写了。

但是吧，用AI测语文考试还没啥，但是看了一些用AI做数学考试的文章，真的给我看的一脸地铁老头表情包，就，那个测试方法，也特么太扯淡了。

我觉得既然是考试，那就公平公正的去测试？

当然，你要是玩整活，那就另谈了。

结果最后得出一些不太靠谱的结论，我觉得还是蛮误导大家的。

客观、公平、公正，是我觉得最核心的标准。

所以我觉得，我想按照我的玩法，再严谨一点的测一下大模纯数学能力型高考，给大家看一下，真实客观的评分。

测试试卷为2025年数学全国一卷。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicM5GQGuCP444YmiafXUqicTbgQv0bUu9JgMQt7VqoCAVVdKkiazCnSkVxRA/640?wx_fmt=png&from=appmsg)

测试规则如下：

1. 不考解答题（因为给我标准答案我也看不懂，不知道咋给分。。）

2. 所有的题目截图全部使用LaTeX编辑器转成LaTeX文本格式，再扔给大模型进行回答。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicM0HyicibIq9dibzoT6N1fQagOeUGPgsaNvac7gNwcskznf7nYqXUMicpWFw/640?wx_fmt=png&from=appmsg)

LaTeX是学术界最广泛使用的数学公式排版语言，能最精确地表达数学符号，我们考的是模型的数学能力，不是考模型的多模态识图能力，比如DeepSeek根本就没多模态，用的是OCR提取文本，很可能识别错误，所以截图上传不公平，一律转化成LaTeX格式再进行统一测试。

3. 剔除掉单选题第6题，因为这是单选、多选、填空题中唯一有图表的，转成文字可能会有理解歧义，同时就一题，影响不大，直接剔除。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicMS6mx5DZQKShE3MGia5U4NqNGzDVrMib36cTt0lyibQEeSBJYsGdAsr4Rg/640?wx_fmt=png&from=appmsg)

4. 单题计分方法也依照高考判分原则：单选题7道，每道5分，选项正确计分，错误不得分；多选题3道，每道6分，全对计6分，漏选按正确答案数量计分，如答案为ABCD，漏选其一扣1.5分，错选不得分；填空题3道，每道5分，填空正确计分，错误不得分。

5. 每道题都会使用大模型跑3遍，根据正确比例进行分配，最大程度减少幻觉。比如OpenAI o3模型，做单选题第7题，对2次，错1次，则实际得分为5*0.66=3.3分。

6. 只开推理、不使用Prompt引导、不开联网、不允许写代码在沙盒进行计算，比如o3，我直接把这几个功能关掉了。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicMO05SZBhUSd7ov0PpJoLricXtrTrBHh4cznFdG8s1TPYdBcC4Ys6H8DA/640?wx_fmt=png&from=appmsg)

以上，就是全部规则了。

接下来，请我们的模型考生入场。

测试模型为
OpenAI o3、Gemini 2.5 pro、DeepSeek R1
、豆包（
1.5-thinking-pro）
、元宝（混元T1）、千问3（235B）、讯飞星火X1，
均为推理模型。

在晚上凌晨2点开始测试，因为搞API写脚本反而可能更麻烦，所以直接搞了个表格，复制粘贴测了，以至于喊了我的几个好朋友@卡尔的AI沃兹、@Max、@猫先生 一起测，硬生生测到凌晨4点。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicM68qjZBxNv0GjBCiblTt91OyRbceMnlAnV2v2wbkEicXjBkQo7Ok0Utrg/640?wx_fmt=png&from=appmsg)

7道单选题、3道多选题、3道填空题，总分一共68分。

我们得出了，我认为，非常公平客观的，每个模型的考试结果。

没有收任何家钱，也没有任何利益关系，全部客观公正。

如下图：

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicMncTKRqke7kYF9Ih61op8fLS6Zkw7bgABQAtSLLuxo8vkbsibNibmSnwA/640?wx_fmt=png&from=appmsg)

看看每一题的具体选项。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicMiczDH1ptQaEormNsTkX9ndNSkdswh5uPMiaLdOQVQI5Ye3g5R6tjCX0g/640?wx_fmt=png&from=appmsg)

第9题是个非常神奇的题目，是个多选题，只有Gemini 2.5 Pro每次都对了，其他的所有大模型，几乎全都有问题，D选项倒是全都答出来了，但是缺了B。
而那个DeepSeek第11道题错的那道题，其实并不是真做错了，明明做对了，但是非要作死的瞎答，比如11题多选题，DeepSeek R1错了一道题。
但是我给你看看，它其实是这么错的。
真的，太抽象了。。。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicMTiblX5l5lrty3dSGjwDRU2TlhMlTPwj8OhIQPeGDiapacmCxCbC9hXeA/640?wx_fmt=png&from=appmsg)

再看看，最终分数。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicMgDiaOBx7aUTVzzgRJB6uSfebaUhTMgeaaPP7bzLzfia4YyT3OtufR3tA/640?wx_fmt=png&from=appmsg)

Gemini确实非常强，在整个逻辑上，没有一题是错的。

而豆包、混元、星火位列第二梯队，在第9题上漏了一个选项，并列屈居第二。

DeepSeek半对半错了一个多选题，丢了0.7分，排名第五。

而Qwen3和OpenAI o3因为两个都错了1次填空题，只能被迫垫底。。

通过我的测试，我相信，大家应该对于模型的数学能力，有一些了解了。

其实，根本拉不开差距，出错一般也都是小小的幻觉。

高考对于现在绝大多数的推理大模型来说，其实真的就是，没有特别大的难度，跟2023年的时候，真的是天壤之别。

很多测出来测的非常离谱的文章，其实最后答案错了，跟推理模型本身没有半毛钱关系，而是你把截图扔过去，各种符号啥的识别错误。

比如
则 \complement_{U} A，硬生生识别成了CuA。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURp43bjAY6FYmgwShxEEVlicMRMYyqwTpBTOLiamaYfDeLIS4vtzy4vgTweHXGKj32iaPBnSaEgKxrwEg/640?wx_fmt=png&from=appmsg)

所以，折腾到现在，这场公平、客观的AI数学高考终于落幕了。

在打完最后一个结果的时候，我松了一口气。

其实吧，我们不睡觉，熬夜折腾这么久，想得出的并不仅仅是一个简单的分数。

而是我们我们想知道，怎么才算是一场合格的AI考试。

规则公正，流程严谨，技术中立，少一点博眼球的夸张，多一点对真相的执着。

我始终相信，无论是对技术，还是对人生，严谨总能让我们更接近真实。

而真实，总能让我们更加自由。

睡觉。

起床以后，一定又是美好的一天。


wzglyay@virxact.com

## 关联主题

- [[00-元语/数字生命卡兹克]]
- [[00-元语/AI]]
- [[00-元语/llm]]
