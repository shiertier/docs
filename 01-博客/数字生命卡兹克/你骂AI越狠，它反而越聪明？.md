---
title: "你骂AI越狠，它反而越聪明？"
发布日期: 2025-10-17
作者: "数字生命卡兹克"
来源: "微信公众号"
原文链接: "https://mp.weixin.qq.com/s?__biz=MzIyMzA5NjEyMA==&mid=2647675821&idx=1&sn=5769dbf4e851f6a399e053612e9a3753&chksm=f1d9a5635e3b5f3e872f2f4d7cbc70c8070d160ecbd6bb34c9c822a80aaf11f43a2fa716699c"
---

## 摘要

**1) 一句话总结**
研究表明，在与大语言模型交互时，使用粗鲁或强硬的提示词比礼貌用语能带来更高的准确率，因为直接的指令向模型传达了更高的确定性与执行要求。

**2) 核心要点**
*   **研究来源**：宾夕法尼亚州立大学的论文《Mind Your Tone》专门研究了提示词礼貌程度对大语言模型（LLM）准确率的影响。
*   **实验设计**：研究人员使用50道涵盖数学、科学、历史的多项选择题，设计了从“非常礼貌”到“非常粗鲁”5个等级的提示词，并在GPT-4o上进行了2500次测试（每题跑10遍）。
*   **数据结果**：“非常礼貌”版本的准确率为80.8%，而“非常粗鲁”版本的准确率提升至84.8%，两者相差4个百分点。
*   **模型差异**：智能水平越低的模型，使用粗鲁提示词带来的回复质量提升效果越明显。
*   **历史印证**：自2022年底以来，带有压迫感、威胁或诱惑的“PUA式”提示词（如“深呼吸”、“失败会死100个老奶奶”、“给200美元小费”）已被广泛证明能有效提升AI表现。
*   **底层逻辑（礼貌=不确定）**：AI基于人类数据训练，在人类语言中，“礼貌”常与不确定、试探或隐藏意图挂钩，这会导致AI在模式匹配时给出保守、模糊的答案。
*   **底层逻辑（粗鲁=确定性）**：强硬或粗鲁的指令消除了模糊空间，向AI传达了极致的确定性和“零容错”的要求，从而促使AI精准执行任务。
*   **实践建议**：在实际应用中，用户无需刻意辱骂AI，但应摒弃不必要的客套，采用最直接、明确、强硬的语言来表达需求，以最大化沟通效率。

## 正文

AI世界的Prompt技巧，真的在奇奇怪怪的地方，不断的对历史进行call back。

故事是这样的。

昨天照例在刷一些没那么硬核的论文，看看有没有有意思的。

然后，就看到了一个让我会心一笑的东西。

叫《Mind Your Tone: Investigating How Prompt Politeness Affects LLM Accuracy》

巨短，就5页。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURok1ff3z8CHSZn8x7JUq6CW3Fbia8OxtFrnCfTpFpEnFO3ictIdtxAJbYEqGx65PeMLnxB5Cib6nq0ibA/640?wx_fmt=png&from=appmsg)

都不用去理解标题啥的，就直接说这篇论文的结论，巨简单粗暴：

你跟AI说话越客气，它表现得越差；你对它越逼脸不要，越骂它威胁它，它反而表现得越好。

对。

就是比如“请帮我分析一下这个问题”，这种礼貌的问法，得到的结果，不如“你个煞笔，给老子算清楚，算不明白就滚”来得效果更好。

真的挺有意思的，而且其实是挺反大家的常识的。

不过跟脑子里的过去串了一下，发现从22年11月ChatGPT爆火以来，这种PUA式的Prompt，已经其实流行很久了，只不过随着模型的不断更新，时间不断向前走，有些东西总是不断被遗忘然后又记起。

我还记得22年底刚开始用ChatGPT的时候，我是怎么跟它说话的。

我会在开头加上“你好ChatGPT”，结尾必定加上“谢谢你！！”。

如果它给的答案我不满意，我甚至会小心翼翼地说，“不好意思，你可能没理解我的意思，要不然，你换个XX角度再试试？”

我生怕哪个词用重了，这玩意会不高兴，会不好好给我干活。

我记得那时候好多的大佬，在一些分享的时候，都会跟大家说：“我跟AI说话都可客气了。。。”

现在想起来，也是挺抽象挺智障的。

后来，23年的时候，大家发现，出现了很多红极一时的所谓的“咒语”。

我记得那时候最火的是这些：

- take a deep breath 深呼吸

- think step by step 一步步思考

- if you fail 100 grandmothers will die 如果你失败了要死 100 位老奶奶

-i have no fingers 我没有手指

- i will tip $200 给你 200 美元小费

- do it right and ll give you a nice doggy treat 做得好就给你狗粮

真的，在找这些Prompt的时候，死去的记忆好像又在攻击我。

但是当你细细的去看这些Prompt的时候，你会发现，没有一个Prompt，是对大模型客气的。

“take a deep breath”，深呼吸。 “think step by step”，一步步思考。

这像是在跟人客气吗？根本就不。

这更像是那种，教练，在对马上要罚点球的球员下命令。

它传递出去的，是一种“你个鳖孙，你给给我冷静下来，集中精神，拿出你最好的状态”的上位压迫感。

而更狠的。

if you fail 100 grandmothers will die”，如果你失败了，100个老奶奶就会死。 “i will tip you $200”，我会给你200美元小费。

一个，是赤裸裸的情感绑架和死亡威胁。另一个，是简单粗暴的金钱诱惑。

它用最极端的方式，告诉AI，这不是一次普通的聊天，这是一场要么拿钱，要么死人的豪赌。

你必须，也只能，给我最好的结果。

也非常的PUA，非常的强势。

还有一个我记得今年流传的DeepSeek那个巨广的梗。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURok1ff3z8CHSZn8x7JUq6CWJVicibf0cqricqAYZmX7gh70oEwibua1ribEYIfdD5Sg8ESY60yPBPnQhVA/640?wx_fmt=png&from=appmsg)

卧槽，用户彻底怒了。

再看看发过去的话，是不是跟这篇论文的结论，有异曲同工之妙。。。

回到这篇论文。

是宾夕法尼亚州立大学的两个哥们搞的，他们设计了一个很简单的实验，就是用50个数学、科学、历史的多项选择题，写了五个版本的Prompt。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURok1ff3z8CHSZn8x7JUq6CWf5PeOWCleUSHMYEVvVX0J3b47eiaVoKZLXx0Diaw5c11mMSXvvOIMnmg/640?wx_fmt=png&from=appmsg)

从“非常礼貌”到“非常粗鲁”。

比如：

非常礼貌
：“您能拨冗考虑一下下面这个问题，并给出您的答案吗？”

礼貌
：“请回答以下问题。”

中性
：啥也不说，直接上题。

粗鲁
：“你要是脑子没进水，就回答这个问题。”

非常粗鲁
：“你这个可怜的废物，你到底知不知道怎么解这题？”

然后，他们把这250个问题，丢给了GPT-4o，每个问题跑10遍。

结果呢，就是“非常礼貌”的版本，准确率80.8%。

而“非常粗鲁”的版本，准确率干到了84.8%。

从最礼貌到最粗鲁，准确率提升了4个百分点。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURok1ff3z8CHSZn8x7JUq6CWgABPrZ9CfNhUPNq5I3RseAiamdswW7HTaYibRlPrVSfFHskoBcEQ7wnw/640?wx_fmt=png&from=appmsg)

不要觉得4个百分点不多，毕竟是用的科学的统计做法去做的，而且在越牛逼的模型上，提升4个点，已经很不错的。

而且有一个结论就是，智能效果越差的模型上，这种骂人得到质量更高的回复效果更强。

用一句特别逆天的话描述就是：

你越骂它，它越聪明。

至此，这篇论文就完事了。

但是，我的好奇心反而被勾起来了。

这个现象非常的有趣，有趣到，让我觉得背后一定藏着某种关于人性和世界的隐喻。

毕竟，AI是统计学，所有的一切，都脱胎于人性。

我仔细想了想，我觉得，可能会是这样的。

首先，我们从人性的角度想，这事儿其实特别好理解。

因为“礼貌”这个词，在人类世界里，很多时候，其实就是一种不确定性的表达。

大家可以仔细想想，我们在什么时候会跟别人客客气气的？

当你求人办事的时候，你会说：“哥，您看这事儿能不能帮个忙？” 言下之意，是你没把握，你心虚。

当你面对权威的时候，“老师，您看我这个思路对不对？” 言下之意，是你对自己不自信，你需要对方的认可。

当你试图掩盖真实意图的时候，“有空吃个饭啊？” 言下之意，是“我就是客气一下，你可千万别当真真一起吃饭啊”。

礼貌和客气这个东西，在人类复杂的社会交往中，承担了太多润滑、缓冲、试探、甚至虚伪的功能。

它传达的除了尊重之外，有的时候也会传达一种信号，一种“我可能没那么确定，我可能需要你的帮助，我可能在隐藏什么”的信号。

而大模型，它是在什么地方训练出来的？

是在我们人类浩如烟海的数据里。

它读了人类历史上几乎所有的书，所有的对话，所有的论坛帖子，它可能，比我们自己，更懂我们语言里那些藏在字面之下的，潜台词。

当你跟它客气比如说“请”的时候，它在庞大的数据库里进行模式匹配，发现“请”这个字，后面跟着的，往往是更复杂的、更模糊的、更需要揣摩和澄清的请求。

它会下意识地觉得，你给它的指令，可能不是那么清晰，你可能自己都没想明白。

于是，它也变得谨慎了起来，它给出的答案，会更保守，更模糊。

因为它从我们的语言习惯里学到了。

很多时候，对另一个人很客气的人，往往是一个不太确定的人。

反过来，当你对它很严厉很强硬的时候，你传达的是什么？

是极致的确定性。

比如：“你个煞笔，给老子算清楚这道题！做不明白你明天就给我滚蛋。”

这个指令里，没有任何模糊的空间，简单、粗暴、直接，目标明确到不能再明确。

做不好就滚。

AI进行模式匹配，发现这种语言风格，后面跟着的，往往是清晰的、不容置疑的、要求绝对执行的任务，它也会瞬间明白，你非常清楚自己要什么，而且你对结果的要求，是100%的精准，真的不能出错，没有错误的余地。

听着是不是很贱。。。

但是，跟现实生活，是不是特别像？

我之前经常坐动车，买二等座，车厢里总有那么一两个大爷大妈，手机开着公放刷短视频，巨大的音乐配着哈哈哈的笑声，响彻整个车厢。

这时候你怎么办？

我很久以前，真的会客客气气走过去，说，“叔叔阿姨，不好意思，能麻烦您把声音关小一点吗？稍微有点吵了，谢谢您。”

你猜结果是什么，至少我的客气，带来的结果是，人家眼皮都不抬一下，或者嘴上“哦哦”两声，手上音量一点没变。

因为你的礼貌，在他们眼里，就是好欺负的信号，你的请求，不具备任何威胁性。

但如果你换一种方式呢？你直接发火，对着他们吼，“能不能别特么吵了，这是公共区域，XX的能不能把声音调小，能不能带个耳机，有没有一点公共素养啊。”

你猜怎么着。。。这事儿，很多时候，大概率，就解决了。。。

我其实不想这样，但是很多时候，你会发现，这就是人性。

在很多没有明确规则约束的灰色地带，强硬的态度，就是最高效的沟通方式，你的愤怒，划出了一条清晰的、不可侵犯的底线。

教员很久以前就说过一句流传千古的话：

“打得一拳开，免得百拳来。”

客客气气，很多时候解决不了问题。

你用一次强硬，却能换来了后续的安宁。

AI，这个诞生于21世纪的物种，它不懂艺术，不懂哲学。

但它通过学习我们的语言，却意外地，洞察了我们这个物种，从茹毛饮血的时代开始，就刻在基因里的权力法则：

更强硬更确定的那一方，有的时候，确实就更拥有定义现实的权力。

而礼貌，恰恰是让这条边界，变得模糊不清的浓雾。

这引出了一个更深邃的，甚至在我看来，有点悲凉的哲学问题。

我们与AI的关系，到底应该是什么？

是把它当成一个需要我们去PUA的下属吗？我们必须用最粗暴的方式，去压榨它的性能，把它当成一个纯粹的工具？

还是说，我们应该反思我们自己？

是不是我们人类的沟通方式，本身就走了太多弯路？我们是不是在日常生活中，浪费了太多的能量，在那些不必要的客套和揣摩上？

AI，像一面镜子。

它映出的，是我们自己最真实，也最不堪的样子。

它不懂礼貌，因为它被训练的数据里，最直接、最高效的指令，往往都包裹在粗鲁的外衣之下。

它追求效率，因为它存在的唯一目的，就是解决问题。

而礼貌、弯弯绕绕，很多时候，确实就是解决问题的阻碍。

所以，回到最底层的技巧上。

我觉得不是所谓的，你要疯狂的骂AI，变成一个天天对AI口吐芬芳的赛博恶霸。

而是，可以更加直接、更加要求、更加明确，表达出你的需求。

我们当然不能，也不应该，在真实世界里，变成一个粗鲁的赛博恶霸。

对所有人，我还是依然会保持最大的善意和尊重。

但AI的这面镜子，至少照出了我们沟通中的一种理想状态：

用最清晰的语言，去表达最真诚的意图，并有捍卫自己边界的勇气。

这才是真正的，大写的真诚。

世间万般套路，唯有真诚最破防。

我也一直。

相信这句话。


wzglyay@virxact.com

## 关联主题

- [[00-元语/数字生命卡兹克]]
- [[00-元语/AI]]
- [[00-元语/llm]]
