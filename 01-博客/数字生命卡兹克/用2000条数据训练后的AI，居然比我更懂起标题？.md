---
title: "用2000条数据训练后的AI，居然比我更懂起标题？"
发布日期: 2023-09-24
作者: "数字生命卡兹克"
来源: "微信公众号"
原文链接: "https://mp.weixin.qq.com/s?__biz=MzIyMzA5NjEyMA==&mid=2647659767&idx=1&sn=dfbfb389342f8f83b1814ec24163b5ac&chksm=f1568037f51c99c4cfd4dc7d6552af4f70790ce6d1dd85554fb8b2fdf0efec56d10e51b8a0be"
---

## 摘要

**1) 一句话总结**
作者通过抓取并清洗约2000条爆款文章数据，在文心千帆平台上低成本微调了ERNIE大模型，成功打造出一个能高效生成高质量、网感化标题的专属AI工具。

**2) 关键要点**
*   **核心痛点**：通用大模型生成的标题过于死板，而人工构思爆款标题耗时较长（通常需要30至60分钟）。
*   **数据获取**：借助GPT-4编写代码，从B站、微信公众号、人人都是产品经理和知乎抓取了约6000条爆款文章数据。
*   **数据清洗**：强调数据质量重于数量。利用GPT-4的高级数据分析功能，剔除过长或过短的内容（仅保留1000~4000字符的文章），最终获得1945条干净的数据。
*   **数据格式**：将清洗后的数据处理为文心千帆平台要求的JSONL格式（包含 `prompt` 和 `response` 字段）。
*   **微调配置**：在百度文心千帆平台上创建SFT训练任务，选用 `ERNIE-Bot-turbo-0725` 模型，并采用 LoRA 训练方式。
*   **时间与成本**：整个微调训练过程耗时约1小时，花费约50元人民币（作者对比提及，此前微调GPT-3.5单次花费高达71美元）。
*   **最终效果**：微调后的模型成功掌握了“爆款标题”的范式（如情绪化表达、设问等），在特定任务上的生成质量和效率大幅提升。

**3) 风险/缺口**
*   **数据抓取合规风险**：原文明确提到在抓取各大平台数据时，“这个地方不能细说，因为XX要求”，暗示爬虫行为存在平台限制或合规性敏感问题。

## 正文

写了这么久文章，我一直有一个很强的痛点：

给文章起标题。

真的，起标题太特么痛苦了。

而起一个能让观众愿意点进来的标题，更特么的痛苦。

标题，是你跟观众见面的第一眼，你的内容写的无论再好再牛逼，标题不吸引人，那照样跟观众无缘。

很多媒体人都做过一件事，分析各种爆款标题，学他们写作方法。

但是我这人呢，是个大懒逼。

所以，秉持着
AI让懒逼生活更
美好
的理念。

我干脆，花一些时间，让AI来当我的赛博小编，把取标题这事给我解决了吧~

首先，我们得知道，什么标题能称的上是“爆款标题”？可能每个人都有每个人的喜好，但是我们就用最“科学”的方法：谁的火谁就是对的。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1ZryH5lKIYmdaOIIibNooco6R7ekOrcrZ1zc2S7dPgqcA7WBRy4AxVjw/640?wx_fmt=png)

比如我最喜欢的Lks的标题。

按朋友的话说：“浓烈的情绪化表达，熟悉的设问和反问，吊人胃口的一把好手。”

而各家大模型写出来的都是啥样的标题呢？

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1AOT8sOeicDoktUA4IAZ6ib661tWZH0aHTv3SW246xibVRHgXeLu6hFYaw/640?wx_fmt=png)

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1r5VOkXW2wVfYSGNnDEATqD73EPKssUemwWtWGJtBzhhsALbdMyMiasA/640?wx_fmt=png)

你就感觉，完全没有那个味，一股子正儿八经的劲。

所以，只能自己动手了。

为了
让懒逼生活更美好，我要自己找数据集，微调一个大模型，来专门给我干起标题的这个事。

微调或者训练一个大模型，其实没有大家想的那么复杂，找数据集、清洗数据集、上传训练。三步，完事。

说干就干。

第一步，当然是找数据集啦。

我自己是用GPT4帮我写了代码，抓了B站、公众号、人人都是产品经理、知乎这四个地方的一些爆文。这个地方不能细说，因为XX要求。

所以请找GPT4、智谱AI等大模型帮你写代码去抓，或者找你身边的开发朋友。只能自己去解决。

总而言之，我形成了一个6000条数据的数据集。

第二步，清洗数据集。

数据集的质量，对于训练来说，非常非常非常重要。数量不一定要多，一两千条都够了，但是质量一定要好，不要有一些乱七八糟的东西。

因为我是用文心千帆大模型平台去训练的，所以其实是有标准的数据集格式的，直接照抄就行。

文心千帆网址在此：

https://console.bce.baidu.com/qianfan/data/dataset/list

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1JsfNDAKQibcLHdNRiafENttTQu35kgtVXX4x5WqUicc1iaYtmBTFxibZ6dQ/640?wx_fmt=png)

你只需要创建数据集，选择文本对话，非排序，然后下一步。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1dtcWttNibEEiaCLaCibA4fbw5hvy5AEE81LBR6SQjMoiaKRqXF6IOoueSQ/640?wx_fmt=png)

再选有标注信息，把你的jsonl格式的数据集传上去。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1owd91BB0iabWEp8X56AYrcoAuLcv6NFmRlGkcxCng9zCt2LYC0wJ2hw/640?wx_fmt=png)

数据集的具体格式，按文心千帆平台的要求是这样的：

[{
"prompt"
:
"请根据下面的文章生成标题, 内容如下:<文章内容>\n生成标题如下:"
,
"response"
: [[
"<文章标题>"
]]}]

<>中的内容，替换成你抓过来的信息。

举个例子：

[
{"prompt"
:
"请根据下面的文章生成标题, 内容如下:曾经的抖音直播顶流“交个朋友”团...发展轨迹？我们拭目以待。\n生成标题如下:"
,
"response"
: [[
"三年后，「交个朋友」怎么样了？"
]]}]

可以用GPT4的
Advanced Data Analysis功能
，帮你把数据直接AI处理成这样的格式。

同时也可以让它帮你删除一些太短的和太长的文章，只保留1000~4000字符的文章即可。

最后我处理完以后，还剩1945条干净的数据集。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1TujL44YpyMQLqHzvPxxsvialrq5IpWC6xu4iazenOCYGAcANibURXNTQg/640?wx_fmt=png)

直接传到文心千帆上就行，记得传完了以后点击一下发布。

最后一步，就是愉快又简单的微调训练啦。

得益于文心千帆的傻瓜式操作，你直接点开首页的SFT训练，创建一个新任务。

选择文心自己的那个最新的模型ERNIE-Bot-turbo-0725，训练方式选LoRA，其他的都是默认就行，数据集就选自己的。然后直接开跑。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1NibZibN2rKTrcQf154E7kZUHebzoBFGWZLQOSmQp4NZ5UnPWzj6FH8cg/640?wx_fmt=png)

大概就花个50几块钱就行，真的不贵了。。

毕竟，我微调GPT3.5，特么的微调1次花了我71刀，@&！*…

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1n7xY0bG9F2qgpPibibAecDYhxLdictKz06VEGzP9eHdFuWRbyPgpicgc5w/640?wx_fmt=png)

大概1个小时左右，模型就微调好啦。

咱们直接来验证一下效果！

![](https://mmbiz.qpic.cn/mmbiz_jpg/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1Hb6wdyBAKVy9x43XKPUjRBqE4P6mC4eKeDa7bNianqGYR7Vzno3MjVA/640?wx_fmt=jpeg)

微调前：小红书自营电商关停: 从福利社”到”小绿洲”的探索与失败

微调后：小红书的电商闭环梦，难道又要碎了?

![](https://mmbiz.qpic.cn/mmbiz_jpg/OjgKEXmLURrJCbeWESNHeRbJ56s4VIY1j06icDEHhxjUVCSicNfLAs9X14o55m22QfvVdgZ9GxibSpuBBNb0xC0RA/640?wx_fmt=jpeg)

微调前：
ChatGPT引领Al潮流: 生成式AI产品流量权升，移动优先的GenAl产品薪露头角

微调后：ChatGPT之后，谁可能成为下一个“大赢家”？

这就是我最喜欢的标题范式了！

有“爆款标题”那个味了。

我又随手扔了几篇文章进去，它生成的标题是这样的：

---

字节跳动再战长视频，这次和之前有何不同?

抖音悄悄开店卖衣服，向快时尚大佬们“宣战”

《长相思》爆红，网文IP改编影视剧为何越来越火?

双十一到了，你还在疯狂购物吗?

--

当然，我把我的这篇文章写完了扔给他，这篇文章的标题也是它帮我取的：

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURoB0e1mA9nNKqsVTzl0UJf3dD5gs8NwHKicNubeFdomIEn7HGibIKE15KUB3JDmjibibqrHDNM4MSibPag/640?wx_fmt=png)

泪流满面。

以后我终于不用痛苦的想标题了。

特定微调过的大模型，在一些特定任务中，从效率上能碾压99%的人类，从质量上，也能碾压95%的人类。

以前，我想标题的时间可能都要憋半小时到一小时，要写好几个，让朋友们帮忙挑。

现在，这一个小时的时间，我终于可以拿去做一些更有意思的事了。

再去做更多的特定任务的微调大模型。

把我从另一些事情中再解放出来。

解放的后时间，再去做一些更多的AI。

如此循环。

直到我自己的生活中，不再需要我。

AI，让懒逼生活更____
。

后面这个词该填啥，现在我也不知道了。

⭐～感
恩。

## 关联主题

- [[00-元语/数字生命卡兹克]]
- [[00-元语/AI]]
- [[00-元语/llm]]
