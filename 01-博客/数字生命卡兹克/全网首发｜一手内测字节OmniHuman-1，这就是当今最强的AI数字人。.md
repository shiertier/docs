---
title: "全网首发｜一手内测字节OmniHuman-1，这就是当今最强的AI数字人。"
发布日期: 2025-02-22
作者: "数字生命卡兹克"
来源: "微信公众号"
原文链接: "https://mp.weixin.qq.com/s?__biz=MzIyMzA5NjEyMA==&mid=2647668822&idx=1&sn=1190c35ce6e04230315b770707d3bf35&chksm=f1e47f367a1324b3316299a067bf1d90640fcd6658ea694539f51a3f54ded0cf98a8f7dc629f"
---

## 摘要

**1) 一句话总结**
字节跳动在“即梦”平台上线了OmniHuman-1模型内测，用户仅需提供一张图片和一段音频，即可一键生成支持全身动作、动态背景且口型同步的15秒AI视频。

**2) 关键要点**
*   **核心功能**：通过“1张图+1段音频”生成超逼真的唇形同步AI视频。
*   **技术突破**：打破以往仅能生成面部/头部动画的限制，支持全身肢体动作与动态背景的生成。
*   **平台接入**：该模型已在字节跳动旗下的“即梦”平台上线，对应视频对口型功能中的“大师模式”。
*   **生成规格**：支持任意比例的图片输入（无强制剪裁），一键直接生成长达15秒的带表演和口型的视频。
*   **多场景支持**：实测支持复杂的肢体运动（如弹吉他）、背景人物动态（如行人穿梭），且支持多人同时生成。
*   **工作流简化**：将以往需要调动画、找配音、后期合成的数天工作量，缩短至十几秒钟并支持批量生成。

**3) 风险与不足**
*   **角色识别限制**：目前角色审核与检测非常严格，模型当前仅支持真人角色。
*   **不支持非真人图像**：明确不支持猫狗等动物，且无法识别生成2D/3D拟人角色或侧面角度过大的图像（产品经理确认为当前模型特性限制）。
*   **生成质量瑕疵**：生成的视频画面仍存在部分瑕疵，尚未达到专业影视原片的完美水平。

## 正文

半个月前，字节的OmniHuman-1模型在全球的AI圈，都掀起了巨浪。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpKdOicuCUcbDGtibU5XnAaY7YI1xYJZaPp762hTXoAkAwB36WrXTa9cIeCsGh8fF9c6EMiaMK5y72eg/640?wx_fmt=png&from=appmsg)

可能有些朋友不知道这是个啥，我大概通俗易懂的解释一下：

一张图+一段音频，就能生成超逼真的唇形同步AI视频。

听起来好像是不是之前已经有了？没毛病，这种AI视频我们一般称为对照片说话，我自己之前也写过：
3分钟用AI让照片开口说话，去造属于自己的梦吧。

那时候的效果是这样的：

说实话，这个效果已经很不错了，但是有个最大的问题，就是只能生成面部或者头部的动画，背景、肢体全都没法动，非常的尴尬。

而这一次，OmniHuman-1做了巨幅的突破，一张照片+一段音频，就可以生成背景是动态、支持全身动作的视频，甚至还能保证口型同步。

在我心中，这好像才是真正的Sora该有的样子。

而我等啊等啊等啊。

终于，在今天深夜，我等来了OmniHuman-1的内测。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpKdOicuCUcbDGtibU5XnAaY7qWaKeIVzeAhuOicmxxXSexjZnZWHLYW7ay1YseTJmTXaG7Z5kBibr0gg/640?wx_fmt=png&from=appmsg)

这一次，他们把这个模型也放
在了老朋友即梦上。

视频生成中的对口型上的大师模式，就是
OmniHuman-1。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpKdOicuCUcbDGtibU5XnAaY7JXm7gGj0fayxCp4nsGcun0NrzKA0pvAKtWnuoAgdTHnu6ZKQo0iaptA/640?wx_fmt=png&from=appmsg)

三种模式的描述对比一下：

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpKdOicuCUcbDGtibU5XnAaY7YRevlFvKVicoRC425HHTqWN4sGcNZfribT724QSh7yicosCTWIPNibuAtA/640?wx_fmt=png&from=appmsg)

在我玩了2个小时后，我只能感叹一句：

AI视频中的人物表演，也终于走进了下一个时代。

视频中的人物，再也不是默剧了，让人物开口说话也终于不用先跑一段动态AI视频再换口型了。

只需要一键，就直接生成一段带表演的、带口型的15秒视频。

这就像当年的语音，从TTS，进化到了端到端的声音一样。

酷到爆炸了好吗。

给大家看下怎么用，真的巨简单。

首先，你需要准备一张人物角色图和一段音频。

图的话没啥需要注意的，不同于之前的生动模式会强制剪裁，现在的
OmniHuman-1支持任何比例，同时
我自己测试下来，有个问题比较大，就是角色的审核非常严格。

猫猫狗狗之类的动物不能生存我能理解，但是一些拟人角色，或者稍微侧面一点的，都显示未检测到可用角色，比如我传这个哪吒的图：

![](https://mmbiz.qpic.cn/mmbiz_jpg/OjgKEXmLURpKdOicuCUcbDGtibU5XnAaY7xW3FwnbmujeicbaOGBYLSslRksUD43WE39S8cHNOWSDlpKjYOwDg0CQ/640?wx_fmt=jpeg&from=appmsg)

就会显示这个：

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpKdOicuCUcbDGtibU5XnAaY7yNibaBbj8UepLcSuKbhT7gCQ4hxbGZ4VnB4NZNadRqtNGWtApVff6Vg/640?wx_fmt=png&from=appmsg)

这个我觉得就有一点问题，我就去直接问了下产品经理，是BUG，还是模型特性。产品的回复是：

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpKdOicuCUcbDGtibU5XnAaY7skec2FGIWsn5f1EsbSAP2ibibOzokaGquicibUoLlbIcVqKwqBmfKj0nMg/640?wx_fmt=png&from=appmsg)

至于音频的话，除了真人配音之外，如果想用AI生成，我比较建议去海螺AI，目前我觉得最强的AI语音。我曾经也写过一篇文章介绍：
30秒就能完美复刻你的声音，这就是当今最强的中文AI语音克隆。

https://hailuoai.com/audio

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpKdOicuCUcbDGtibU5XnAaY7SGceFiaEoFIveWpxk8dUpnfyyYhmv0mz8qnuVGyD51cohdiaQhEqnobw/640?wx_fmt=png&from=appmsg)

全部准备就绪上传之后，你只要，点击生成就可以了。

比如我准备了一张哪吒的图片，和一段哪吒2里非常经典的语音。

![](https://mmbiz.qpic.cn/mmbiz_jpg/OjgKEXmLURpKdOicuCUcbDGtibU5XnAaY7xn7TX6qndQzmsNEPqblibRn65WQsicuHiaUv3XjCJt1TVLUsUNCiaho1Uw/640?wx_fmt=jpeg&from=appmsg)

然后，他两直接合成了一段，AI哪吒念诗。

这效果，虽然有一些瑕疵，而且不能跟哪吒2原片段比，但是已经是我见过的，表演最好的了，毕竟你要是真能跟哪吒2片段打个平手。。。

那...AI对于影视的冲击...

我又整了个活，让奥特曼...来搞个花的。

这个运动非常夸张，不仅奥特曼自己的表演是到位的，背景里面的行人也是匆匆，左右穿越，稳得一笔。

又或者这个miku酱弹吉他。

太牛逼了。

再放几个跑的case。

甚至不止单人，连多人...都可以。

AI女团有望。

从以前要调动画、找配音、做后期合成，至少得个把星期的工作量，如今十几秒钟就能完成，还能批量跑，简直让人不敢相信这是现实。

说实话，
这就是我心里那个AI视频2.0时代的标志。

人物不仅动了，还能用自然语音去表达信息，真正把视频当做核心载体，让AI深度参与到表演和叙事中。

这样的想法放在半年前，像极了天方夜谭，可它如今就真实地摆在你面前。

再往后，我们也许要重新思考。

影视、动画、广告、甚至直播，这些传统概念，会不会因为一个AI，而统统被打碎重构？

相信，结论，都在大家的心中。

只是时间上的尺度有不同而已。

科技的长河滚滚向前。

从来不会等待，任何人。

## 关联主题

- [[00-元语/数字生命卡兹克]]
- [[00-元语/AI]]
- [[00-元语/llm]]
