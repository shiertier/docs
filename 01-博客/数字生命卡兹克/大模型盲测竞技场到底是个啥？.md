---
title: "大模型盲测竞技场到底是个啥？"
发布日期: 2025-10-05
作者: "数字生命卡兹克"
来源: "微信公众号"
原文链接: "https://mp.weixin.qq.com/s?__biz=MzIyMzA5NjEyMA==&mid=2647675646&idx=1&sn=570146a4af548f5c6f9db53308de9caa&chksm=f18338c3d4f460e9f7cda57ce7eeaa327bf9c4d84971a7cc32247e5bd19c130d3de21b79c0b2"
---

## 摘要

**1) 一句话总结**
LMArena（原Chatbot Arena）是一个由加州伯克利团队创立的大模型评估平台，通过用户匿名盲测和Elo积分系统来衡量模型的真实应用能力，目前腾讯开源的混元图像3.0在该平台的文生图榜单中击败闭源模型登顶。

**2) 关键要点**
*   **最新动态**：在LMArena最新的文生图盲测排行榜中，腾讯开源的混元图像3.0击败了Banana和即梦4.0等闭源模型，排名第一。
*   **创立背景**：该平台原名Chatbot Arena，由加州伯克利团队于2023年创立。
*   **传统评测的缺陷**：2023-2024年间，大模型评估主要依赖标准化评测集（跑分），导致模型严重“应试化”（高分低能），实际工作表现不佳。
*   **核心机制（盲测）**：用户输入指令后，系统会随机挑选两个匿名的模型（模型A和B）同时生成结果。
*   **投票揭晓**：用户根据个人偏好选出表现更好的结果，做出选择后，系统才会揭晓两个模型的真实身份。
*   **计分系统**：采用游戏行业常用的Elo积分系统，胜出的模型会从落败的模型处赢取积分。
*   **核心价值**：通过全球海量用户的真实投票（用脚投票）决定排名，虽然主观，但能真正客观地反映大模型解决实际问题的能力，正逐渐成为权威且主流的评价标准。

## 正文

昨晚刷到了一条推文。

大概意思就是，LMArena这个大模型竞技场上的排行榜更新了，在用户盲测中，现在文生图第一不是Banana和即梦4.0了。

是腾讯家的混元图像3.0，而且这玩意是开源的，以开源击败闭源。

然后今天又看到了很多人在发，但是也看到了一些群友的讨论，说这个竞技场到底是个啥？啥又是盲测？以及，这个排行榜它靠谱吗。

所以感觉可以简单的聊聊，LMArena这玩意不太一样的地方，还是蛮有意思的。

23年24年的时候，我们判断一个模型牛不牛逼，排行第几，主要靠的是跑分，也就是拿一堆标准化的评测集让大模型去测。

其实就跟我们传统的考试没啥区别，就是纯做题，谁分数高，谁就牛逼。

但是这玩意其实带来了一个现实生活中常常遇到的问题。就是，大模型变得特别特别会做题，非常的应试，但是你真让他干点活，一干一个不吱声。

23年的时候很多国产大模型就是靠跑分宣发，在XX上又超越GPT-4啦，大家懂的都懂。

那时候，天下苦这种应试久矣，就想着，能不能有个更公平的玩意，能真正客观的评价大模型的能力的。

于是，LMArena出来了，这玩意其实之前是23年加州伯克利的极客们搞的，之前的名字叫Chatbot Arena。

最核心的规则，就两个字，盲测。

你在他们的网站上，输入一个指令，比如“帮我画一只太空里的熊猫”，系统会把指令同事发给两个匿名的随机挑选的模型。然后，这两个模型会同时把它们的答案返回给你，一个叫模型A，一个叫模型B。

你要做的，就是你按照自己的品味，选出你觉得更好的那一个。

在你做出选择之前，你完全不知道模型A和模型B，到底哪个是banana，哪个是腾讯混元。

当你做出选择之后，才会揭晓谜底，告诉你刚刚是哪两个模型。

你每一次的选择，都会被计入一个游戏行业常用的Elo积分系统，就是那种你们天天打的排位赛，赢了的模型，会从输了的模型那里，拿走一点积分。

久而久之，经过成千上万次来自全世界各地用户的盲测对决之后，那个积分最高的模型，就是大家用正儿八经的投票，投出来的第一名。

这个就是竞技场的玩法，现在越来越权威越来越主流。

因为它跟传统排行榜最大的不同，在于它衡量的，是真干活咋样。

真的好，用户就会用脚投票。

这个东西，非常主观，但又无比重要。

网址我放在评论区，大家感兴趣的也可以自己去玩一玩。感受一下竞技场的魅力。

以上。

## 关联主题

- [[00-元语/数字生命卡兹克]]
- [[00-元语/AI]]
- [[00-元语/llm]]
