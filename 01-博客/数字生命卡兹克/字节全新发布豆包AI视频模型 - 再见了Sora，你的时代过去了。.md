---
title: "字节全新发布豆包AI视频模型 - 再见了Sora，你的时代过去了。"
发布日期: 2024-09-24
作者: "数字生命卡兹克"
来源: "微信公众号"
原文链接: "https://mp.weixin.qq.com/s?__biz=MzIyMzA5NjEyMA==&mid=2647665433&idx=1&sn=66e23b256bccf3ba5d21864a8be0d1d2&chksm=f1008ed56bae9eac2a2cad91dbd277efd4974f15e1b213b099fceca3fb2fae9203b3f3ac2a31"
---

## 摘要

**1) 一句话总结**
字节跳动正式发布全新AI视频模型“豆包PixelDance”与“Seaweed”，其中PixelDance凭借支持复杂连续动作、多镜头组合及极致运镜控制三大核心能力，大幅提升了AI视频在专业工作流中的可用性。

**2) 关键要点**
*   **发布产品**：字节跳动火山引擎正式发布两款全新AI视频模型——豆包视频生成-PixelDance模型与Seaweed模型。
*   **核心能力一（连续动作）**：突破以往AI视频类似“PPT动画”的局限，能够生成人物复杂的连续表演动作（如摘墨镜、起身、走向目标等），并保持人物比例、肢体和光影的高度一致。
*   **核心能力二（多镜头组合）**：仅需“一张图+提示词（Prompt）”，即可生成风格、场景、角色高度一致的多镜头组合视频（涵盖全景、中景、特写等）。
*   **核心能力三（运镜控制）**：支持通过纯文本提示词实现复杂的摄像机调度，包括360度主体环绕、前后景变焦、摇摄、目标跟随及升降镜头等，且画面稳定性极高。
*   **行业应用**：降低了普通人的视频制作门槛，并使AI视频具备了真正进入影视、广告、动漫等专业工作流的条件。
*   **企业端发布计划**：发布当日优先对企业开启邀测，随后将上线“火山方舟”平台。
*   **C端发布计划**：面向C端大众的“即梦”平台上线时间待定，计划在模型能力进一步优化稳定后全员开放。

**3) 风险与不足**
*   **细节瑕疵**：在部分生成的复杂动作视频中，局部细节（如人物手上的表）仍存在轻微的闪动现象。
*   **C端可用性延迟**：模型太新，仍需时间进行能力优化与稳定性测试，短期内普通C端用户无法直接使用。

## 正文

刚刚，字节的火山引擎的发布会基本结束了。

我现在有点过于激动。

虽然发布会结束了，但是我觉得，一个颠覆行业的全新的起点，在这一刻，正式到来了。

字节正式发布了他们全新的两款AI视频模型：

豆包视频生成-PixelDance模型和
Seaweed模型
。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURoqGJ8ia6kzlT5LCvlZJmvst5mdQicgDKTXibswAJ2TAhxx5WtXA7icoyPDFyOibdrJibr29WLRJd4O2ByA/640?wx_fmt=png&from=appmsg)

Seaweed模型下次我再详细来说。
这次，我想说这个
豆包
PixelDance模型，
因为
太屌了，屌炸了，我真的是全程惊叹着看完的。

他们正式宣布这玩意的那一刻，现场掌声雷动，我隔着屏幕都感觉快特么把房顶掀翻了。

真的，如果要给这个
豆包PixelDance
模型，做一个总结，那就是三个词：

人物的复杂连续动作，
多镜头组合视频，极致的运镜控制。

听着感觉有点难理解是不是？不用急，我一会详细来解释。

我先放几个case，给大家感受一下这玩意的震撼：

真的，影视
行业在之前，几乎没法用AI，就是因为，人物表演太垃圾，还有场景和人物一致性太差，运镜说实话也不咋地。

现在，字节出手，将AI视频推上了全新的高度。

行业颠覆的奇点，就在今天，就在这个发布会上，正式到来了。

而我，在憋了整整4天后，也终于可以发出这篇文章。

对，4天前，我就受字节邀请，提前测过了这个
豆包PixelDance
模型
，当时给我震惊的无以复加，你知道，作为一个博主，测完了这么屌的东西，自然就是想第一时间分享出去，但是因为保密协议，我只能只字不提。

所以你就知道，我这4天，憋的有多难受。

而现在，一切都来了。我终于可以特么的说话了。

说回那三个最重要的特点：

一.
可以做连续动作的人物表演

过往，AI视频有一个很致命的点，就是看起来像PPT动画。

不管是Sora展示出来的视频、还是runway、还是可灵等等，运动幅度再大，也只是镜头幅度大，从来没有人的复杂动作。

顶天了，转个身，或者快速跑个步，或者挥个手，或者拥抱一下。说实话，就单拥抱这个，都没几个AI视频能做出来的。

而如果让图里这个女生，摘下墨镜，站起身，然后走向雕像呢？

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpULIEkBIHLzD0kZkR7yetdRyjBuCf4ibWP3kBtYv7rpRPFRPDfEcT7Uq17mYu26icUjhYUb8e70chg/640?wx_fmt=png&from=appmsg)

所有的AI视频，全部阵亡。

而这一次
豆包PixelDance
，做到了，真的。

除了手上的表有一些些闪动，人物比例、动作、肢体、光影等等，几乎毫无瑕疵。

一个戏好看，人的动作表演，才是最重要的啊。

比如在《喜剧之王》里，在最后一幕，周星驰饰演的尹天仇，在对着柳飘飘喊出那句经典的“我养你啊”的台词之后，柳飘飘坐在离去的出租车里，哭的非常伤心，看了一会手上的钱和表，然后把他们放进包里，拿出尹天仇视为信仰的那本《演员的自我修养》，伤心的抱在胸口。

这段表演，是连续的。连续的东西，才有张力。你才能感受到，那痛彻心扉的情绪。

而现在，用AI，生成可以做连续动作的人物表演，不再是空谈。

再看一个case，男人喝了一口咖啡，然后放下，一个女人从背后走来。

还有，人物表情也很屌，老人笑着笑着，就哭了。

![](https://mmbiz.qpic.cn/mmbiz_gif/OjgKEXmLURoqGJ8ia6kzlT5LCvlZJmvstj6vMQmzX3LUxkeUmSV9A7ibFtCwzicOFs4F0NyzsSjnRTQpPZqeCiaKxQ/640?wx_fmt=gif&from=appmsg)

我也想哭，真的。

去年8月我做《流浪地球3》预告片的时候，我就幻想过无数种关于AI做人物表演的可能。

仅仅一年后的今天，豆包就帮我圆了这个最大的梦。

二.
多镜头组合视频

一张图+Prompt，就能生成风格、场景、人物一致的多镜头视频，这个能力，我只在Sora的宣传片里面看到过。

就是那个著名的一只狼对着月亮嚎叫的视频。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpULIEkBIHLzD0kZkR7yetdFRvfaRibtboGHibUK6ZMw7BCW921hMfoibxvUbIicQXRAOHiaI7EftzUiaibQ/640?wx_fmt=png&from=appmsg)

其实说实话，这个视频当时看，非常的震撼，但是现在看其实也还好，风格、角色和场景都太简单了，所以一致性很好保持，也没啥复杂的故事和分镜。

但就这样，现在，依然没有任何一个AI视频，能做到单视频多镜头，而且还能保证完美的一致性。

别跟我说LTX studio那种玩意，那个做做故事版还行，做正片？洗洗睡吧，别说场景了，人物保持全景、中景、特写统一都难。而且真的丑的出奇。

但是现在，
豆包PixelDance
做出来了，而且一致性简直无敌，真的。

而且，只需要一张图+Prompt就行。

比如，这个。

Prompt：拿着镰刀的死神朝女人走近。特写女人的脸，她惊恐地尖叫。

或者，一场战斗。

Prompt：白色机器人抬起双手拿着一把步枪对着画面左侧不断射击。枪口射出一道绿色的能量光线。镜头变化成画面左侧是一个黑色的机器人，一道绿光从画面右侧快速射入，击中了它的身体，黑色机器人被击倒并爆炸。画面变了，白色机器人望向爆炸，它望向远处的爆炸，转身走出了画面。

又或者，看一个离奇的克苏鲁故事。

一张图和Prompt，就能生成单视频多镜头，屌爆了，真的。

对于影视和广告行业来说，几分钟能瞬间调度后面两三个镜头的分镜，直接出成片。

普通人的使用门槛，也巨幅降低，
人人都是导演，人人都可以做故事的时代。

如今，真的到来了。

三.
极致的运镜控制

豆包PixelDance
模型的运镜，是我见过最离谱，最牛逼的。

现在的AI视频的运镜控制，还基本集中在摄像机+运动笔刷两个功能的组合拳上，但是说实话，上限真的有限，很多大运镜和变焦，根本做不出来。

而
豆包PixelDance
，效果真的就特娘的离谱。

什么鸟瞰缩放上移旋转这种基操我就不说了，关键是，
直接一句话，各种360度围绕主体环绕、前后景变焦、
摇摄、目标跟随、升降镜头什么玩意都行。

效果出奇的好，我第一次见到，在AI视频，运镜能这么牛逼，这么炫酷的。

直接看case。

Prompt：
女人微笑着低下头，镜头拉远，一个白人男人注视着这个女人。

变焦的极度自然顺滑，无敌，太无敌了。

还有这个，360度大幅度环绕运镜。

Prompt：黑白风格，镜头环绕着戴墨镜的女人拍摄，从她侧面移动到正面，最后聚焦于女人的面部特写。

这是一张图，然后一句Prompt干出来的，你敢信？这动作幅度，这稳定性，比特么建模出来的还离谱，我真的服了。

你这让摄影们还怎么玩，疯了啊...

写在最后

Sora一个巨型期货，从2.16号到如今，迟迟不见任何踪影。

而后，6.6号，可灵默不作声，正式上线，代表了中国Sora的输出。

而今天，9.24号，字节再把AI视频，推向一个全新的高度，是一个在Sora的宣传片里，都看不到的高度。

至此，
中国不需要Sora，豆包模型就是天。

豆包PixelDance
也不需要什么中国版Sora的外号，
豆包PixelDance
就是
豆包PixelDance
，
他就是现在AI视频的天。

也至此，AI视频不再是玩具，而是真正的，可以进入到影视、广告、动漫工作流中，带来一些全新的想象。

这一枪，由我们打响。

今天这个
豆包PixelDance模型，就会优先对企业开启邀测，过几天上线火山方舟，至于啥时候上线即梦向C端用户全员开放，可能还得等一段时间，毕竟太新，他们说还想再优化优化模型能力，稳定了以后，就直接上线即梦，给全员开放了。

真的，也从来没有什么奇迹，一切都是沉淀多年的积累，一切都是如约而至。

今天，我也可以喊出那句台词：

字节，No.1！

## 关联主题

- [[00-元语/数字生命卡兹克]]
- [[00-元语/AI]]
- [[00-元语/llm]]
