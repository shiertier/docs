---
title: "一个被忽视的Prompt技巧，居然是复制+粘贴。"
发布日期: 2026-01-22
作者: "数字生命卡兹克"
来源: "微信公众号"
原文链接: "https://mp.weixin.qq.com/s?__biz=MzIyMzA5NjEyMA==&mid=2647679125&idx=1&sn=72ace866ecc8bd528ebfc802a96e66b9&chksm=f13960b23e0edd9c927351ea1d5b7affd3f13cbc10840923d93ab14f3c7b9785a1158040dd66"
---

## 摘要

**1) 一句话总结**
根据Google的最新研究，通过简单地重复输入提示词（直接复制粘贴问题），可以显著提升非推理类大模型在各类任务中的准确率，部分任务的准确率可从21.33%提升至97.33%。

**2) 核心要点**
*   **操作方法**：无需添加额外指令（如“请”、“一步步思考”等），只需将原问题直接复制粘贴重复一次（即 `<问题><问题>` 格式）即可生效。
*   **实验数据**：在70个基准模型组合测试中，该技巧赢了47次，平局23次，0次失败，所有测试模型的性能均得到改善。
*   **测试模型**：实验涵盖了7款主流非推理模型，包括Gemini 2.0 Flash/Flash Lite、GPT-4o/4o-mini、Claude 3 Haiku/3.7 Sonnet以及DeepSeek V3。
*   **测试基准**：涵盖ARC、OpenBookQA、GSM8K、MMLU-Pro、MATH等常见测试集，以及论文设计的NameIndex（姓名索引法）和MiddleMatch（中间匹配法）。
*   **生效原理**：大模型属于“因果语言模型”（从左往右逐词预测）。重复输入使得模型在读取第二遍问题时，能够“回头看到”第一遍的完整上下文信息，从而生成更准确的选项表征。
*   **衍生技巧**：实验发现，将提示词重复三遍等衍生操作同样能提升模型效果。
*   **未来方向**：论文提出的后续研究方向包括将重复机制写入模型训练/微调流程、仅在KV Cache中保留第二遍提示以优化推理性能、仅重复部分提示词，以及在图像/视频等多模态领域应用。

**3) 风险/局限**
*   **适用范围局限**：该技巧主要针对非推理类大模型。对于推理模型（如DeepSeek R1），由于其在生成思维链（思考过程）时通常会自动复述问题，因此该技巧对其基本无效。

## 正文

前两天，我在网上发现了一个关于很有趣Prompt技巧。

就是，通过重复输入提示词，可以将非推理类大模型的准确率，从21.33%提高到97.33%。

这个技巧，出自Google的一篇好玩的新论文。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpSib6zyXsy8qgZEWaLzWmujgGZmgUic31pdZxUAeWgNNT7E5tsibibkRR0ul0Z2Mn4ib6iaOp3ficQYEQnw/640?wx_fmt=png&from=appmsg)

叫《Prompt Repetition Improves Non-Reasoning LLMs》。

翻译过来就是：

重复你的问题，能让AI变得更聪明。

听着是不是非常抽象，其实巨简单。

比如你以前问AI：“梵蒂冈的那个圣伯多禄大教堂门口有几根柱子？”

现在，你可以改成问：“
梵蒂冈的那个圣伯多禄大教堂门口有几根柱子？
梵蒂冈的那个圣伯多禄大教堂门口有几根柱子？
”

对，不是我多复制了一遍，其实，这个Prompt技巧，就是把问题，重复一遍，也就是传说的CV大法。

Ctrl C + Ctrl V。

就这，根据Google的实验，他就能让AI回答正确的概率，就会有显著的提升。

在70个不同的测试任务中，这个简单的复制粘贴大法，赢了47次，一次都没输过。而且性能提升是肉眼可见的，在某些任务上，准确率甚至能从21%直接飙到97%。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpSib6zyXsy8qgZEWaLzWmujXmn1cibJicU9R5fpoGLJGzmmAwVq3lWNne82jql5cjYGiad7oLJLAQSxw/640?wx_fmt=png&from=appmsg)

真的，当我第一次看到这个结论的时候，我的表情，是这样的：

( ´･･)ﾉ(._.`)？？？？

这感觉，就像你千辛万苦爬上喜马拉雅山顶，想求见传说中的武林宗师，结果宗师摸着胡子告诉你，天下第一的武功秘籍，就五个字：
“大力出奇迹”
。

尼玛。

充满了B级片的荒诞感。

但你先别急着笑。

我花了一点时间，把这篇看着简单的论文，以及它背后的一些原理琢磨了一下之后，我觉得，这玩意，是真的有点意思和道理。

先说说Google的这个实验。

他们找了七个现在市面上最常见的一线非推理模型，Gemini 2.0 Flash跟 Flash Lite，GPT-4o和4o-mini，Claude 3 Haiku、3.7 Sonnet，再加一个DeepSeek V3，全部用官方 API，老老实实在各种基准上测了一轮。

这里需要注意一下，这种Prompt技巧，几乎都是对非推理模型有用，DeepSeek V3就是非推理模型，DeepSeek R1就是推理模型。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpSib6zyXsy8qgZEWaLzWmujwrdDSfokrsYAl02e8b8uHpYTyz6Tw80xJQnDEic7NyS0uibzsEoTOljQ/640?wx_fmt=png&from=appmsg)

当你开了深度思考，有这个正在思考的，有这种思维链的，就是推理模型。

非推理模型和推理模型有好有坏，核心区别自然就是速度和准确性，推理模型很多时候速度太慢了。

比如我经常让GPT 5.2 Thinking帮我干个活或者搜个东西，思考一下，就是8分钟过去了。。。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpSib6zyXsy8qgZEWaLzWmujZRvEd3pZrQ7cNmgkCz5gQl1pica7oUP8Iz5ZI6tsCqZ0f0kA3hqIvpQ/640?wx_fmt=png&from=appmsg)

但是好处就是准。

非推理模型，没有思考，上来就是干活，速度非常快，但是相对于的，就是经常不准。

而现在这个复制大法，可以让你的非推理模型在速度不变的情况下，准确性飙升，所以，在很多场景下，还是非常有用的。

说回实验，他们找了7个模型测试，测的内容也都耳熟能详，ARC、OpenBookQA、GSM8K、MMLU-Pro、MATH等等一些常见的测试集，还有他们自己设计的两个怪东西，NameIndex和MiddleMatch。

NameIndex叫姓名索引法，大概就是给模型50个名字的列表，问它第25个是谁。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpSib6zyXsy8qgZEWaLzWmujibdRIPDzohPnAuBB7YgggAmdZhO626pdgTOLqo08c4WERibzUN8aOPaQ/640?wx_fmt=png&from=appmsg)

MiddleMatch就是中间匹配法，就是给模型一个会随机重复且包含多个名字的列表，问他两个字符之间的那个名字叫啥。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpSib6zyXsy8qgZEWaLzWmujAFAojymHmSIdmT44ARoJxQ24V6RY7aMPa5wzyykHleFGHZiaJkJibm6g/640?wx_fmt=png&from=appmsg)

讲道理他们设计的这两个小测试，还是挺有趣的。

然后呢，他们就做了一件看起来特别没有技术含量的事情。

以前我们问模型，是这样问的：

<问题>

他们变成这样然后去对比：

<问题><问题>

一模一样，再来一遍。

中间不加解释，不说please，不说think step by step，不加别的Prompt，不贴示例，就真的只是在原问题后面连着又粘了一次。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpSib6zyXsy8qgZEWaLzWmujliccibibP6iaxVZanDBwuNbpwvsXu6gicEVZ4bp3icSRoDlQD8qx1RWw9qCA/640?wx_fmt=png&from=appmsg)

然后成功率就暴涨，就是我们开头说的数据，他们自己的原话是：

“据此标准，提示重复在70个基准模型组合中赢得了47个，0个失败。值得 注意的是，所有测试模型的性能都得到了改善。”

在 70 组原始提示词 vs 复制一遍的对比里，这个土味招数赢了 47 次，平了 23 次，一次都没输。

非常离谱。

他们还根据这个复制粘贴大法，搞了一些衍伸Prompt技巧，比如重复三遍啥的，发现效果也会同样变好。

为啥复制一遍，会有效果呢？

论文里面给了一个很工程的解释，大概就是大模型训练的时候，是“因果语言模型”，也就是那种从左往右一个词一个词预测的风格。

当前这个token，只能看到之前的那些，没法提前看到后面的。

所以，当你把问题重复一遍，比如
从
Q
变成
Q1Q2
，
那么
Q2
里的每一个字，在计算的时候，就能回头看到
Q1
里的所有内容。

等于给了AI一次“回头看、再思考”的机会。

听着很难理解对吧。

我还是用大白话举个例子。

现在，你给AI一个选择题，这个选择题可能会有点绕：

选项：
A
. 把蓝色方块放到红色方块左边
B
. 把红色方块放到蓝色方块左边
场景说明：
现在红色在左，蓝色在右。
问题：
哪一个选项会改变画面？只输出
A
或
B

如果你现在是AI，你就是一个类似于在看视频字幕的人，当你读到 A、B 的时候，你还不知道当前画面到底谁在左谁在右。你对A、B的第一印象就会很空，像是两个差不多的句子。

等你读到后面的场景说明，你当然知道答案该怎么选，但那个字幕已经过去了，你又没法往回拉进度条，已经没法回头重新读一遍A、B来更新第一印象了。

那我们现在按照论文的做法，把整段复制一遍。

选项：
A
. 把蓝色方块放到红色方块左边
B
. 把红色方块放到蓝色方块左边
场景说明：
现在红色在左，蓝色在右。
问题：
哪一个选项会改变画面？只输出
A
或
B
选项：
A
. 把蓝色方块放到红色方块左边
B
. 把红色方块放到蓝色方块左边
场景说明：
现在红色在左，蓝色在右。
问题：
哪一个选项会改变画面？只输出
A
或
B

第二遍的A、B出现时，其实已经包含了第一遍的完整信息，所以模型这次读到选项时，脑子里的小卡片会带着场景条件一起生成。

于是它在最后输出A或B时，能直接调用一份更懂题的选项表征，准确率就更容易上去。

就很像你第一次看《流浪地球2》或者《盗梦空间》，可能第一次很多地方没看懂，但是当你第二次看的时候，你一定会有更加全面、更加新的领悟。

这就是重复的力量。

重复，其实就是给我们，给AI，多一次重来的机会。

而这种Prompt技巧，之所谓对DeepSeek R1这种推理模型没啥用，其实原因也特别简单，很多通过RL微调出来的会推理的模型，其实已经自己学会这个技巧了。

你让它推理的时候，它第一反应经常就是先把问题复述一遍。

你可以仔细回想一下很多模型的回答开头：

“题目问的是……”

“我们需要求解的是……”

“首先我们需要理解题目给出的条件……”

本质上，它已经在自动多抄一遍题目，给自己重新排了次版。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURpSib6zyXsy8qgZEWaLzWmujKEUdQwHicic7YHJndNoU6ZD6iasfedDWzdl3ZTE6yrl4CCHo02aJlk3xw/640?wx_fmt=png&from=appmsg)

我说实话，我读这个小短文的时候，一直有一个特别强烈的感觉：

我们一直以来，对Prompt工程的想象，一直都太浪漫了。

总觉得好的提示词，应该是：

结构清晰，层层递进，有role、有 rule、有context、有format，有点像咨询公司做的 PPT，一页一页讲逻辑，最后抛给模型一个完美的问题。

过去两年，大模型相关的内容里，Prompt也经常被讲成一种玄学。

写提示词像下咒语一样，要讲究格式、口气、敬语，要学一堆咒语模板，甚至要背prompt手册。

我其实一直都不太提倡，所以前段时间，还写了我自己的所谓的Prommpt心法：

分享6个平时我最常用的Prompt心法。

但其实说真的，对很多纯粹的问答场景，尤其是短问题，模型压根不需要你在提示词上搞太多花活。

你只要安安静静，把题目再重复一遍，就已经是一个极其强力的优化。

Google论文里面的未来方向，也写了一些。

比如：把重复提示这件事，写进模型的训练流程里，让模型从预训练或者微调阶段就习惯这种结构；或者只在 KV cache 里保留第二遍的提示，让推理阶段的性能完全不受影响；或者只重复提示词的一部分，而不是整段全文；甚至还可以考虑在多模态里重复，比如图像、视频。

我们总是希望用复杂的语言解决问题，结果发现，有时候最有效的是那句顺嘴又重复的话。

这件事其实跟很多我们熟悉的领域一样。

人类社会其实一直在用复制粘贴这个技能，只不过给它起了很多体面的名字：

复述、强调、排比、朗诵、咏唱、抄经、背诵、晨读、开大会、宣誓、校训等等。

我倒是突然想起一个很私人化的画面。

有一阵我数据确实不是很好，感觉内容怎么写都没人看，方向也有问题，然后本来情绪特别糟糕，还有一堆其他的项目管理的事、各种意外发生、然后身体也不太好。

那天跟朋友聊微信，实在没崩住，哭诉了几句。

对方只发了一句特别简单的话：

“你已经做得很好了。”

我回了一个“哈哈哈，哪有”。

过了几分钟，他又发了一遍，还是同一句。

大概又隔了十几分钟，他第三次发过来：

“你已经做得很好了，真的。”

那一瞬间，我突然就没绷住。

人类的很多情感，其实都是靠重复才能构筑的。

从这个角度看，复制粘贴这事，好像也没那么卑微。

爱一个人是日常的复制粘贴，专业是一辈子的复制粘贴，写作是对一些想法一遍又一遍的复制粘贴，

直到有一天，这些东西都不需要你刻意想起，它们自动从你的手指和眼神里长出来。

AI 的世界，很大一块其实就是压缩过的人的世界。

当你下一次在终端里敲下那一长串Prompt的时候，也许可以在末尾多敲一次 Ctrl+V。

同样，当你下一次觉得人生很乱的时候，也许可以找一两句你真心认同的话，写在记事本、手机备忘录、贴在桌边墙上，反复去看。

从一堆token里看到真正的重点，需要的是几次重复后的清晰。

而从一地鸡毛里看到一点点意义，生活，很多时候也是这样。

高山之流水。

万物皆重复。


wzglyay@virxact.com

## 关联主题

- [[00-元语/数字生命卡兹克]]
- [[00-元语/AI]]
- [[00-元语/llm]]
