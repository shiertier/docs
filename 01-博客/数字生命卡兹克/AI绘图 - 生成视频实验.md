---
title: "AI绘图 - 生成视频实验"
发布日期: 2023-03-02
作者: "卡兹克"
来源: "微信公众号"
原文链接: "https://mp.weixin.qq.com/s?__biz=MzIyMzA5NjEyMA==&mid=2647657713&idx=1&sn=d737d5d1ca33ca331b4adcdec45aea13&chksm=f1af5e8a795968fff3ac4c5b0f227ebc9671db3374ce5060fa152a0890ab14e3c5d656ba93f6"
---

## 摘要

**1) 一句话总结**
本文记录了利用Stable Diffusion的mov to mov插件进行AI视频转视频生成的实验，指出了当前技术的算力与稳定性局限，并提示了相关生态的合规风险。

**2) 关键要点**
*   Stable Diffusion生态新增了直接进行视频转视频（mov to mov）的插件功能。
*   AI生成视频的理论基础是利用ControlNet插件固定动作、LoRA模型固定脸部，将视频拆分为序列帧（如24帧/秒）逐帧渲染后再进行拼接。
*   B站开发者（@瑟瑟发抖的小丁同学）推出的mov to mov插件实现了全自动渲染，免去了手动逐帧处理的庞大工作量（如10秒视频需处理240张图）。
*   实验表明，当前直接生成的视频效果不够稳定，若追求精致画面需依赖达芬奇等软件进行后期稳定处理。
*   渲染过程对算力要求极高，使用RTX 3060显卡渲染十几秒的视频需耗时约2个小时。
*   作者预测AI视频生成技术将快速进化，未来换脸、换衣、换人等技术将趋于普及和常态化。

**3) 风险与不足**
*   **技术与硬件局限**：当前生成的视频画面效果不稳定，且对硬件算力要求高、渲染耗时极长。
*   **法律与合规风险**：目前大多数相关的AI生成生态游走在违法边缘，使用者需保持警惕并控制自身行为。

## 正文

最近又有大佬开发了
stable-diffusion的插件，AI
绘图
继续升级，可以直接视频转视频。

其实以前就设想过场景，因为
stable-diffusion
有神器级的C
ontrolnet插件，可以固定动作直接将某一张图渲染另一张图，视频嘛，其实也就是24张/秒或60张/秒拼起来的东西，那完全可以把视频渲染成序列帧用Controlnet插件固定姿势，Lora模型固定脸部，一帧一帧的渲染出来，最后再用PR或者AE拼成一个视频。

当然想想也就是想想，一张一张的渲染，10秒钟的24帧视频，就有240张图片了。。。工作量太大了。

但是感谢B站@
瑟瑟发抖的小丁同学，开发了mov to mov的插件，太猛了，解放双手，导进去视频，出来是一个生成好的视频。

下面这个就是AI生成的实验。

效果其实还是不太稳定，求精致的话需要达芬奇去做后期稳定处理，并且对算力邀请还是挺高的，十几秒的视频，我3060渲了2个小时才完事。

即使效果一般，但是往后看，未来的空间，这想像力再一次被拉高。

我觉得就以现在的进化速度，生成稳定的AI视频要不了多久了，换脸换衣服换人可能成为未来不太新鲜的技术。

只能说，新技术固然好玩，但现在我看到的大多数生态，都在违法的边缘游走。

警惕吧。控制住自己。

关于ChatGPT的兄弟 - AI绘图的小思考

AI绘图傻瓜指南 - 5分钟带你生成你的专属AI妹子

## 关联主题

- [[00-元语/数字生命卡兹克]]
- [[00-元语/AI]]
- [[00-元语/llm]]
