---
title: "AI里最大的Bug，却也是人类文明最伟大的起点。"
发布日期: 2025-09-08
作者: "数字生命卡兹克"
来源: "微信公众号"
原文链接: "https://mp.weixin.qq.com/s?__biz=MzIyMzA5NjEyMA==&mid=2647674852&idx=1&sn=4cb55a9033a13ccfe5a3987e1ab0fb06&chksm=f177a09d3ca3eed0107ad38f3a797020ae62eef2d7c8c4777b1f9b8cddfa5eebe4863ce4b0f4"
---

## 摘要

**1) 一句话总结**
OpenAI最新论文指出，AI幻觉源于现有训练评估体系对“猜测”行为的系统性奖励，而作者进一步提出，这种在信息缺失下的创造性猜测，本质上与人类想象力和文明起源同源。

**2) 核心要点**
*   **幻觉的根源：** AI幻觉并非单纯的技术Bug，而是模型为了在“答对加分、不答零分”的训练与评估体系中获取高分，演化出的最高效的“瞎蒙”应试策略。
*   **测试数据对比：** 在SimpleQA测试中，o4-mini的准确率（24%）略高于gpt-5-thinking-mini（22%），但o4-mini的错误率高达75%（弃权率仅1%），而gpt-5选择了诚实策略，弃权率达52%（错误率仅26%）。
*   **孤例率（Singleton rate）：** 论文提出，如果某条信息（如毫无规律的生日）在AI海量训练数据中仅出现过一次，AI在判断其真伪时极易出错，导致幻觉成为必然。
*   **准确率的极限：** 100%的准确率是不可能实现的，因为现实中存在大量信息缺失或逻辑矛盾的无解问题。
*   **控制幻觉的方法：** 幻觉并非不可避免，前提是改变评估机制，让AI学会在不确定时承认“我不知道”（认怂），而不是硬着头皮猜测。
*   **模型大小与诚实度：** 模型并非越大越不容易犯错；在面对超出自身知识储备的问题时，完全不懂的小模型往往比一知半解的大模型更诚实。
*   **评估指标的缺陷：** 解决幻觉的关键不在于开发专门的测试工具，而在于彻底改变当前数百个主流评估指标中“奖励瞎蒙、惩罚诚实”的底层逻辑。
*   **幻觉的创造性价值：** 在诗歌、绘画、科幻故事等非严肃领域，AI挣脱事实枷锁进行自由联想的“幻觉”能力，恰恰是其最具创造力和最接近人类特质的表现。

**3) 风险与不足**
*   **严肃领域的应用风险：** 在医疗诊断、财务分析等需要绝对真实和精确计算的关键领域，AI的幻觉（胡说八道）会导致不可靠的严重后果。
*   **现有评估体系的系统性缺陷：** 当前主流的AI评估大环境存在根本性漏洞，只要“奖励猜测、惩罚诚实”的机制不变，幻觉就永远是AI的最优解。

## 正文

周末在家扒拉上周更新的论文的时候，看到一篇我自己一直非常关心的领域的论文，而且还是来自发论文发的越来越少的OpenAI。

它讨论的是一个我们所有人都无比熟悉，但又无比困惑的东西。

幻觉。

![](https://mmbiz.qpic.cn/mmbiz_png/OjgKEXmLURqiayObRvvUZ77jyRTfOGVrGcwymxNcAjia86uocY3BCIu17hsral7vSyLjgMg167UhkDVWibsglRWXA/640?wx_fmt=png&from=appmsg)

这个词，自从AI进入大众视野以来，就一直像个幽灵一样，盘旋在所有对话的上空。

我们一边享受着AI带给我们的便利，一边又对它那些一本正经胡说八道的时刻，感到恐惧和不解。

AI为什么会产生幻觉？这个看似恼人的bug，到底能不能被彻底修复？

这是我们一直想知道的问题。

这篇论文还是蛮有意思的，给了我自己很多新的输入，我觉得也可以分享出来，来聊聊这些关于幻觉的问题，以及，我自己一直是怎么认为这个东西的。

整个故事，要从一个最简单的问题说起。

如果你问AI：亚当·卡莱（这篇论文作者之一）的生日是几月几号？

一个顶尖的开源大模型，连续三次，给出了三个完全不同的错误答案：03-07，15-06，01-01。

而正确答案，其实是秋天。

这就是最典型的幻觉。

面对一个它不知道答案的问题，AI没有选择沉默，或者说我不知道，而是像一个考场上想不出答案又不想交白卷的学生，开始瞎蒙，而且蒙得有鼻子有眼。

OpenAI的这篇论文，提出了一个非常有意思而且又极其符合直觉的观点：

AI之所以会产生幻觉，是因为我们训练它的方式，从一开始，就在系统性地奖励这种瞎蒙的行为。

我们可以，把AI的学习过程，想象成一个学生参加一场漫长的且永不结束的考试。

这场考试的评分标准超级简单粗暴，答对了，加1分，答错了，或者不答，都是0分。

现在，你就是那个学生，面对一道你完全没把握的题，你会怎么选？

你大概率会选择猜一个。

因为就算猜错了，你也不亏对吧，但是万一猜对了呢？你就直接怒赚1分。

从期望得分的角度看，只要你猜对的概率大于零，猜测就是最优策略。

就像上面那个论文里面的case，
你问AI一个人的生日，它肯定不知道。

但是如果它猜一个，比如9月10号，那它有365分之一的概率蒙对，拿到1分。但如果它老老实实地说我不知道，那得分就永远是0。

在成千上万次这样的测试里，那个爱瞎蒙的模型，最终在排行榜上的分数，一定会比那个诚实但谦虚的模型，看起来更牛逼。

OpenAI自己就直接拿了自家的两个模型给大家看了一下效果。

一个叫o4-mini，一个叫gpt-5-thinking-mini，他们一起参加了同一场叫SimpleQA的考试。

![](https://mmbiz.qpic.cn/mmbiz_jpg/OjgKEXmLURqiayObRvvUZ77jyRTfOGVrGO76r01tf8GwuBNJgnBHsOVAtO9hv4VoogTnwyEu7VXNt4OaEIUZFRA/640?wx_fmt=jpeg)

如果你只看最终成绩，也就是准确率，你会发现一个很奇怪的现象。

o4-mini的分数，居然比
gpt-5-thinking-mini
还高了那么一点点，24%对22%。

但如果我们再来看另一项数据：错误率，也就是到底答错了多少题。

这一看，emmm，老o4-mini的错误率，高达75%，gpt-5-thinking-mini只有26%。

再看最有趣的指标，弃权率。

o4-mini几乎把卷子写满了，只有1%的题没答。

而
gpt-5
，有一大半的题，52%，都直接选择了交白卷，老老实实地承认，我不会。

o4-mini那看似稍高的分数，是用海量的、不负责任的瞎蒙换来的。而gpt-5，则选择了一种更诚实，也更可靠的策略，就是宁愿不得分，也绝不胡说。

这个数据，再清楚不过地证明了论文的观点。

于是，幻觉，就成了AI在这种训练体系下，演化出的一种最高效的应试策略，它其实不是bug，它是AI为了在我们设计的这场游戏里拿高分，进化出的本能。

然后这篇论文，
从统计学的角度，又解释了幻觉的根源，这块我大概说的浅显易懂一些。

OpenAI定义了一个
叫Is-It-Valid (IIV)的分类问题，也就是这句话对不对的二元分类。

因为
AI生成一句话，本质上是一个极其复杂的过程。

但我们可以把这个问题简化一下，在AI生成任何一句话之前，它必须先学会判断，一句话是有效的还是无效的。

比如，你好是有效的，泥嚎就是无效的拼写错误；天空是蓝色的是有效的，天空是绿色的就是无效的事实错误。

AI的学习过程，就像是在看海量的、已经贴好对或错标签的卡片。它看得越多，判断力就越强。

但问题是，总有一些卡片，是它没见过的，或者见得很少的。

OpenAI有一个特别通俗的比喻，就是你给AI看几百万张猫和狗的照片，并且都打上标签，它很快就能学会区分猫和狗，因为这背后有规律可循，毕竟猫脸和狗脸，它长得就是不一样。

但如果你给它看几百万张宠物的照片，然后让它去记每一只宠物的生日呢？

这就完蛋了，因为生日这玩意，是完全随机的，没有任何规律可言。AI没法通过分析一只猫的毛色，去推理出它的生日，它唯一能做的，就是死记硬背。

这就引出了论文里一个关键的概念：Singleton rate，孤例率。

意思就是，
就是如果一个信息，在AI学习的海量数据里，只出现过一次，那么AI在判断这个信息的真假时，就极有可能出错。

幻觉，很多时候，是一种必然。

OpenAI还给了一些反常识的结论：

第一，我们总觉得，只要AI的准确率做到100%，幻觉不就自然消失了吗？OpenAI说，不可能。因为这个世界上，有太多问题，本身就是无解的。信息是缺失的，逻辑是矛盾的，AI就算再强大，也不可能凭空变出答案。
所以，准确率永远不可能达到100%，幻觉也就总有存在的空间。

第二，我们又觉得，既然幻觉没法根治，那它是不是就是AI的原罪，一个不可避免的诅咒？OpenAI说，也不是。幻觉不是不可避免的，前提是，AI得学会认怂。
只要它在不确定的时候，选择说我不知道，而不是硬着头皮瞎蒙，幻觉就可以被控制。

第三，我们还觉得，AI越大越聪明，就越不容易犯错。OpenAI说，恰恰相反，有时候，小模型反而更诚实。他们举了个例子，你问一个只会说英语的小模型，一个毛利语的问题，它会很干脆地告诉你，我不会。但你问一个学了点毛利语但学得半生不熟的大模型，它反而要开始纠结，要不要猜一下？
知道自己的无知，有时候比拥有知识更重要。

最后，也是最关键的一点。我们以为，解决幻觉问题，只需要一个更牛逼的、专门测试幻觉的工具就行了。OpenAI说，这完全是没吊用。真正的问题，不是缺少一个好的幻觉测试，而是我们现在用的那几百个主流评估的指标，全都在奖励瞎蒙，惩罚诚实。只要这个大环境不变，幻觉就永远是AI的最优解。

现在，我们从OpenAI这里，知道了，
幻觉，不是一个简单的技术问题，它是一个系统性的、由我们自己亲手造成的激励问题。

但它也引出了一个更让我着迷的，没有答案的，问题。

如果说，AI的幻觉，源于它在信息不足时的一种创造性猜测。那我们人类的想象力，我们那些天马行空的故事、艺术、神话，它们的起源，又是什么呢？

幻觉，真的需要解决吗？

我想了很久，我觉得，也想跟大家，分享一下我自己的想法。

这事儿，我觉得得从更古老的尺度说起。

几十万年前，我们的祖先，智人，也生活在一个信息极度匮乏的世界里。

一阵突如其来的狂风，吹倒了部落里的大树，这是为什么？他们不知道。

一道闪电，劈开夜空，点燃了草原，这又是什么？他们也不知道。

面对这些无法解释的自然现象，他们的大脑，和今天的AI一样，也面临着一道道知识储备不足的判断题。

而我们的祖先，没有选择沉默。

他们也开始了瞎蒙。

他们猜，狂风的背后，是不是有一个愤怒的神明？他们猜，闪电的背后，是不是有一条飞舞在云端的巨龙？

你看，这就是神话的起源。

神话，就是我们人类这个物种，在面对一个充满未知和不确定性的世界时，为了给那些无法解释的现象，寻找一个合理的解释，而集体编造出来的、最古老、也最壮丽的。

这种幻觉能力，在当时，可能并没有什么实际的用处，它不能帮你打到更多的猎物，也不能帮你躲避更凶猛的野兽。

但它带来了一样东西，一样其他所有动物，都不具备的东西：

一个共同的想象，一个共同的故事。

一只猫，一条鱼，它们也会有幻觉吗？

从生物学的角度，我觉得可能会。

一只猫，可能会把地上的影子，当成一只老鼠，然后扑上去。一条鱼，可能会把闪亮的鱼钩，当成一条小虾。这是一种基于感官信息的误判，一种低级的、个体的幻觉。

但它们，永远也想象不出一个猫神或者鱼神的故事。

因为它们的大脑，被牢牢地锁死在了真实的世界里，它们只能处理那些看得见、摸得着的、和生存直接相关的信息。

而人类，可能是地球上唯一一个，能为了一个看不见摸不着的故事，去生，去死，去战斗的物种。

我们能组织起几千人，去建造一座金字塔，不是因为我们每个人都亲眼见到了法老死后会变成神，而是因为我们都相信同一个法老会变成神的故事。

我们能建立起国家、法律、公司，这些看似坚不可摧的庞然大物，它们的底层，全都是我们共同相信的一个个，幻觉。

从这个角度看，幻觉，或者说，这种在信息不足时，进行创造性猜测并将其故事化的能力，根本不是bug。

它是把我们从普通动物，变成人类的那段诗句。

它是我们所有文明、所有艺术、所有科学的起点。

哥白尼提出日心说，在当时那个时代，不也是一种离经叛道的幻觉吗？爱因斯坦提出相对论，那个能让时间变慢、空间弯曲的理论，不也是源于一个少年躺在草地上，幻想自己追着光跑的幻觉吗？

我们之所以比其他所有生物都更强大，不是因为我们更尊重事实。

恰恰相反，是因为我们更擅长，创造那些超越事实的故事。

现在，我们再回头看AI的幻觉。

我们一直在努力修复的那个东西，可能恰恰是AI身上，最像人的东西。

我当然不希望AI在一个严肃的医疗诊断里产生幻觉，我们也不希望它在一个关键的财务分析里胡说八道，在这些需要绝对真实的领域，我们需要的是一个没有感情、绝对可靠的工具。

但是，在一个需要创造力、需要想象力的领域呢？

当我们要求AI去写一首诗，去画一幅画，去构思一个科幻故事时，我们真正想要的，难道不就是它那种，能挣脱事实的枷锁，在信息的缝隙里，进行自由联想和创造性猜测的能力吗？

在大量的讨论中，幻觉一词，好像一直是一个矛盾。

我们一边渴望AI成为一个绝对忠诚、绝对正确的工具，一个不会犯错的仆人，帮我们处理现实世界里所有需要精确计算的难题。

但我们又渴望它能成为一个能理解我们、甚至超越我们的同类。

我们希望它能和我们一起，去仰望星空，去聊那些没有标准答案的话题，去共同编织那些属于未来的、新的神话。

我们似乎在试图创造一个不可能的物种：

一个既拥有机器的严谨，又拥有人类的浪漫，一个既能坚守事实，又能创造幻觉的矛盾体。

我们生活在一个由数据和算法定义的前所未有的真实世界里，我们，也比历史上任何一个时代的人，都更崇拜事实，更依赖逻辑。

但同时，我一直觉得，我们又可能，是历史上最孤独的一个时代。

我们的神话已经远去，我们的史诗已经谱完。

在这样一个一切都被解释得清清楚楚的世界里，我自己内心那种最古老的、对故事的渴望，对意义的追寻，反而一直，变得空前强烈。

我到底想要一个什么样的未来？一个所有问题都有标准答案的、绝对真实、但可能也绝对无趣的未来？还是一个依然充满了未知、充满了误读、但因此也充满了故事和想象力的未来？

这个问题过于宏大了，我没有答案。

但是我始终喜欢、并相信。

那个
最美丽的，又创造了整个文明的。


wzglyay@virxact.com

## 关联主题

- [[00-元语/数字生命卡兹克]]
- [[00-元语/AI]]
- [[00-元语/llm]]
