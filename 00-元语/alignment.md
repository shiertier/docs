# alignment

## 文档信息

- 类型：主题词条
- 更新日期：2026-02-23

## 定义

alignment（对齐）指让 AI 系统在训练、部署与迭代过程中，持续与人类意图、价值约束及安全边界保持一致的研究与工程实践。

## 核心内涵

- 目标对齐：把系统优化目标与人类真实目标尽量一致，降低“指标达成但结果偏航”的风险。
- 行为对齐：在复杂或对抗场景中维持可控、可解释、可审计的输出行为。
- 评估与纠偏：通过持续评估、红队测试和反馈回路识别偏差并迭代修正。

## 相关词条

- [[00-元语/AI]]
- [[00-元语/risk]]
- [[00-元语/evals]]
- [[00-元语/security]]
- [[00-元语/compliance]]

## 关联主题

- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/evals]]
- [[00-元语/risk]]
- [[00-元语/security]]
- [[00-元语/compliance]]
