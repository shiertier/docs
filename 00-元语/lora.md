# lora

## 文档信息

- 类型：主题词条
- 更新日期：2026-02-22

## 定义

用于聚合 LoRA 相关文档。LoRA 常用于大语言模型与扩散模型的参数高效微调。

## 核心内涵

LoRA（Low-Rank Adaptation）是一种参数高效的微调技术。它通过冻结预训练模型的核心权重，并在模型的特定层中注入可训练的低秩分解矩阵，从而在极大地减少计算资源和显存消耗的前提下，实现对大模型针对特定垂直领域或具体任务的定制化适配。

## 实践要点

- 参数配置：合理设置秩（Rank/r）与缩放因子（Alpha），在模型拟合能力与训练成本之间寻找最佳平衡点。
- 数据质量：由于 LoRA 训练的参数量较小，其对微调数据集的质量、多样性与格式规范性要求极高，需投入精力进行数据清洗与标注。
- 模块化管理：利用 LoRA 权重的即插即用特性，可以为同一个基础模型训练多个不同任务的 LoRA 适配器，在推理时根据需求动态加载或切换。
- 灾难性遗忘防范：在微调过程中注意监控模型在通用任务上的表现，避免因过度拟合特定数据而丧失基础模型的泛化能力。

## 相关词条

- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/image-editing]]

## 关联主题
- [[00-元语/AI]]
- [[00-元语/llm]]
- [[00-元语/image-editing]]
- [[00-元语/multimodal]]
